{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam, AdamW, Nadam, RMSprop, SGD\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from keras.losses import categorical_crossentropy\n",
    "from sklearn.metrics import log_loss\n",
    "from keras.utils import to_categorical\n",
    "from adabound import AdaBound\n",
    "from tensorflow.keras.metrics import AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evito que ciertas columnas se transformen a notacion cientifica en las predicciones\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'Open_time',\n",
    "    'Open',\n",
    "    'High',\n",
    "    'Low',\n",
    "    # 'Close',\n",
    "    'Number of trades',\n",
    "    'Close_BTCUSDT',\n",
    "    'Volume_BTCUSDT',\n",
    "    'Number_of_trades_BTCUSDT',\n",
    "    'Close_ETHUSDT',\n",
    "    'Volume_ETHUSDT',\n",
    "    'Number_of_trades_ETHUSDT',\n",
    "    'Close_BNBUSDT',\n",
    "    'Volume_BNBUSDT',\n",
    "    'Number_of_trades_BNBUSDT',\n",
    "    'SMA_20',\n",
    "    'EMA_20',\n",
    "    'Upper_Band',\n",
    "    'Middle_Band',\n",
    "    'Lower_Band',\n",
    "    'RSI',\n",
    "    'buy_1000x_high_coinbase',\n",
    "    'sell_1000x_high_coinbase',\n",
    "    'total_trades_coinbase',\t\n",
    "    'Tweets_Utilizados',\n",
    "    'Tweets_Utilizados_coin',\n",
    "    'Tweets_Utilizados_referentes',\n",
    "    'Tweets_Utilizados_whale_alert',\n",
    "    'Buy_1000x_high',\n",
    "    'sell_1000x_high',\n",
    "    'total_trades_binance'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armado y entrenamiento de un clasificador a partir de los datos originales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = pd.read_csv('/Users/mmarchetta/Desktop/Tesis-2024/data-visualization/final_dataset.csv') \n",
    "classifier_dataset = complete_dataset[columns]\n",
    "classifier_dataset['Open_time'] = pd.to_datetime(classifier_dataset['Open_time'])\n",
    "classifier_dataset['Tendencia'] = complete_dataset['Tendencia']\n",
    "\n",
    "clasifier_validation = classifier_dataset[-10:]\n",
    "classifier_dataset = classifier_dataset[:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open_time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Number of trades</th>\n",
       "      <th>Close_BTCUSDT</th>\n",
       "      <th>Volume_BTCUSDT</th>\n",
       "      <th>Number_of_trades_BTCUSDT</th>\n",
       "      <th>Close_ETHUSDT</th>\n",
       "      <th>Volume_ETHUSDT</th>\n",
       "      <th>Number_of_trades_ETHUSDT</th>\n",
       "      <th>Close_BNBUSDT</th>\n",
       "      <th>Volume_BNBUSDT</th>\n",
       "      <th>Number_of_trades_BNBUSDT</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>Upper_Band</th>\n",
       "      <th>Middle_Band</th>\n",
       "      <th>Lower_Band</th>\n",
       "      <th>RSI</th>\n",
       "      <th>buy_1000x_high_coinbase</th>\n",
       "      <th>sell_1000x_high_coinbase</th>\n",
       "      <th>total_trades_coinbase</th>\n",
       "      <th>Tweets_Utilizados</th>\n",
       "      <th>Tweets_Utilizados_coin</th>\n",
       "      <th>Tweets_Utilizados_referentes</th>\n",
       "      <th>Tweets_Utilizados_whale_alert</th>\n",
       "      <th>Buy_1000x_high</th>\n",
       "      <th>sell_1000x_high</th>\n",
       "      <th>total_trades_binance</th>\n",
       "      <th>Tendencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>2024-04-25</td>\n",
       "      <td>6.93</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.70</td>\n",
       "      <td>71088.00</td>\n",
       "      <td>64498.34</td>\n",
       "      <td>31341.46</td>\n",
       "      <td>1375324.00</td>\n",
       "      <td>3155.80</td>\n",
       "      <td>352288.55</td>\n",
       "      <td>861077.00</td>\n",
       "      <td>613.20</td>\n",
       "      <td>453745.52</td>\n",
       "      <td>353114.00</td>\n",
       "      <td>7.43</td>\n",
       "      <td>7.45</td>\n",
       "      <td>9.08</td>\n",
       "      <td>7.43</td>\n",
       "      <td>5.77</td>\n",
       "      <td>38.83</td>\n",
       "      <td>21.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>33468.00</td>\n",
       "      <td>151</td>\n",
       "      <td>114</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>242.00</td>\n",
       "      <td>219.00</td>\n",
       "      <td>48000.00</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>2024-04-26</td>\n",
       "      <td>6.86</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.71</td>\n",
       "      <td>67383.00</td>\n",
       "      <td>63770.01</td>\n",
       "      <td>27085.19</td>\n",
       "      <td>1025561.00</td>\n",
       "      <td>3131.30</td>\n",
       "      <td>252522.65</td>\n",
       "      <td>628635.00</td>\n",
       "      <td>598.00</td>\n",
       "      <td>302119.88</td>\n",
       "      <td>269508.00</td>\n",
       "      <td>7.34</td>\n",
       "      <td>7.38</td>\n",
       "      <td>8.94</td>\n",
       "      <td>7.34</td>\n",
       "      <td>5.74</td>\n",
       "      <td>37.81</td>\n",
       "      <td>29.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>26619.00</td>\n",
       "      <td>117</td>\n",
       "      <td>106</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>292.00</td>\n",
       "      <td>324.00</td>\n",
       "      <td>42000.00</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>6.76</td>\n",
       "      <td>6.87</td>\n",
       "      <td>6.51</td>\n",
       "      <td>64779.00</td>\n",
       "      <td>63461.98</td>\n",
       "      <td>20933.06</td>\n",
       "      <td>912422.00</td>\n",
       "      <td>3255.56</td>\n",
       "      <td>323811.19</td>\n",
       "      <td>734026.00</td>\n",
       "      <td>596.20</td>\n",
       "      <td>268783.91</td>\n",
       "      <td>233820.00</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.33</td>\n",
       "      <td>8.73</td>\n",
       "      <td>7.24</td>\n",
       "      <td>5.76</td>\n",
       "      <td>38.57</td>\n",
       "      <td>17.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>25565.00</td>\n",
       "      <td>101</td>\n",
       "      <td>138</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>248.00</td>\n",
       "      <td>179.00</td>\n",
       "      <td>41000.00</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>2024-04-28</td>\n",
       "      <td>6.81</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.69</td>\n",
       "      <td>43208.00</td>\n",
       "      <td>63118.62</td>\n",
       "      <td>16949.20</td>\n",
       "      <td>790652.00</td>\n",
       "      <td>3263.45</td>\n",
       "      <td>304766.01</td>\n",
       "      <td>753239.00</td>\n",
       "      <td>600.20</td>\n",
       "      <td>258059.43</td>\n",
       "      <td>206703.00</td>\n",
       "      <td>7.13</td>\n",
       "      <td>7.27</td>\n",
       "      <td>8.38</td>\n",
       "      <td>7.13</td>\n",
       "      <td>5.88</td>\n",
       "      <td>37.66</td>\n",
       "      <td>16.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20954.00</td>\n",
       "      <td>82</td>\n",
       "      <td>106</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>173.00</td>\n",
       "      <td>165.00</td>\n",
       "      <td>26000.00</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>6.73</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.47</td>\n",
       "      <td>63006.00</td>\n",
       "      <td>63866.00</td>\n",
       "      <td>28150.23</td>\n",
       "      <td>1152296.00</td>\n",
       "      <td>3216.73</td>\n",
       "      <td>421831.29</td>\n",
       "      <td>943719.00</td>\n",
       "      <td>592.80</td>\n",
       "      <td>330474.01</td>\n",
       "      <td>271926.00</td>\n",
       "      <td>7.03</td>\n",
       "      <td>7.20</td>\n",
       "      <td>8.08</td>\n",
       "      <td>7.03</td>\n",
       "      <td>5.97</td>\n",
       "      <td>36.02</td>\n",
       "      <td>69.00</td>\n",
       "      <td>37.00</td>\n",
       "      <td>33959.00</td>\n",
       "      <td>115</td>\n",
       "      <td>125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>260.00</td>\n",
       "      <td>188.00</td>\n",
       "      <td>41000.00</td>\n",
       "      <td>Bajista</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Open_time  Open  High  Low  Number of trades  Close_BTCUSDT  \\\n",
       "941 2024-04-25  6.93  7.00 6.70          71088.00       64498.34   \n",
       "942 2024-04-26  6.86  6.95 6.71          67383.00       63770.01   \n",
       "943 2024-04-27  6.76  6.87 6.51          64779.00       63461.98   \n",
       "944 2024-04-28  6.81  6.95 6.69          43208.00       63118.62   \n",
       "945 2024-04-29  6.73  6.83 6.47          63006.00       63866.00   \n",
       "\n",
       "     Volume_BTCUSDT  Number_of_trades_BTCUSDT  Close_ETHUSDT  Volume_ETHUSDT  \\\n",
       "941        31341.46                1375324.00        3155.80       352288.55   \n",
       "942        27085.19                1025561.00        3131.30       252522.65   \n",
       "943        20933.06                 912422.00        3255.56       323811.19   \n",
       "944        16949.20                 790652.00        3263.45       304766.01   \n",
       "945        28150.23                1152296.00        3216.73       421831.29   \n",
       "\n",
       "     Number_of_trades_ETHUSDT  Close_BNBUSDT  Volume_BNBUSDT  \\\n",
       "941                 861077.00         613.20       453745.52   \n",
       "942                 628635.00         598.00       302119.88   \n",
       "943                 734026.00         596.20       268783.91   \n",
       "944                 753239.00         600.20       258059.43   \n",
       "945                 943719.00         592.80       330474.01   \n",
       "\n",
       "     Number_of_trades_BNBUSDT  SMA_20  EMA_20  Upper_Band  Middle_Band  \\\n",
       "941                 353114.00    7.43    7.45        9.08         7.43   \n",
       "942                 269508.00    7.34    7.38        8.94         7.34   \n",
       "943                 233820.00    7.24    7.33        8.73         7.24   \n",
       "944                 206703.00    7.13    7.27        8.38         7.13   \n",
       "945                 271926.00    7.03    7.20        8.08         7.03   \n",
       "\n",
       "     Lower_Band   RSI  buy_1000x_high_coinbase  sell_1000x_high_coinbase  \\\n",
       "941        5.77 38.83                    21.00                     26.00   \n",
       "942        5.74 37.81                    29.00                     24.00   \n",
       "943        5.76 38.57                    17.00                     17.00   \n",
       "944        5.88 37.66                    16.00                     20.00   \n",
       "945        5.97 36.02                    69.00                     37.00   \n",
       "\n",
       "     total_trades_coinbase  Tweets_Utilizados  Tweets_Utilizados_coin  \\\n",
       "941               33468.00                151                     114   \n",
       "942               26619.00                117                     106   \n",
       "943               25565.00                101                     138   \n",
       "944               20954.00                 82                     106   \n",
       "945               33959.00                115                     125   \n",
       "\n",
       "     Tweets_Utilizados_referentes  Tweets_Utilizados_whale_alert  \\\n",
       "941                          0.00                          22.00   \n",
       "942                          0.00                          14.00   \n",
       "943                          0.00                           7.00   \n",
       "944                          0.00                          13.00   \n",
       "945                          0.00                          24.00   \n",
       "\n",
       "     Buy_1000x_high  sell_1000x_high  total_trades_binance Tendencia  \n",
       "941          242.00           219.00              48000.00   Lateral  \n",
       "942          292.00           324.00              42000.00   Lateral  \n",
       "943          248.00           179.00              41000.00   Lateral  \n",
       "944          173.00           165.00              26000.00   Lateral  \n",
       "945          260.00           188.00              41000.00   Bajista  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(classifier_dataset.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(946, 31)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = classifier_dataset.drop(columns=[\"Tendencia\", \"Open_time\"])\n",
    "y = classifier_dataset[\"Tendencia\"]\n",
    "\n",
    "y = y.to_numpy().reshape(-1, 1)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_one_hot = onehot_encoder.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_validation = clasifier_validation.drop(columns=[\"Tendencia\", \"Open_time\"])\n",
    "y_validation = clasifier_validation[\"Tendencia\"]\n",
    "\n",
    "X_validation_scaled = scaler.transform(X_validation)\n",
    "y_validation = y_validation.to_numpy().reshape(-1, 1)\n",
    "y_validation_one_hot = onehot_encoder.transform(y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.71028637,  1.73812395,  1.71239905, ...,  0.62105604,\n",
       "         0.07813715,  1.10706827],\n",
       "       [ 1.60086133,  1.5617387 ,  1.57244477, ...,  0.41483393,\n",
       "        -0.04949395,  0.6669114 ],\n",
       "       [ 1.46310302,  1.58144131,  1.56935754, ...,  0.88953389,\n",
       "         0.58479392,  0.74693992],\n",
       "       ...,\n",
       "       [-0.44646164, -0.45674653, -0.44752767, ..., -0.45674632,\n",
       "        -0.6373705 , -0.42014269],\n",
       "       [-0.4422605 , -0.44877167, -0.42910722, ..., -0.74857006,\n",
       "        -0.69151703, -0.52017834],\n",
       "       [-0.45027198, -0.46049941, -0.45174688, ..., -0.41005452,\n",
       "        -0.60256202, -0.42014269]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "\n",
    "def create_model(activation, units, dropout, learning_rate, l2_penalty, depth, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=int(units/2), activation=activation, input_shape=(len(X.columns), 1), return_sequences=True, kernel_regularizer=l2(l2_penalty)))\n",
    "    # model.add(Bidirectional(LSTM(units=int(units/2), activation=activation, return_sequences=True, input_shape=(len(X.columns), 1), kernel_regularizer=l2(l2_penalty))))\n",
    "\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    for _ in range(depth - 1):\n",
    "        # model.add(Bidirectional(LSTM(units=units, activation=activation, return_sequences=True, kernel_regularizer=l2(l2_penalty))))\n",
    "        model.add(LSTM(units=units, activation=activation, return_sequences=True, kernel_regularizer=l2(l2_penalty)))\n",
    "        model.add(Dropout(dropout))\n",
    "        model.add(BatchNormalization())\n",
    "    \n",
    "    # model.add(Bidirectional(LSTM(units=int(units*2), activation=activation, kernel_regularizer=l2(l2_penalty))))\n",
    "    model.add(LSTM(units=int(units*2), activation=activation, kernel_regularizer=l2(l2_penalty)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(units=3, activation='softmax'))\n",
    "    \n",
    "    if optimizer == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        optimizer = SGD(learning_rate=learning_rate)\n",
    "    # elif optimizer == 'adamw':\n",
    "    #     optimizer = AdamW(learning_rate=learning_rate)\n",
    "    # elif optimizer == 'nadam':\n",
    "    #     optimizer = Nadam(learning_rate=learning_rate)\n",
    "    # elif optimizer == 'adabound':\n",
    "    #     optimizer = AdaBound(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=[AUC(name='auc')])\n",
    "    return model\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "classifier = KerasClassifier(build_fn=create_model, verbose=0, activation='relu', units=50, dropout=0.2, learning_rate=0.1, l2_penalty=0.001, depth=2, optimizer='adam')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001)\n",
    "\n",
    "cv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "param_space = {\n",
    "    'depth': [2, 3, 4, 5, 6],\n",
    "    'activation': ['relu', 'tanh', 'swish', 'selu'],\n",
    "    'units': [64, 128, 256, 512],\n",
    "    'dropout': [0.1, 0.2, 0.3, 0.4],\n",
    "    'learning_rate': [0.01, 0.001, 0.0001],\n",
    "    'epochs': [10, 20, 30, 50, 100],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'optimizer': ['adam', 'rmsprop', 'sgd'],\n",
    "    # 'optimizer': ['adam', 'adamw', 'nadam', 'adabound'],\n",
    "    'l2_penalty': [0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "def categorical_crossentropy_loss(estimator, X_test, y_test):\n",
    "    y_pred = estimator.predict_proba(X_test)\n",
    "    if np.isnan(y_pred).any():\n",
    "        y_pred[np.isnan(y_pred)] = 0\n",
    "    loss = log_loss(y_test, y_pred)\n",
    "    return loss\n",
    "\n",
    "bayes_search = BayesSearchCV(classifier, param_space, scoring=categorical_crossentropy_loss, cv=cv, verbose=0)#10)\n",
    "# bayes_result = bayes_search.fit(X, y_one_hot, callbacks=[early_stopping, reduce_lr], shuffle=False, validation_split=0.1)\n",
    "bayes_result = bayes_search.fit(X_scaled, y_one_hot, callbacks=[early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 2.62298942993928\n",
      "Best parameters: OrderedDict([('activation', 'swish'), ('batch_size', 64), ('depth', 2), ('dropout', 0.4), ('epochs', 100), ('l2_penalty', 0.01), ('learning_rate', 0.01), ('optimizer', 'rmsprop'), ('units', 64)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KerasClassifier(\n",
       "\tmodel=None\n",
       "\tbuild_fn=&lt;function create_model at 0x7fb4a1720670&gt;\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=64\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=0\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=100\n",
       "\tactivation=swish\n",
       "\tunits=64\n",
       "\tdropout=0.4\n",
       "\tlearning_rate=0.01\n",
       "\tl2_penalty=0.01\n",
       "\tdepth=2\n",
       "\tclass_weight=None\n",
       ")</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=None\n",
       "\tbuild_fn=&lt;function create_model at 0x7fb4a1720670&gt;\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=64\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=0\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=100\n",
       "\tactivation=swish\n",
       "\tunits=64\n",
       "\tdropout=0.4\n",
       "\tlearning_rate=0.01\n",
       "\tl2_penalty=0.01\n",
       "\tdepth=2\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KerasClassifier(\n",
       "\tmodel=None\n",
       "\tbuild_fn=<function create_model at 0x7fb4a1720670>\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=64\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=0\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=100\n",
       "\tactivation=swish\n",
       "\tunits=64\n",
       "\tdropout=0.4\n",
       "\tlearning_rate=0.01\n",
       "\tl2_penalty=0.01\n",
       "\tdepth=2\n",
       "\tclass_weight=None\n",
       ")"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show best results\n",
    "print(\"Best score:\", bayes_result.best_score_)\n",
    "print(\"Best parameters:\", bayes_result.best_params_)\n",
    "\n",
    "# Entrenar el modelo con los mejores hiperparámetros\n",
    "best_model = bayes_result.best_estimator_\n",
    "# best_model.fit(X, y_one_hot)\n",
    "best_model.fit(X_scaled, y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = bayes_result.best_estimator_.model_.history\n",
    "\n",
    "plt.plot(history.history['auc'])\n",
    "# plt.plot(history.history['val_auc'])\n",
    "plt.title('Model AUC')\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 mejores modelos:\n",
      "Modelo 1\n",
      "Hiperparámetros: OrderedDict([('activation', 'swish'), ('batch_size', 64), ('depth', 2), ('dropout', 0.4), ('epochs', 100), ('l2_penalty', 0.01), ('learning_rate', 0.01), ('optimizer', 'rmsprop'), ('units', 64)])\n",
      "Puntaje: 2.62298942993928\n",
      "Modelo 2\n",
      "Hiperparámetros: OrderedDict([('activation', 'swish'), ('batch_size', 64), ('depth', 3), ('dropout', 0.3), ('epochs', 50), ('l2_penalty', 0.001), ('learning_rate', 0.01), ('optimizer', 'sgd'), ('units', 64)])\n",
      "Puntaje: 2.3161767660535064\n",
      "Modelo 3\n",
      "Hiperparámetros: OrderedDict([('activation', 'swish'), ('batch_size', 64), ('depth', 2), ('dropout', 0.4), ('epochs', 50), ('l2_penalty', 0.001), ('learning_rate', 0.01), ('optimizer', 'sgd'), ('units', 64)])\n",
      "Puntaje: 2.2652998922688594\n",
      "Modelo 4\n",
      "Hiperparámetros: OrderedDict([('activation', 'swish'), ('batch_size', 64), ('depth', 5), ('dropout', 0.4), ('epochs', 20), ('l2_penalty', 0.01), ('learning_rate', 0.01), ('optimizer', 'rmsprop'), ('units', 64)])\n",
      "Puntaje: 2.043740995105809\n",
      "Modelo 5\n",
      "Hiperparámetros: OrderedDict([('activation', 'swish'), ('batch_size', 64), ('depth', 5), ('dropout', 0.2), ('epochs', 100), ('l2_penalty', 0.01), ('learning_rate', 0.01), ('optimizer', 'rmsprop'), ('units', 64)])\n",
      "Puntaje: 2.005688966286849\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Obtener los hiperparámetros y puntajes de los 5 mejores modelos\n",
    "top_n_models = 5\n",
    "best_params_list = []\n",
    "best_scores_list = []\n",
    "\n",
    "if 'rank_test_score' in bayes_search.cv_results_:\n",
    "    sorted_indices = np.argsort(bayes_search.cv_results_['rank_test_score'])\n",
    "\n",
    "    for i in range(min(top_n_models, len(sorted_indices))):\n",
    "        best_params_list.append(bayes_search.cv_results_['params'][sorted_indices[i]])\n",
    "        best_scores_list.append(bayes_search.cv_results_['mean_test_score'][sorted_indices[i]])\n",
    "\n",
    "    # Guardar los hiperparámetros de los 5 mejores modelos en un archivo JSON\n",
    "    with open('conv_classifier/top_5_hyperparameters.json', 'w') as f:\n",
    "        json.dump({'best_params': best_params_list, 'best_scores': best_scores_list}, f)\n",
    "\n",
    "    # O imprimir los hiperparámetros\n",
    "    print(\"Top 5 mejores modelos:\")\n",
    "    for i in range(len(best_params_list)):\n",
    "        print(\"Modelo\", i + 1)\n",
    "        print(\"Hiperparámetros:\", best_params_list[i])\n",
    "        print(\"Puntaje:\", best_scores_list[i])\n",
    "\n",
    "else:\n",
    "    print(\"Error: 'rank_test_score' no encontrado en cv_results_\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Armado del ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prime_seeds(n):\n",
    "    seeds = []\n",
    "    num = 70001  # Comenzamos desde el primer número primo mayor que 70000\n",
    "    while len(seeds) < n:\n",
    "        is_prime = True\n",
    "        for i in range(2, int(num**0.5) + 1):\n",
    "            if num % i == 0:\n",
    "                is_prime = False\n",
    "                break\n",
    "        if is_prime:\n",
    "            seeds.append(num)\n",
    "        num += 1\n",
    "    return seeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clase personalizada para hacer el ensamble, dado que sklearn no provee ninguna clase que permita hacer ensmble\n",
    "## de modelos re regresion multivariados\n",
    "class MultivariableVotingClassifier:\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for model in self.models:\n",
    "            model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Hacer predicciones con cada modelo\n",
    "        predictions = np.array([model.predict(X) for model in self.models])\n",
    "        \n",
    "        # Calcular la moda de las predicciones\n",
    "        mode_predictions = np.argmax(np.sum(predictions, axis=0), axis=1)\n",
    "        \n",
    "        return mode_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 17s 2s/step - loss: 31.1738 - auc: 0.5547\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 18s 2s/step - loss: 31.1699 - auc: 0.5398\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 18s 2s/step - loss: 31.1605 - auc: 0.5437\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 18s 2s/step - loss: 31.1442 - auc: 0.5500\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 18s 2s/step - loss: 31.1391 - auc: 0.5531\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 31.1362 - auc: 0.5452\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 31.1291 - auc: 0.5378\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 18s 2s/step - loss: 31.1064 - auc: 0.5638\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 31.1088 - auc: 0.5387\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 31.0938 - auc: 0.5475\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 18s 2s/step - loss: 31.0868 - auc: 0.5436\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 31.0761 - auc: 0.5582\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 31.0678 - auc: 0.5445\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 19s 2s/step - loss: 31.0475 - auc: 0.5622\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 18s 2s/step - loss: 31.0417 - auc: 0.5622\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 31.0475 - auc: 0.5245\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 31.0305 - auc: 0.5503\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 31.0202 - auc: 0.5495\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 18s 2s/step - loss: 31.0009 - auc: 0.5656\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 18s 2s/step - loss: 30.9957 - auc: 0.5544\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 30.9878 - auc: 0.5550\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 30.9743 - auc: 0.5605\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 18s 2s/step - loss: 30.9682 - auc: 0.5603\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 18s 2s/step - loss: 30.9550 - auc: 0.5638\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 30.9584 - auc: 0.5349\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 30.9394 - auc: 0.5510\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 30.9230 - auc: 0.5631\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 18s 2s/step - loss: 30.9127 - auc: 0.5647\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 18s 2s/step - loss: 30.9139 - auc: 0.5439\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 30.9005 - auc: 0.5478\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 19s 2s/step - loss: 30.8873 - auc: 0.5618\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 30.8759 - auc: 0.5620\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 30.8600 - auc: 0.5678\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 30.8569 - auc: 0.5464\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 30.8506 - auc: 0.5494\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 30.8460 - auc: 0.5398\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 30.8299 - auc: 0.5562\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 18s 2s/step - loss: 30.8114 - auc: 0.5670\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 30.8024 - auc: 0.5591\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 30.8010 - auc: 0.5484\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 30.7693 - auc: 0.5819\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 30.7748 - auc: 0.5547\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 18s 2s/step - loss: 30.7584 - auc: 0.5628\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 20s 2s/step - loss: 30.7568 - auc: 0.5413\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 19s 2s/step - loss: 30.7362 - auc: 0.5702\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.7241 - auc: 0.5674\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.7121 - auc: 0.5753\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.7100 - auc: 0.5596\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.6972 - auc: 0.5658\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 30.6909 - auc: 0.5542\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 30.6765 - auc: 0.5603\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.6587 - auc: 0.5704\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.6418 - auc: 0.5881\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 30.6406 - auc: 0.5651\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 30.6318 - auc: 0.5582\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.6355 - auc: 0.5380\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.6051 - auc: 0.5622\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.6024 - auc: 0.5548\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.5872 - auc: 0.5610\n",
      "8/8 [==============================] - 6s 585ms/step\n",
      "model number 4, seed number 4\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 25s 2s/step - loss: 32.5917 - auc: 0.5305\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 29.2371 - auc: 0.5566\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 28.1776 - auc: 0.5387\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 27.4384 - auc: 0.5145\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 27.3204 - auc: 0.5008\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 27.6867 - auc: 0.5232\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 28.1001 - auc: 0.4944\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 28.2496 - auc: 0.5048\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 28.4941 - auc: 0.4875\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 28.7865 - auc: 0.4885\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 28.8690 - auc: 0.5212\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 28.9061 - auc: 0.4943\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 28.8145 - auc: 0.4926\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.6971 - auc: 0.5031\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 28.5626 - auc: 0.5042\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 28.4422 - auc: 0.4966\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 28.2819 - auc: 0.5196\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 28.1707 - auc: 0.4900\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 28.0067 - auc: 0.5205\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 27.8889 - auc: 0.5048\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 27.7564 - auc: 0.5200\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 27.6379 - auc: 0.5060\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 27.5047 - auc: 0.5149\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 27.3884 - auc: 0.5102\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 27.2633 - auc: 0.5063\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 27.1635 - auc: 0.4991\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 27.0442 - auc: 0.4984\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 26.9312 - auc: 0.5064\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 26.8133 - auc: 0.5100\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 26.6955 - auc: 0.5249\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 26.5926 - auc: 0.5257\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 26.4960 - auc: 0.5097\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 26.3731 - auc: 0.5434\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 26.2891 - auc: 0.5253\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 26.1992 - auc: 0.5106\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 26.0936 - auc: 0.5205\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 25.9995 - auc: 0.5286\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 25.9193 - auc: 0.5025\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 25.8307 - auc: 0.5027\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 25.7330 - auc: 0.5160\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 25.6497 - auc: 0.5043\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 25.5571 - auc: 0.5297\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 25.4844 - auc: 0.5048\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 25.3931 - auc: 0.5146\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 25.3089 - auc: 0.5192\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 25.2291 - auc: 0.5227\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 25.1521 - auc: 0.5202\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 25.0729 - auc: 0.5274\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 25.0001 - auc: 0.5269\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 24.9236 - auc: 0.5302\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 24.8512 - auc: 0.5328\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 24.7789 - auc: 0.5333\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 24.7058 - auc: 0.5364\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 24.6404 - auc: 0.5302\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 24.5675 - auc: 0.5420\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 24.5072 - auc: 0.5221\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 24.4379 - auc: 0.5311\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 24.3825 - auc: 0.5036\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 24.2996 - auc: 0.5458\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 24.2402 - auc: 0.5367\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 24.1785 - auc: 0.5356\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 24.1160 - auc: 0.5348\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 24.0555 - auc: 0.5417\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 24.0010 - auc: 0.5211\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 23.9325 - auc: 0.5462\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 23.8877 - auc: 0.5176\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 23.8239 - auc: 0.5309\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 23.7616 - auc: 0.5387\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 23.7128 - auc: 0.5312\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 23.6630 - auc: 0.5144\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 23.6038 - auc: 0.5189\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 23.5459 - auc: 0.5310\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 23.4941 - auc: 0.5262\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 23.4330 - auc: 0.5495\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 23.3882 - auc: 0.5268\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 23.3347 - auc: 0.5381\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 23.2801 - auc: 0.5450\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 23.2284 - auc: 0.5477\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 23.1778 - auc: 0.5508\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 23.1370 - auc: 0.5307\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 23.0936 - auc: 0.5210\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 23.0462 - auc: 0.5221\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 22.9906 - auc: 0.5403\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 22.9463 - auc: 0.5324\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 22.8983 - auc: 0.5396\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 22.8496 - auc: 0.5422\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 22.8077 - auc: 0.5348\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 22.7614 - auc: 0.5385\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 22.7189 - auc: 0.5280\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 22.6749 - auc: 0.5291\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 22.6253 - auc: 0.5428\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 22.5853 - auc: 0.5351\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 22.5497 - auc: 0.5334\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 22.4934 - auc: 0.5501\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 22.4564 - auc: 0.5403\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 22.4205 - auc: 0.5265\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 22.3852 - auc: 0.5151\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 22.3397 - auc: 0.5263\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 22.2951 - auc: 0.5421\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 22.2518 - auc: 0.5423\n",
      "8/8 [==============================] - 7s 497ms/step\n",
      "model number 4, seed number 5\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 36s 2s/step - loss: 32.3676 - auc: 0.5145\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.8154 - auc: 0.5583\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.5468 - auc: 0.5218\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.2898 - auc: 0.5052\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 28.8630 - auc: 0.5081\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 28.3788 - auc: 0.4820\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 27.8556 - auc: 0.5058\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 27.7091 - auc: 0.4723\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 27.5102 - auc: 0.5083\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 27.2325 - auc: 0.5184\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 26.9100 - auc: 0.5102\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 26.5892 - auc: 0.4795\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 26.2339 - auc: 0.4911\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 25.8803 - auc: 0.5029\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 25.5370 - auc: 0.5062\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 25.2294 - auc: 0.4975\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 24.9200 - auc: 0.4924\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 24.6205 - auc: 0.4973\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 24.3219 - auc: 0.5046\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 24.0420 - auc: 0.5113\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 23.7815 - auc: 0.5077\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 23.5151 - auc: 0.5185\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 23.2694 - auc: 0.5083\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 23.0248 - auc: 0.5138\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 22.8062 - auc: 0.4888\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 22.5899 - auc: 0.4815\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 22.3439 - auc: 0.5191\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 22.1223 - auc: 0.5249\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 21.9333 - auc: 0.4902\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 21.7241 - auc: 0.5009\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 21.5165 - auc: 0.5209\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 21.3196 - auc: 0.5195\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 21.1219 - auc: 0.5350\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 20.9533 - auc: 0.5024\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 20.7573 - auc: 0.5345\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 20.5792 - auc: 0.5274\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 20.4091 - auc: 0.5141\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 20.2325 - auc: 0.5339\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 20.0661 - auc: 0.5259\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 19.9100 - auc: 0.5166\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 19.7385 - auc: 0.5285\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 19.5840 - auc: 0.5276\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 19.4285 - auc: 0.5302\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 19.2905 - auc: 0.4985\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 19.1348 - auc: 0.5132\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 18.9639 - auc: 0.5574\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 18.8306 - auc: 0.5342\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 18.6784 - auc: 0.5567\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 18.5376 - auc: 0.5649\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 18.4164 - auc: 0.5314\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 18.2773 - auc: 0.5457\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 18.1408 - auc: 0.5490\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 18.0145 - auc: 0.5355\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 17.8882 - auc: 0.5276\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 17.7594 - auc: 0.5371\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 17.6293 - auc: 0.5440\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 17.5020 - auc: 0.5576\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 17.3892 - auc: 0.5314\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 17.2673 - auc: 0.5346\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 17.1370 - auc: 0.5602\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 17.0173 - auc: 0.5713\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 16.9168 - auc: 0.5392\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 16.8015 - auc: 0.5419\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 16.6722 - auc: 0.5697\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 16.5856 - auc: 0.5299\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 16.4818 - auc: 0.5274\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 16.3712 - auc: 0.5402\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 16.2656 - auc: 0.5500\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 16.1492 - auc: 0.5698\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 16.1069 - auc: 0.5458\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 19.8019 - auc: 0.4920\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 27.4858 - auc: 0.4853\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 32.8357 - auc: 0.5115\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 35.5821 - auc: 0.5329\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 36.9657 - auc: 0.5089\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 37.6156 - auc: 0.5034\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 37.8898 - auc: 0.5301\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 38.0186 - auc: 0.5019\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 38.0764 - auc: 0.5073\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 38.1118 - auc: 0.4949\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 38.1135 - auc: 0.4986\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 38.0906 - auc: 0.5434\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 38.1187 - auc: 0.5047\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 38.1214 - auc: 0.5057\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 38.1121 - auc: 0.5202\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 38.1203 - auc: 0.4889\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 38.1214 - auc: 0.5037\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 38.1046 - auc: 0.5217\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 38.1262 - auc: 0.4938\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 38.1173 - auc: 0.4951\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 38.1078 - auc: 0.5033\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 38.1211 - auc: 0.4916\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 38.1083 - auc: 0.4957\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 38.1128 - auc: 0.4939\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 38.0949 - auc: 0.5302\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 38.1079 - auc: 0.5067\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 38.1091 - auc: 0.5039\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 38.1060 - auc: 0.4968\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 38.0954 - auc: 0.5110\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 38.0993 - auc: 0.5020\n",
      "8/8 [==============================] - 7s 608ms/step\n",
      "model number 4, seed number 6\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 28s 2s/step - loss: 32.1982 - auc: 0.5404\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.3621 - auc: 0.5326\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.0087 - auc: 0.4965\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.3664 - auc: 0.5047\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.8486 - auc: 0.5098\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.1950 - auc: 0.5289\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.4316 - auc: 0.5209\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.5682 - auc: 0.5058\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.6195 - auc: 0.5108\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.6235 - auc: 0.5084\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.6071 - auc: 0.5185\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.6053 - auc: 0.5126\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.6019 - auc: 0.5148\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.5835 - auc: 0.5194\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.5768 - auc: 0.5039\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.5422 - auc: 0.5268\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.5152 - auc: 0.5485\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.5112 - auc: 0.5295\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.5074 - auc: 0.5115\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.4808 - auc: 0.5277\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.4753 - auc: 0.5172\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.4521 - auc: 0.5213\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 30.4230 - auc: 0.5414\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.4050 - auc: 0.5490\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.4140 - auc: 0.5185\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.4047 - auc: 0.5161\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.3864 - auc: 0.5218\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 30.3785 - auc: 0.5198\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.3470 - auc: 0.5440\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.3435 - auc: 0.5301\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.3287 - auc: 0.5271\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.3223 - auc: 0.5226\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.2936 - auc: 0.5443\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.2781 - auc: 0.5405\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.2698 - auc: 0.5374\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 30.2599 - auc: 0.5210\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.2440 - auc: 0.5280\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.2212 - auc: 0.5328\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.2071 - auc: 0.5366\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.1916 - auc: 0.5353\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.1588 - auc: 0.5766\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.1428 - auc: 0.5680\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.1302 - auc: 0.5682\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.1222 - auc: 0.5509\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.1149 - auc: 0.5437\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.1074 - auc: 0.5245\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 30.0820 - auc: 0.5383\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.0741 - auc: 0.5244\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 30.0413 - auc: 0.5594\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 30.0261 - auc: 0.5546\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.0104 - auc: 0.5532\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.0075 - auc: 0.5388\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.9788 - auc: 0.5576\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.9760 - auc: 0.5371\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.9536 - auc: 0.5389\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.9318 - auc: 0.5496\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.9049 - auc: 0.5730\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.9089 - auc: 0.5345\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.8920 - auc: 0.5319\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.8676 - auc: 0.5458\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.8562 - auc: 0.5389\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.8361 - auc: 0.5439\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.8158 - auc: 0.5495\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.7999 - auc: 0.5521\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.7763 - auc: 0.5650\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.7707 - auc: 0.5431\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.7567 - auc: 0.5482\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.7197 - auc: 0.5779\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.7169 - auc: 0.5581\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.7089 - auc: 0.5369\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.6887 - auc: 0.5439\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.6743 - auc: 0.5343\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.6396 - auc: 0.5704\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.6349 - auc: 0.5480\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.6082 - auc: 0.5639\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.6042 - auc: 0.5488\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.5865 - auc: 0.5409\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.5747 - auc: 0.5402\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.5570 - auc: 0.5419\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.5267 - auc: 0.5606\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.5171 - auc: 0.5469\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.4977 - auc: 0.5515\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.4793 - auc: 0.5531\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.4581 - auc: 0.5596\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.4389 - auc: 0.5639\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.4266 - auc: 0.5526\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.4125 - auc: 0.5475\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.4016 - auc: 0.5270\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.3865 - auc: 0.5188\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.3572 - auc: 0.5484\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.3426 - auc: 0.5394\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.3284 - auc: 0.5403\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.2986 - auc: 0.5720\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.2930 - auc: 0.5390\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.2626 - auc: 0.5735\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.2459 - auc: 0.5732\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.2388 - auc: 0.5525\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.2222 - auc: 0.5483\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.1984 - auc: 0.5613\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.2038 - auc: 0.5291\n",
      "8/8 [==============================] - 6s 607ms/step\n",
      "model number 4, seed number 7\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 26s 2s/step - loss: 31.7990 - auc: 0.5593\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.9448 - auc: 0.5552\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.9006 - auc: 0.5032\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.3738 - auc: 0.4823\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.7351 - auc: 0.5128\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 30.0262 - auc: 0.4926\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 30.1122 - auc: 0.5007\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 30.1751 - auc: 0.5123\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 30.1860 - auc: 0.5120\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 30.1900 - auc: 0.5089\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.1761 - auc: 0.5182\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 30.1892 - auc: 0.4839\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 30.1454 - auc: 0.5106\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 30.1323 - auc: 0.5002\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 30.1092 - auc: 0.5099\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 30.1122 - auc: 0.4914\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 30.0862 - auc: 0.4941\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 30.0661 - auc: 0.4905\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.0396 - auc: 0.5022\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 30.0466 - auc: 0.5125\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.9957 - auc: 0.5122\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 30.0021 - auc: 0.4772\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.9497 - auc: 0.5306\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.9521 - auc: 0.4950\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.9264 - auc: 0.5016\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.9184 - auc: 0.4745\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.8698 - auc: 0.5214\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.8499 - auc: 0.5181\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.8337 - auc: 0.5197\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.8228 - auc: 0.4997\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.7956 - auc: 0.5103\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.7647 - auc: 0.5265\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 29.7601 - auc: 0.5030\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 16s 2s/step - loss: 29.7373 - auc: 0.5052\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.7018 - auc: 0.5310\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.7038 - auc: 0.4868\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.6770 - auc: 0.4962\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.6472 - auc: 0.5139\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.6159 - auc: 0.5364\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.6160 - auc: 0.4931\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.5868 - auc: 0.5116\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.5634 - auc: 0.5160\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.5366 - auc: 0.5310\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.5278 - auc: 0.4983\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.5001 - auc: 0.5163\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.4753 - auc: 0.5226\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.4502 - auc: 0.5271\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.4330 - auc: 0.5181\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.4184 - auc: 0.5009\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.3906 - auc: 0.5193\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.3591 - auc: 0.5377\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.3437 - auc: 0.5235\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.3222 - auc: 0.5247\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 17s 2s/step - loss: 29.3169 - auc: 0.4853\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.2832 - auc: 0.5104\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.2606 - auc: 0.5044\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.2277 - auc: 0.5292\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.2171 - auc: 0.5021\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.1961 - auc: 0.5019\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.1647 - auc: 0.5182\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.1498 - auc: 0.5080\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.1180 - auc: 0.5262\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.0926 - auc: 0.5302\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.0729 - auc: 0.5188\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.0586 - auc: 0.5005\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.0275 - auc: 0.5261\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.0113 - auc: 0.5075\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.9734 - auc: 0.5425\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.9573 - auc: 0.5226\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.9426 - auc: 0.5032\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.9277 - auc: 0.4910\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.8899 - auc: 0.5220\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.8639 - auc: 0.5226\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.8491 - auc: 0.5111\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 16s 2s/step - loss: 28.8130 - auc: 0.5371\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.7972 - auc: 0.5237\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.7729 - auc: 0.5232\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.7439 - auc: 0.5358\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.7253 - auc: 0.5260\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.7014 - auc: 0.5299\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.6758 - auc: 0.5374\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.6619 - auc: 0.5150\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.6320 - auc: 0.5211\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.6105 - auc: 0.5197\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.5757 - auc: 0.5484\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 16s 2s/step - loss: 28.5531 - auc: 0.5449\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 16s 2s/step - loss: 28.5524 - auc: 0.5116\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.5094 - auc: 0.5389\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.4955 - auc: 0.5137\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.4579 - auc: 0.5469\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 16s 2s/step - loss: 28.4346 - auc: 0.5481\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.4298 - auc: 0.5080\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.3917 - auc: 0.5399\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.3753 - auc: 0.5204\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 16s 2s/step - loss: 28.3533 - auc: 0.5162\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.3288 - auc: 0.5186\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.3000 - auc: 0.5265\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.2802 - auc: 0.5238\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.2486 - auc: 0.5435\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.2337 - auc: 0.5258\n",
      "8/8 [==============================] - 8s 708ms/step\n",
      "model number 4, seed number 8\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 34s 2s/step - loss: 32.0917 - auc: 0.5243\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.0782 - auc: 0.5616\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.8664 - auc: 0.4876\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.1395 - auc: 0.4968\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.3628 - auc: 0.4715\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.3815 - auc: 0.4881\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.2919 - auc: 0.5154\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.1845 - auc: 0.5034\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.0152 - auc: 0.5155\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.8823 - auc: 0.4876\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.6206 - auc: 0.5381\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.4872 - auc: 0.4909\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.2594 - auc: 0.4978\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 16s 2s/step - loss: 28.0496 - auc: 0.4999\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 27.8198 - auc: 0.5144\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 27.6194 - auc: 0.5096\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 27.4040 - auc: 0.5078\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 27.2348 - auc: 0.4658\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 26.9917 - auc: 0.5131\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 26.7816 - auc: 0.5084\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 26.5843 - auc: 0.5046\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 26.3755 - auc: 0.5115\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 26.1697 - auc: 0.5168\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 25.9861 - auc: 0.4947\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 25.7857 - auc: 0.4944\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 25.5502 - auc: 0.5471\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 25.3655 - auc: 0.5341\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 25.1851 - auc: 0.5142\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 24.9868 - auc: 0.5181\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 24.7610 - auc: 0.5721\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 24.6240 - auc: 0.5294\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 24.4584 - auc: 0.5114\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 24.2821 - auc: 0.5265\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 24.9976 - auc: 0.4996\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 16s 2s/step - loss: 27.0392 - auc: 0.4872\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.7020 - auc: 0.4981\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.6885 - auc: 0.5048\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 30.1104 - auc: 0.5143\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 30.2360 - auc: 0.5153\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 30.2387 - auc: 0.5018\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 30.1629 - auc: 0.5023\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 30.0496 - auc: 0.5121\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.9322 - auc: 0.5101\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.8362 - auc: 0.4949\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.7174 - auc: 0.4971\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.5943 - auc: 0.4940\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.4546 - auc: 0.5328\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.3605 - auc: 0.4962\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 29.2310 - auc: 0.5306\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.1196 - auc: 0.5179\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.0352 - auc: 0.4874\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.9147 - auc: 0.4932\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.8009 - auc: 0.5151\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.7105 - auc: 0.4903\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.5947 - auc: 0.5124\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 16s 2s/step - loss: 28.5054 - auc: 0.4971\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.4295 - auc: 0.4959\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.3297 - auc: 0.5178\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.2492 - auc: 0.4755\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 28.1233 - auc: 0.5080\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.0308 - auc: 0.4942\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 27.9331 - auc: 0.5044\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 27.8560 - auc: 0.4902\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 27.7363 - auc: 0.4989\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 27.6388 - auc: 0.5031\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 27.5567 - auc: 0.4882\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 27.4373 - auc: 0.5216\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 27.3578 - auc: 0.4938\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 27.2728 - auc: 0.5231\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 27.9383 - auc: 0.5063\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.0542 - auc: 0.4911\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.6559 - auc: 0.5117\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.8898 - auc: 0.5021\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.9268 - auc: 0.5024\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.8748 - auc: 0.4896\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.7747 - auc: 0.5024\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 16s 2s/step - loss: 29.6605 - auc: 0.5211\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.5556 - auc: 0.5034\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.4466 - auc: 0.4998\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.3431 - auc: 0.4738\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.2329 - auc: 0.4733\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.1026 - auc: 0.5255\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 29.0045 - auc: 0.5127\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.9073 - auc: 0.4862\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.7921 - auc: 0.5205\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.6903 - auc: 0.5247\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.5943 - auc: 0.5132\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.5033 - auc: 0.4964\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.3893 - auc: 0.5384\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.3140 - auc: 0.4831\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.2238 - auc: 0.4701\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 28.1146 - auc: 0.5197\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 28.0305 - auc: 0.4980\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 27.9403 - auc: 0.4978\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 27.8399 - auc: 0.5242\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 27.7706 - auc: 0.4691\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 27.6565 - auc: 0.5423\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 27.5839 - auc: 0.5040\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 27.5026 - auc: 0.4886\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 27.4141 - auc: 0.5029\n",
      "8/8 [==============================] - 7s 676ms/step\n",
      "model number 4, seed number 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "# Leer los hiperparámetros desde el archivo JSON\n",
    "with open('lstm_classifier/top_5_hyperparameters.json', 'r') as f:\n",
    "    top_hyperparameters = json.load(f)\n",
    "\n",
    "prime_seeds = generate_prime_seeds(10)\n",
    "models = []\n",
    "best_seeds= {}\n",
    "\n",
    "# Train models with different seeds for each set of hyperparameters\n",
    "for mode_number, params in enumerate(top_hyperparameters['best_params']):\n",
    "    best_validation_errors = {}\n",
    "    \n",
    "    for seed_number, seed in enumerate(prime_seeds):\n",
    "        model = KerasClassifier(build_fn=create_model, random_state=seed, verbose=1, **params)\n",
    "        # model.fit(X, y_one_hot)\n",
    "        model.fit(X_scaled, y_one_hot)\n",
    "        \n",
    "        # Make predictions with the model\n",
    "        # train_error = categorical_crossentropy_loss(model, X, y_one_hot)\n",
    "        train_error = categorical_crossentropy_loss(model, X_scaled, y_one_hot)\n",
    "        \n",
    "        mean_train_error = np.mean(train_error)\n",
    "\n",
    "        # Update best validation error for this seed\n",
    "        best_validation_errors[seed] = mean_train_error\n",
    "    \n",
    "        print(f\"model number {mode_number}, seed number {seed_number}\")\n",
    "\n",
    "    # Find the best seed for this set of hyperparameters\n",
    "    best_seed_for_params = min(best_validation_errors, key=lambda k: best_validation_errors[k])\n",
    "    best_seeds[str(params)] = best_seed_for_params\n",
    "    \n",
    "    # Create and train the model with the best seed\n",
    "    model = KerasClassifier(build_fn=create_model, random_state=best_seed_for_params, verbose=0, **params)\n",
    "    # model.fit(X, y_one_hot)\n",
    "    model.fit(X_scaled, y_one_hot)\n",
    "    models.append(model)\n",
    "\n",
    "# Define and train the ensemble model\n",
    "ensemble = MultivariableVotingClassifier(models)\n",
    "# ensemble.fit(X, y_one_hot)\n",
    "ensemble.fit(X_scaled, y_one_hot)\n",
    "\n",
    "# Save the best seeds to a JSON file\n",
    "with open('lstm_classifier/best_seeds.json', 'w') as f:\n",
    "    json.dump(best_seeds, f)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clasificacion con el ensamble sobre las redicciones de los modelos generativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 24s 581ms/step - loss: 7.2453 - auc: 0.5082\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 17s 562ms/step - loss: 12.2811 - auc: 0.5037\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 17s 550ms/step - loss: 13.8851 - auc: 0.4929\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 17s 556ms/step - loss: 14.0358 - auc: 0.5099\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 17s 556ms/step - loss: 13.8374 - auc: 0.4986\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 18s 593ms/step - loss: 13.4653 - auc: 0.5140\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 17s 565ms/step - loss: 13.2361 - auc: 0.4927\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 17s 557ms/step - loss: 12.9652 - auc: 0.4889\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 17s 568ms/step - loss: 12.6287 - auc: 0.5154\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 17s 562ms/step - loss: 12.3148 - auc: 0.5032\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 16s 540ms/step - loss: 12.1154 - auc: 0.5164\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 17s 558ms/step - loss: 11.9852 - auc: 0.5001\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 18s 594ms/step - loss: 11.8287 - auc: 0.4799\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 17s 555ms/step - loss: 11.6688 - auc: 0.4711\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 17s 572ms/step - loss: 11.3560 - auc: 0.5089\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 17s 560ms/step - loss: 11.1409 - auc: 0.5282\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 17s 579ms/step - loss: 10.9963 - auc: 0.5046\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 16s 547ms/step - loss: 10.7727 - auc: 0.5306\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 16s 537ms/step - loss: 10.6704 - auc: 0.5145\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 17s 552ms/step - loss: 10.4998 - auc: 0.4970\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 17s 579ms/step - loss: 10.3194 - auc: 0.5281\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 17s 565ms/step - loss: 10.1935 - auc: 0.5151\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 17s 561ms/step - loss: 10.0498 - auc: 0.5016\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 17s 545ms/step - loss: 9.8974 - auc: 0.5095\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 17s 566ms/step - loss: 9.7719 - auc: 0.5079\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 17s 574ms/step - loss: 9.6674 - auc: 0.5057\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 18s 584ms/step - loss: 9.5542 - auc: 0.5079\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 16s 548ms/step - loss: 9.4214 - auc: 0.5106\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 16s 538ms/step - loss: 9.2911 - auc: 0.5521\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 16s 542ms/step - loss: 9.2035 - auc: 0.4936\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 18s 597ms/step - loss: 9.0990 - auc: 0.5302\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 17s 561ms/step - loss: 33.6961 - auc: 0.4898\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 17s 561ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 17s 572ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 16s 546ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 17s 559ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 16s 551ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 16s 548ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 17s 572ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 16s 545ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 17s 553ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 17s 572ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 18s 590ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 18s 592ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 16s 542ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 17s 570ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 17s 579ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 18s 593ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 18s 599ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 16s 551ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 16s 541ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 17s 561ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 16s 534ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 16s 531ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 16s 529ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 16s 522ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 16s 539ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 16s 541ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 16s 537ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 16s 535ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 17s 571ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 16s 548ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 16s 537ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 16s 529ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 16s 550ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 16s 541ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 16s 537ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 17s 581ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 17s 559ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 17s 552ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 17s 554ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 17s 570ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 16s 539ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 16s 542ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 17s 559ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 16s 547ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 16s 542ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 17s 554ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 17s 559ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 17s 564ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 17s 575ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 16s 547ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 17s 571ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 16s 548ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 17s 546ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 18s 587ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 17s 555ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 16s 547ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 17s 550ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 16s 537ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 17s 557ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 17s 563ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 16s 544ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 16s 531ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 16s 547ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 16s 538ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 17s 564ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 16s 548ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 17s 553ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 16s 546ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 42s 898ms/step - loss: 11.9903 - auc: 0.4912\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 28s 930ms/step - loss: 19.1438 - auc: 0.5047\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 27s 900ms/step - loss: 19.4157 - auc: 0.5299\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 27s 889ms/step - loss: 19.0381 - auc: 0.4880\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 26s 870ms/step - loss: 18.5463 - auc: 0.5206\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 26s 854ms/step - loss: 18.4763 - auc: 0.4986\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 26s 869ms/step - loss: 18.3330 - auc: 0.4914\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 26s 873ms/step - loss: 17.9269 - auc: 0.5120\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 27s 883ms/step - loss: 17.5221 - auc: 0.5112\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 27s 909ms/step - loss: 17.1913 - auc: 0.5036\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 16s 130ms/step - loss: 25.0019 - auc: 0.5410\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 2s 138ms/step - loss: 8.1376 - auc: 0.5300\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 2s 127ms/step - loss: 3.0527 - auc: 0.5317\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 1.7779 - auc: 0.5154\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 2s 124ms/step - loss: 1.3784 - auc: 0.5373\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 2s 129ms/step - loss: 1.2590 - auc: 0.4753\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 1.3137 - auc: 0.4872\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 1.3235 - auc: 0.5165\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 2s 134ms/step - loss: 1.2234 - auc: 0.4682\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 1.1923 - auc: 0.4972\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 1.1541 - auc: 0.5120\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 2s 129ms/step - loss: 1.1513 - auc: 0.5048\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 2s 128ms/step - loss: 1.1318 - auc: 0.5241\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 1.1664 - auc: 0.4831\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 2s 122ms/step - loss: 1.1465 - auc: 0.5035\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 1.1285 - auc: 0.5233\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1507 - auc: 0.4966\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1377 - auc: 0.5098\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 2s 110ms/step - loss: 1.1417 - auc: 0.5011\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 2s 130ms/step - loss: 1.1305 - auc: 0.5026\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 1.1422 - auc: 0.4949\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 2s 123ms/step - loss: 1.1259 - auc: 0.5074\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 2s 130ms/step - loss: 1.1299 - auc: 0.4944\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 2s 109ms/step - loss: 1.1369 - auc: 0.4832\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.1306 - auc: 0.4927\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 2s 128ms/step - loss: 1.1154 - auc: 0.5161\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 2s 101ms/step - loss: 1.1357 - auc: 0.4994\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 2s 99ms/step - loss: 1.1261 - auc: 0.4955\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 2s 132ms/step - loss: 1.1301 - auc: 0.5047\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 2s 129ms/step - loss: 1.1159 - auc: 0.5187\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.1380 - auc: 0.4704\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 1.1146 - auc: 0.5157\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 2s 126ms/step - loss: 1.1181 - auc: 0.5044\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 2s 123ms/step - loss: 1.1277 - auc: 0.4894\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 1.1245 - auc: 0.4963\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 2s 125ms/step - loss: 1.1175 - auc: 0.4917\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 2s 127ms/step - loss: 1.1072 - auc: 0.5220\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 2s 102ms/step - loss: 1.1055 - auc: 0.5202\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1091 - auc: 0.5152\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 2s 132ms/step - loss: 1.1174 - auc: 0.5015\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 2s 125ms/step - loss: 1.1192 - auc: 0.4927\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 1.1228 - auc: 0.4746\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 2s 117ms/step - loss: 1.1070 - auc: 0.5085\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 2s 128ms/step - loss: 1.1204 - auc: 0.4810\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 2s 125ms/step - loss: 1.1063 - auc: 0.5091\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 2s 111ms/step - loss: 1.1085 - auc: 0.5093\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 2s 123ms/step - loss: 1.1109 - auc: 0.4972\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 2s 125ms/step - loss: 1.1164 - auc: 0.4757\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 1.1093 - auc: 0.4990\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 2s 122ms/step - loss: 1.1127 - auc: 0.4817\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 13s 114ms/step - loss: 6.4829 - auc: 0.4650\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 1s 164ms/step - loss: 6.2536 - auc: 0.5169\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 6.1255 - auc: 0.5787\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 6.1091 - auc: 0.5716\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 1s 165ms/step - loss: 6.0371 - auc: 0.5917\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 6.0217 - auc: 0.5757\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 5.9219 - auc: 0.6054\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 5.9672 - auc: 0.5811\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 5.9162 - auc: 0.5944\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 1s 159ms/step - loss: 5.9126 - auc: 0.5918\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 1s 106ms/step - loss: 5.8749 - auc: 0.6076\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 5.8568 - auc: 0.6158\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 5.8759 - auc: 0.5941\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 5.7715 - auc: 0.6248\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 1s 153ms/step - loss: 5.7893 - auc: 0.6098\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 5.8026 - auc: 0.6111\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 1s 137ms/step - loss: 5.7338 - auc: 0.6271\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 5.7390 - auc: 0.6190\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 5.7216 - auc: 0.6222\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 1s 152ms/step - loss: 5.7664 - auc: 0.6095\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 5.6543 - auc: 0.6373\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 5.6779 - auc: 0.6142\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 5.6701 - auc: 0.6125\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 5.6679 - auc: 0.6168\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 5.6647 - auc: 0.6172\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 5.6455 - auc: 0.6118\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 1s 150ms/step - loss: 5.6234 - auc: 0.6168\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 5.6021 - auc: 0.6134\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 5.5858 - auc: 0.6145\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 5.5601 - auc: 0.6114\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 1s 179ms/step - loss: 5.4932 - auc: 0.6494\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 5.4949 - auc: 0.6415\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 5.5057 - auc: 0.6241\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 1s 175ms/step - loss: 5.4449 - auc: 0.6464\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 5.4672 - auc: 0.6362\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 1s 137ms/step - loss: 5.3889 - auc: 0.6601\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 1s 137ms/step - loss: 5.4416 - auc: 0.6464\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 5.4054 - auc: 0.6395\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 5.3911 - auc: 0.6496\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 5.3383 - auc: 0.6673\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 5.3522 - auc: 0.6638\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 5.3432 - auc: 0.6660\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 5.3273 - auc: 0.6591\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 5.3420 - auc: 0.6361\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 1s 170ms/step - loss: 5.2764 - auc: 0.6667\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 5.2887 - auc: 0.6476\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 5.2620 - auc: 0.6578\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 5.2724 - auc: 0.6460\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 5.3160 - auc: 0.6225\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 5.2561 - auc: 0.6417\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 5.2347 - auc: 0.6441\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 5.1917 - auc: 0.6518\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 5.1983 - auc: 0.6452\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 5.1633 - auc: 0.6526\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 1s 160ms/step - loss: 5.1469 - auc: 0.6633\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 5.1474 - auc: 0.6473\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 5.1350 - auc: 0.6528\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 5.1146 - auc: 0.6600\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 5.0799 - auc: 0.6696\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 5.0886 - auc: 0.6582\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 5.0573 - auc: 0.6592\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 5.0538 - auc: 0.6607\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 1s 134ms/step - loss: 5.0692 - auc: 0.6495\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 5.0547 - auc: 0.6318\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 5.0241 - auc: 0.6560\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 4.9795 - auc: 0.6738\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 1s 109ms/step - loss: 4.9745 - auc: 0.6652\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 4.9714 - auc: 0.6707\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 4.9684 - auc: 0.6654\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 1s 148ms/step - loss: 4.9409 - auc: 0.6678\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 4.9476 - auc: 0.6471\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 4.9162 - auc: 0.6555\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 4.9232 - auc: 0.6540\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 4.8578 - auc: 0.6736\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 4.8728 - auc: 0.6637\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 4.8750 - auc: 0.6558\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 4.8656 - auc: 0.6522\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 4.8235 - auc: 0.6587\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 4.8018 - auc: 0.6621\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 4.7761 - auc: 0.6889\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 4.7646 - auc: 0.6842\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 4.7582 - auc: 0.6771\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 4.7634 - auc: 0.6685\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 4.7296 - auc: 0.6805\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 4.7284 - auc: 0.6766\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 4.7100 - auc: 0.6789\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 1s 172ms/step - loss: 4.7236 - auc: 0.6694\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 4.6939 - auc: 0.6775\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 4.6691 - auc: 0.6782\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 4.6217 - auc: 0.7032\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 1s 109ms/step - loss: 4.6526 - auc: 0.6739\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 1s 128ms/step - loss: 4.6334 - auc: 0.6692\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 4.6275 - auc: 0.6757\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 4.5870 - auc: 0.6947\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 4.5938 - auc: 0.6822\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 4.5804 - auc: 0.6774\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 4.5764 - auc: 0.6791\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 1s 138ms/step - loss: 4.5482 - auc: 0.6850\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 4.5324 - auc: 0.6870\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 4.5331 - auc: 0.6792\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 25s 2s/step - loss: 32.2765 - auc: 0.5206\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 29.7986 - auc: 0.5652\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.0247 - auc: 0.5140\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.4387 - auc: 0.5138\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.7369 - auc: 0.5204\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 31.0126 - auc: 0.5225\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 31.0452 - auc: 0.5348\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 31.1322 - auc: 0.5075\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 31.1434 - auc: 0.5043\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 31.1305 - auc: 0.5152\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 31.1001 - auc: 0.5476\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 31.0956 - auc: 0.5548\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 31.1429 - auc: 0.5052\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 31.0974 - auc: 0.5359\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 31.1094 - auc: 0.5282\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 31.0625 - auc: 0.5552\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 31.0726 - auc: 0.5426\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 31.0540 - auc: 0.5507\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 31.0455 - auc: 0.5504\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 31.0470 - auc: 0.5334\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 31.0291 - auc: 0.5420\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 31.0368 - auc: 0.5313\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 31.0166 - auc: 0.5480\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 31.0219 - auc: 0.5315\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 31.0108 - auc: 0.5368\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.9996 - auc: 0.5479\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.9879 - auc: 0.5529\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.9902 - auc: 0.5350\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.9807 - auc: 0.5428\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.9647 - auc: 0.5648\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 15s 2s/step - loss: 30.9660 - auc: 0.5443\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.9520 - auc: 0.5556\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.9406 - auc: 0.5621\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.9508 - auc: 0.5466\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.9360 - auc: 0.5556\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.9128 - auc: 0.5767\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.9214 - auc: 0.5568\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.9200 - auc: 0.5503\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.9060 - auc: 0.5528\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.8865 - auc: 0.5732\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.8914 - auc: 0.5589\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.8841 - auc: 0.5645\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.8743 - auc: 0.5725\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.8752 - auc: 0.5576\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.8651 - auc: 0.5620\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.8578 - auc: 0.5702\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.8568 - auc: 0.5599\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.8512 - auc: 0.5446\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.8395 - auc: 0.5540\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.8424 - auc: 0.5431\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.8289 - auc: 0.5492\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.8189 - auc: 0.5572\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.8068 - auc: 0.5711\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.7977 - auc: 0.5693\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.7920 - auc: 0.5693\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.7977 - auc: 0.5512\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.7792 - auc: 0.5670\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.7797 - auc: 0.5549\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.7714 - auc: 0.5580\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.7509 - auc: 0.5754\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.7591 - auc: 0.5541\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.7343 - auc: 0.5802\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.7389 - auc: 0.5653\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.7238 - auc: 0.5733\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.7275 - auc: 0.5489\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.7164 - auc: 0.5598\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.7160 - auc: 0.5500\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.6965 - auc: 0.5661\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.6958 - auc: 0.5564\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.6848 - auc: 0.5622\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.6641 - auc: 0.5827\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.6621 - auc: 0.5813\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.6538 - auc: 0.5753\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.6563 - auc: 0.5575\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.6447 - auc: 0.5605\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.6422 - auc: 0.5559\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.6237 - auc: 0.5699\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.6138 - auc: 0.5697\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.6058 - auc: 0.5832\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.6012 - auc: 0.5711\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.5955 - auc: 0.5681\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 14s 2s/step - loss: 30.5823 - auc: 0.5725\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.5786 - auc: 0.5653\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.5654 - auc: 0.5715\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.5577 - auc: 0.5718\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.5683 - auc: 0.5351\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.5336 - auc: 0.5832\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.5250 - auc: 0.5814\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.5294 - auc: 0.5592\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.5159 - auc: 0.5728\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.4924 - auc: 0.6005\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.5016 - auc: 0.5666\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.4869 - auc: 0.5738\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.4706 - auc: 0.5846\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.4666 - auc: 0.5775\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.4787 - auc: 0.5504\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.4550 - auc: 0.5709\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.4396 - auc: 0.5750\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.4454 - auc: 0.5534\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.4260 - auc: 0.5713\n"
     ]
    }
   ],
   "source": [
    "with open('lstm_classifier/best_seeds.json', 'r') as f:\n",
    "    best_seeds = json.load(f)\n",
    "\n",
    "# 21 Crear y entrenar los modelos con los hiperparámetros y semillas guardados\n",
    "models = []\n",
    "for params_str, seed in best_seeds.items():\n",
    "    params = json.loads(params_str.replace(\"'\", \"\\\"\"))\n",
    "    model = KerasClassifier(build_fn=create_model, random_state=seed, **params)\n",
    "    # model.fit(X, y_one_hot)\n",
    "    model.fit(X_scaled, y_one_hot)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "30/30 [==============================] - 21s 501ms/step - loss: 7.2453 - auc: 0.5082\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 15s 504ms/step - loss: 12.2811 - auc: 0.5037\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 16s 519ms/step - loss: 13.8851 - auc: 0.4929\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 15s 516ms/step - loss: 14.0358 - auc: 0.5099\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 17s 584ms/step - loss: 13.8374 - auc: 0.4986\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 15s 486ms/step - loss: 13.4653 - auc: 0.5140\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 16s 521ms/step - loss: 13.2361 - auc: 0.4927\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 15s 513ms/step - loss: 12.9652 - auc: 0.4889\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 16s 528ms/step - loss: 12.6287 - auc: 0.5154\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 16s 517ms/step - loss: 12.3148 - auc: 0.5032\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 16s 533ms/step - loss: 12.1154 - auc: 0.5164\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 16s 531ms/step - loss: 11.9852 - auc: 0.5001\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 16s 523ms/step - loss: 11.8287 - auc: 0.4799\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 15s 515ms/step - loss: 11.6688 - auc: 0.4711\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 16s 521ms/step - loss: 11.3560 - auc: 0.5089\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 16s 522ms/step - loss: 11.1409 - auc: 0.5282\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 15s 509ms/step - loss: 10.9963 - auc: 0.5046\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 16s 527ms/step - loss: 10.7727 - auc: 0.5306\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 16s 524ms/step - loss: 10.6704 - auc: 0.5145\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 15s 503ms/step - loss: 10.4998 - auc: 0.4970\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 16s 515ms/step - loss: 10.3194 - auc: 0.5281\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 16s 544ms/step - loss: 10.1935 - auc: 0.5151\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 16s 528ms/step - loss: 10.0498 - auc: 0.5016\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 15s 508ms/step - loss: 9.8974 - auc: 0.5095\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 17s 574ms/step - loss: 9.7719 - auc: 0.5079\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 16s 523ms/step - loss: 9.6674 - auc: 0.5057\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 16s 529ms/step - loss: 9.5542 - auc: 0.5079\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 16s 518ms/step - loss: 9.4214 - auc: 0.5106\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 15s 505ms/step - loss: 9.2911 - auc: 0.5521\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 15s 517ms/step - loss: 9.2035 - auc: 0.4936\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 16s 550ms/step - loss: 9.0990 - auc: 0.5302\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 16s 532ms/step - loss: 33.6961 - auc: 0.4898\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 16s 520ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 16s 541ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 16s 533ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 15s 510ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 15s 512ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 16s 521ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 15s 516ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 16s 522ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 16s 538ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 16s 530ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 16s 533ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 17s 583ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 14s 478ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 15s 514ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 16s 531ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 15s 510ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 16s 525ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 16s 538ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 16s 527ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 16s 516ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 15s 513ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 16s 532ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 16s 522ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 15s 497ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 15s 515ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 15s 490ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 15s 517ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 15s 516ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 16s 546ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 16s 522ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 16s 544ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 17s 583ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 17s 546ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 15s 496ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 14s 472ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 15s 487ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 15s 486ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 15s 487ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 14s 478ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 14s 481ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 14s 483ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 15s 491ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 14s 478ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 14s 477ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 14s 482ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 15s 485ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 14s 478ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 15s 485ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 14s 480ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 15s 485ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 15s 495ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 16s 539ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 14s 482ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 15s 485ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 14s 479ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 15s 488ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 14s 480ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 14s 475ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 14s 479ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 14s 476ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 14s 469ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 14s 473ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 15s 492ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 14s 476ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 14s 470ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 14s 476ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 14s 479ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 14s 475ms/step - loss: nan - auc: 0.0000e+00\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 33s 763ms/step - loss: 11.9903 - auc: 0.4912\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 23s 759ms/step - loss: 19.1438 - auc: 0.5047\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 24s 803ms/step - loss: 19.4157 - auc: 0.5299\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 23s 755ms/step - loss: 19.0381 - auc: 0.4880\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 22s 735ms/step - loss: 18.5463 - auc: 0.5206\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 23s 749ms/step - loss: 18.4763 - auc: 0.4986\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 22s 750ms/step - loss: 18.3330 - auc: 0.4914\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 23s 752ms/step - loss: 17.9269 - auc: 0.5120\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 22s 742ms/step - loss: 17.5221 - auc: 0.5112\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 23s 759ms/step - loss: 17.1913 - auc: 0.5036\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 12s 107ms/step - loss: 25.0019 - auc: 0.5410\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 8.1376 - auc: 0.5300\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 3.0527 - auc: 0.5317\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 2s 106ms/step - loss: 1.7779 - auc: 0.5154\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 2s 103ms/step - loss: 1.3784 - auc: 0.5373\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 2s 104ms/step - loss: 1.2590 - auc: 0.4753\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 2s 126ms/step - loss: 1.3137 - auc: 0.4872\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 2s 116ms/step - loss: 1.3235 - auc: 0.5165\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 1.2234 - auc: 0.4682\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 1.1923 - auc: 0.4972\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 2s 114ms/step - loss: 1.1541 - auc: 0.5120\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 2s 100ms/step - loss: 1.1513 - auc: 0.5048\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.1318 - auc: 0.5241\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 2s 104ms/step - loss: 1.1664 - auc: 0.4831\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 1s 94ms/step - loss: 1.1465 - auc: 0.5035\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.1285 - auc: 0.5233\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 2s 107ms/step - loss: 1.1507 - auc: 0.4966\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 2s 108ms/step - loss: 1.1377 - auc: 0.5098\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 1s 95ms/step - loss: 1.1417 - auc: 0.5011\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 1s 95ms/step - loss: 1.1305 - auc: 0.5026\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 2s 103ms/step - loss: 1.1422 - auc: 0.4949\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.1259 - auc: 0.5074\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.1299 - auc: 0.4944\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 1s 96ms/step - loss: 1.1369 - auc: 0.4832\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 2s 123ms/step - loss: 1.1306 - auc: 0.4927\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 1s 96ms/step - loss: 1.1154 - auc: 0.5161\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.1357 - auc: 0.4994\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 2s 104ms/step - loss: 1.1261 - auc: 0.4955\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.1301 - auc: 0.5047\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.1159 - auc: 0.5187\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 1s 96ms/step - loss: 1.1380 - auc: 0.4704\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 2s 104ms/step - loss: 1.1146 - auc: 0.5157\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.1181 - auc: 0.5044\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 2s 115ms/step - loss: 1.1277 - auc: 0.4894\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 2s 103ms/step - loss: 1.1245 - auc: 0.4963\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.1175 - auc: 0.4917\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.1072 - auc: 0.5220\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 2s 102ms/step - loss: 1.1055 - auc: 0.5202\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 1s 96ms/step - loss: 1.1091 - auc: 0.5152\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 1s 96ms/step - loss: 1.1174 - auc: 0.5015\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.1192 - auc: 0.4927\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 2s 103ms/step - loss: 1.1228 - auc: 0.4746\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 2s 112ms/step - loss: 1.1070 - auc: 0.5085\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 1s 96ms/step - loss: 1.1204 - auc: 0.4810\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.1063 - auc: 0.5091\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 2s 100ms/step - loss: 1.1085 - auc: 0.5093\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 1.1109 - auc: 0.4972\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.1164 - auc: 0.4757\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 2s 103ms/step - loss: 1.1093 - auc: 0.4990\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 1s 97ms/step - loss: 1.1127 - auc: 0.4817\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 12s 107ms/step - loss: 6.4829 - auc: 0.4650\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 6.2536 - auc: 0.5169\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 6.1255 - auc: 0.5787\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 6.1091 - auc: 0.5716\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 6.0371 - auc: 0.5917\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 6.0217 - auc: 0.5757\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 5.9219 - auc: 0.6054\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 5.9672 - auc: 0.5811\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 5.9162 - auc: 0.5944\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 5.9126 - auc: 0.5918\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 5.8749 - auc: 0.6076\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 5.8568 - auc: 0.6158\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 5.8759 - auc: 0.5941\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 1s 154ms/step - loss: 5.7715 - auc: 0.6248\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 1s 106ms/step - loss: 5.7893 - auc: 0.6098\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 5.8026 - auc: 0.6111\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 5.7338 - auc: 0.6271\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 5.7390 - auc: 0.6190\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 5.7216 - auc: 0.6222\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 5.7664 - auc: 0.6095\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 5.6543 - auc: 0.6373\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 5.6779 - auc: 0.6142\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 5.6701 - auc: 0.6125\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 5.6679 - auc: 0.6168\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 5.6647 - auc: 0.6172\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 5.6455 - auc: 0.6118\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 5.6234 - auc: 0.6168\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 5.6021 - auc: 0.6134\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 5.5858 - auc: 0.6145\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 1s 106ms/step - loss: 5.5601 - auc: 0.6114\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 5.4932 - auc: 0.6494\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 5.4949 - auc: 0.6415\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 5.5057 - auc: 0.6241\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 5.4449 - auc: 0.6464\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 5.4672 - auc: 0.6362\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 1s 109ms/step - loss: 5.3889 - auc: 0.6601\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 5.4416 - auc: 0.6464\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 5.4054 - auc: 0.6395\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 5.3911 - auc: 0.6496\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 5.3383 - auc: 0.6673\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 5.3522 - auc: 0.6638\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 5.3432 - auc: 0.6660\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 2s 270ms/step - loss: 5.3273 - auc: 0.6591\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 5.3420 - auc: 0.6361\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 5.2764 - auc: 0.6667\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 5.2887 - auc: 0.6476\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 5.2620 - auc: 0.6578\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 5.2724 - auc: 0.6460\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 5.3160 - auc: 0.6225\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 5.2561 - auc: 0.6417\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 5.2347 - auc: 0.6441\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 5.1917 - auc: 0.6518\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 1s 128ms/step - loss: 5.1983 - auc: 0.6452\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 5.1633 - auc: 0.6526\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 5.1469 - auc: 0.6633\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 5.1474 - auc: 0.6473\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 5.1350 - auc: 0.6528\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 5.1146 - auc: 0.6600\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 5.0799 - auc: 0.6696\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 1s 106ms/step - loss: 5.0886 - auc: 0.6582\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 5.0573 - auc: 0.6592\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 5.0538 - auc: 0.6607\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 5.0692 - auc: 0.6495\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 5.0547 - auc: 0.6318\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 5.0241 - auc: 0.6560\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 4.9795 - auc: 0.6738\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 4.9745 - auc: 0.6652\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 4.9714 - auc: 0.6707\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 4.9684 - auc: 0.6654\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 4.9409 - auc: 0.6678\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 4.9476 - auc: 0.6471\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 4.9162 - auc: 0.6555\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 4.9232 - auc: 0.6540\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 4.8578 - auc: 0.6736\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 4.8728 - auc: 0.6637\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 4.8750 - auc: 0.6558\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 4.8656 - auc: 0.6522\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 4.8235 - auc: 0.6587\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 4.8018 - auc: 0.6621\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 4.7761 - auc: 0.6889\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 4.7646 - auc: 0.6842\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 4.7582 - auc: 0.6771\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 1s 138ms/step - loss: 4.7634 - auc: 0.6685\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 4.7296 - auc: 0.6805\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 4.7284 - auc: 0.6766\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 4.7100 - auc: 0.6789\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 4.7236 - auc: 0.6694\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 4.6939 - auc: 0.6775\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 4.6691 - auc: 0.6782\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 4.6217 - auc: 0.7032\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 4.6526 - auc: 0.6739\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 4.6334 - auc: 0.6692\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 4.6275 - auc: 0.6757\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 4.5870 - auc: 0.6947\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 4.5938 - auc: 0.6822\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 4.5804 - auc: 0.6774\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 4.5764 - auc: 0.6791\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 4.5482 - auc: 0.6850\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 4.5324 - auc: 0.6870\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 4.5331 - auc: 0.6792\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 20s 1s/step - loss: 32.2765 - auc: 0.5206\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 29.7986 - auc: 0.5652\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.0247 - auc: 0.5140\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.4387 - auc: 0.5138\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.7369 - auc: 0.5204\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 31.0126 - auc: 0.5225\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 31.0452 - auc: 0.5348\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 31.1322 - auc: 0.5075\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 31.1434 - auc: 0.5043\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 31.1305 - auc: 0.5152\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 31.1001 - auc: 0.5476\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 31.0956 - auc: 0.5548\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 31.1429 - auc: 0.5052\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 31.0974 - auc: 0.5359\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 31.1094 - auc: 0.5282\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 31.0625 - auc: 0.5552\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 31.0726 - auc: 0.5426\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 31.0540 - auc: 0.5507\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 31.0455 - auc: 0.5504\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 31.0470 - auc: 0.5334\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 31.0291 - auc: 0.5420\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 31.0368 - auc: 0.5313\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 31.0166 - auc: 0.5480\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 31.0219 - auc: 0.5315\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 31.0108 - auc: 0.5368\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.9996 - auc: 0.5479\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.9879 - auc: 0.5529\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.9902 - auc: 0.5350\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.9807 - auc: 0.5428\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.9647 - auc: 0.5648\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.9660 - auc: 0.5443\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.9520 - auc: 0.5556\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.9406 - auc: 0.5621\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.9508 - auc: 0.5466\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.9360 - auc: 0.5556\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.9128 - auc: 0.5767\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.9214 - auc: 0.5568\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.9200 - auc: 0.5503\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.9060 - auc: 0.5528\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.8865 - auc: 0.5732\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.8914 - auc: 0.5589\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.8841 - auc: 0.5645\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.8743 - auc: 0.5725\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.8752 - auc: 0.5576\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.8651 - auc: 0.5620\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.8578 - auc: 0.5702\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.8568 - auc: 0.5599\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.8512 - auc: 0.5446\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 12s 2s/step - loss: 30.8395 - auc: 0.5540\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.8424 - auc: 0.5431\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.8289 - auc: 0.5492\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.8189 - auc: 0.5572\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.8068 - auc: 0.5711\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.7977 - auc: 0.5693\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.7920 - auc: 0.5693\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.7977 - auc: 0.5512\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.7792 - auc: 0.5670\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.7797 - auc: 0.5549\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.7714 - auc: 0.5580\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.7509 - auc: 0.5754\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.7591 - auc: 0.5541\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.7343 - auc: 0.5802\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.7389 - auc: 0.5653\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.7238 - auc: 0.5733\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.7275 - auc: 0.5489\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.7164 - auc: 0.5598\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.7160 - auc: 0.5500\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.6965 - auc: 0.5661\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.6958 - auc: 0.5564\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.6848 - auc: 0.5622\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.6641 - auc: 0.5827\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.6621 - auc: 0.5813\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.6538 - auc: 0.5753\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.6563 - auc: 0.5575\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.6447 - auc: 0.5605\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 13s 2s/step - loss: 30.6422 - auc: 0.5559\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.6237 - auc: 0.5699\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.6138 - auc: 0.5697\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.6058 - auc: 0.5832\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.6012 - auc: 0.5711\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.5955 - auc: 0.5681\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.5823 - auc: 0.5725\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.5786 - auc: 0.5653\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.5654 - auc: 0.5715\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.5577 - auc: 0.5718\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.5683 - auc: 0.5351\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.5336 - auc: 0.5832\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 12s 1s/step - loss: 30.5250 - auc: 0.5814\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.5294 - auc: 0.5592\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.5159 - auc: 0.5728\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.4924 - auc: 0.6005\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.5016 - auc: 0.5666\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.4869 - auc: 0.5738\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.4706 - auc: 0.5846\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.4666 - auc: 0.5775\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.4787 - auc: 0.5504\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.4550 - auc: 0.5709\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.4396 - auc: 0.5750\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.4454 - auc: 0.5534\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 11s 1s/step - loss: 30.4260 - auc: 0.5713\n"
     ]
    }
   ],
   "source": [
    "ensemble = MultivariableVotingClassifier(models)\n",
    "# ensemble.fit(X, y_one_hot)\n",
    "ensemble.fit(X_scaled, y_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datos originales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open_time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Number of trades</th>\n",
       "      <th>Close_BTCUSDT</th>\n",
       "      <th>Volume_BTCUSDT</th>\n",
       "      <th>Number_of_trades_BTCUSDT</th>\n",
       "      <th>Close_ETHUSDT</th>\n",
       "      <th>Volume_ETHUSDT</th>\n",
       "      <th>Number_of_trades_ETHUSDT</th>\n",
       "      <th>Close_BNBUSDT</th>\n",
       "      <th>Volume_BNBUSDT</th>\n",
       "      <th>Number_of_trades_BNBUSDT</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>Upper_Band</th>\n",
       "      <th>Middle_Band</th>\n",
       "      <th>Lower_Band</th>\n",
       "      <th>RSI</th>\n",
       "      <th>buy_1000x_high_coinbase</th>\n",
       "      <th>sell_1000x_high_coinbase</th>\n",
       "      <th>total_trades_coinbase</th>\n",
       "      <th>Tweets_Utilizados</th>\n",
       "      <th>Tweets_Utilizados_coin</th>\n",
       "      <th>Tweets_Utilizados_referentes</th>\n",
       "      <th>Tweets_Utilizados_whale_alert</th>\n",
       "      <th>Buy_1000x_high</th>\n",
       "      <th>sell_1000x_high</th>\n",
       "      <th>total_trades_binance</th>\n",
       "      <th>Tendencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>6.59</td>\n",
       "      <td>6.67</td>\n",
       "      <td>6.04</td>\n",
       "      <td>115512.00</td>\n",
       "      <td>60672.00</td>\n",
       "      <td>54947.66</td>\n",
       "      <td>1985671.00</td>\n",
       "      <td>3014.05</td>\n",
       "      <td>561717.49</td>\n",
       "      <td>1292873.00</td>\n",
       "      <td>578.40</td>\n",
       "      <td>766513.45</td>\n",
       "      <td>486465.00</td>\n",
       "      <td>6.93</td>\n",
       "      <td>7.13</td>\n",
       "      <td>7.80</td>\n",
       "      <td>6.93</td>\n",
       "      <td>6.05</td>\n",
       "      <td>34.18</td>\n",
       "      <td>51.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>48709.00</td>\n",
       "      <td>142</td>\n",
       "      <td>187</td>\n",
       "      <td>1.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>379.00</td>\n",
       "      <td>377.00</td>\n",
       "      <td>70000.00</td>\n",
       "      <td>Bajista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>6.42</td>\n",
       "      <td>6.93</td>\n",
       "      <td>6.13</td>\n",
       "      <td>175570.00</td>\n",
       "      <td>58364.97</td>\n",
       "      <td>81166.47</td>\n",
       "      <td>2401089.00</td>\n",
       "      <td>2972.46</td>\n",
       "      <td>624963.78</td>\n",
       "      <td>1365039.00</td>\n",
       "      <td>561.80</td>\n",
       "      <td>669027.32</td>\n",
       "      <td>427425.00</td>\n",
       "      <td>6.85</td>\n",
       "      <td>7.11</td>\n",
       "      <td>7.41</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.29</td>\n",
       "      <td>43.30</td>\n",
       "      <td>42.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>83718.00</td>\n",
       "      <td>130</td>\n",
       "      <td>177</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36.00</td>\n",
       "      <td>327.00</td>\n",
       "      <td>340.00</td>\n",
       "      <td>107000.00</td>\n",
       "      <td>Alcista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>6.90</td>\n",
       "      <td>7.41</td>\n",
       "      <td>6.69</td>\n",
       "      <td>109002.00</td>\n",
       "      <td>59060.61</td>\n",
       "      <td>47583.82</td>\n",
       "      <td>1572898.00</td>\n",
       "      <td>2986.19</td>\n",
       "      <td>365939.72</td>\n",
       "      <td>880167.00</td>\n",
       "      <td>560.50</td>\n",
       "      <td>359794.32</td>\n",
       "      <td>250921.00</td>\n",
       "      <td>6.85</td>\n",
       "      <td>7.12</td>\n",
       "      <td>7.42</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.29</td>\n",
       "      <td>49.27</td>\n",
       "      <td>87.00</td>\n",
       "      <td>57.00</td>\n",
       "      <td>61208.00</td>\n",
       "      <td>461</td>\n",
       "      <td>374</td>\n",
       "      <td>1.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>270.00</td>\n",
       "      <td>282.00</td>\n",
       "      <td>71000.00</td>\n",
       "      <td>Alcista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>7.27</td>\n",
       "      <td>7.39</td>\n",
       "      <td>7.00</td>\n",
       "      <td>109634.00</td>\n",
       "      <td>62882.01</td>\n",
       "      <td>43628.40</td>\n",
       "      <td>1558661.00</td>\n",
       "      <td>3102.61</td>\n",
       "      <td>355825.84</td>\n",
       "      <td>859542.00</td>\n",
       "      <td>587.00</td>\n",
       "      <td>342906.43</td>\n",
       "      <td>257575.00</td>\n",
       "      <td>6.90</td>\n",
       "      <td>7.14</td>\n",
       "      <td>7.44</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.35</td>\n",
       "      <td>48.86</td>\n",
       "      <td>52.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>46255.00</td>\n",
       "      <td>573</td>\n",
       "      <td>474</td>\n",
       "      <td>1.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>386.00</td>\n",
       "      <td>635.00</td>\n",
       "      <td>69000.00</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>2024-05-04</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.28</td>\n",
       "      <td>7.11</td>\n",
       "      <td>71120.00</td>\n",
       "      <td>63892.04</td>\n",
       "      <td>24368.69</td>\n",
       "      <td>1113509.00</td>\n",
       "      <td>3117.23</td>\n",
       "      <td>196263.95</td>\n",
       "      <td>575026.00</td>\n",
       "      <td>585.70</td>\n",
       "      <td>197129.25</td>\n",
       "      <td>210303.00</td>\n",
       "      <td>6.91</td>\n",
       "      <td>7.13</td>\n",
       "      <td>7.46</td>\n",
       "      <td>6.91</td>\n",
       "      <td>6.36</td>\n",
       "      <td>46.98</td>\n",
       "      <td>68.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>34251.00</td>\n",
       "      <td>407</td>\n",
       "      <td>472</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>203.00</td>\n",
       "      <td>232.00</td>\n",
       "      <td>49000.00</td>\n",
       "      <td>Bajista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>2024-05-05</td>\n",
       "      <td>7.12</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.01</td>\n",
       "      <td>72928.00</td>\n",
       "      <td>64012.00</td>\n",
       "      <td>18526.75</td>\n",
       "      <td>992921.00</td>\n",
       "      <td>3136.41</td>\n",
       "      <td>218760.27</td>\n",
       "      <td>600693.00</td>\n",
       "      <td>592.00</td>\n",
       "      <td>180458.24</td>\n",
       "      <td>180794.00</td>\n",
       "      <td>6.94</td>\n",
       "      <td>7.15</td>\n",
       "      <td>7.51</td>\n",
       "      <td>6.94</td>\n",
       "      <td>6.37</td>\n",
       "      <td>50.00</td>\n",
       "      <td>37.00</td>\n",
       "      <td>52.00</td>\n",
       "      <td>29197.00</td>\n",
       "      <td>417</td>\n",
       "      <td>499</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>320.00</td>\n",
       "      <td>284.00</td>\n",
       "      <td>47000.00</td>\n",
       "      <td>Alcista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>2024-05-06</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.47</td>\n",
       "      <td>7.06</td>\n",
       "      <td>94264.00</td>\n",
       "      <td>63165.19</td>\n",
       "      <td>34674.92</td>\n",
       "      <td>1392557.00</td>\n",
       "      <td>3062.60</td>\n",
       "      <td>355135.30</td>\n",
       "      <td>873200.00</td>\n",
       "      <td>588.20</td>\n",
       "      <td>278669.01</td>\n",
       "      <td>248490.00</td>\n",
       "      <td>6.96</td>\n",
       "      <td>7.15</td>\n",
       "      <td>7.53</td>\n",
       "      <td>6.96</td>\n",
       "      <td>6.39</td>\n",
       "      <td>47.10</td>\n",
       "      <td>49.00</td>\n",
       "      <td>71.00</td>\n",
       "      <td>40027.00</td>\n",
       "      <td>482</td>\n",
       "      <td>531</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>339.00</td>\n",
       "      <td>249.00</td>\n",
       "      <td>59000.00</td>\n",
       "      <td>Bajista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>2024-05-07</td>\n",
       "      <td>7.12</td>\n",
       "      <td>7.29</td>\n",
       "      <td>6.98</td>\n",
       "      <td>64947.00</td>\n",
       "      <td>62312.08</td>\n",
       "      <td>25598.79</td>\n",
       "      <td>1272898.00</td>\n",
       "      <td>3005.69</td>\n",
       "      <td>298796.68</td>\n",
       "      <td>815246.00</td>\n",
       "      <td>576.50</td>\n",
       "      <td>289488.71</td>\n",
       "      <td>266127.00</td>\n",
       "      <td>6.98</td>\n",
       "      <td>7.13</td>\n",
       "      <td>7.52</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.44</td>\n",
       "      <td>45.10</td>\n",
       "      <td>21.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>31028.00</td>\n",
       "      <td>495</td>\n",
       "      <td>494</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>296.00</td>\n",
       "      <td>205.00</td>\n",
       "      <td>42000.00</td>\n",
       "      <td>Bajista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>2024-05-08</td>\n",
       "      <td>6.99</td>\n",
       "      <td>7.19</td>\n",
       "      <td>6.89</td>\n",
       "      <td>75550.00</td>\n",
       "      <td>61193.03</td>\n",
       "      <td>26121.19</td>\n",
       "      <td>1415152.00</td>\n",
       "      <td>2974.21</td>\n",
       "      <td>266934.81</td>\n",
       "      <td>830635.00</td>\n",
       "      <td>588.60</td>\n",
       "      <td>297016.62</td>\n",
       "      <td>249379.00</td>\n",
       "      <td>6.99</td>\n",
       "      <td>7.12</td>\n",
       "      <td>7.52</td>\n",
       "      <td>6.99</td>\n",
       "      <td>6.46</td>\n",
       "      <td>44.94</td>\n",
       "      <td>17.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>32040.00</td>\n",
       "      <td>426</td>\n",
       "      <td>494</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>230.00</td>\n",
       "      <td>177.00</td>\n",
       "      <td>49000.00</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>2024-05-09</td>\n",
       "      <td>6.98</td>\n",
       "      <td>7.09</td>\n",
       "      <td>6.78</td>\n",
       "      <td>75016.00</td>\n",
       "      <td>63074.01</td>\n",
       "      <td>30660.81</td>\n",
       "      <td>1381957.00</td>\n",
       "      <td>3036.23</td>\n",
       "      <td>238561.75</td>\n",
       "      <td>686147.00</td>\n",
       "      <td>596.80</td>\n",
       "      <td>464857.60</td>\n",
       "      <td>332988.00</td>\n",
       "      <td>7.01</td>\n",
       "      <td>7.11</td>\n",
       "      <td>7.52</td>\n",
       "      <td>7.01</td>\n",
       "      <td>6.50</td>\n",
       "      <td>46.32</td>\n",
       "      <td>18.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>29314.00</td>\n",
       "      <td>475</td>\n",
       "      <td>464</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>188.00</td>\n",
       "      <td>257.00</td>\n",
       "      <td>50000.00</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Open_time  Open  High  Low  Number of trades  Close_BTCUSDT  \\\n",
       "946 2024-04-30  6.59  6.67 6.04         115512.00       60672.00   \n",
       "947 2024-05-01  6.42  6.93 6.13         175570.00       58364.97   \n",
       "948 2024-05-02  6.90  7.41 6.69         109002.00       59060.61   \n",
       "949 2024-05-03  7.27  7.39 7.00         109634.00       62882.01   \n",
       "950 2024-05-04  7.24  7.28 7.11          71120.00       63892.04   \n",
       "951 2024-05-05  7.12  7.40 7.01          72928.00       64012.00   \n",
       "952 2024-05-06  7.30  7.47 7.06          94264.00       63165.19   \n",
       "953 2024-05-07  7.12  7.29 6.98          64947.00       62312.08   \n",
       "954 2024-05-08  6.99  7.19 6.89          75550.00       61193.03   \n",
       "955 2024-05-09  6.98  7.09 6.78          75016.00       63074.01   \n",
       "\n",
       "     Volume_BTCUSDT  Number_of_trades_BTCUSDT  Close_ETHUSDT  Volume_ETHUSDT  \\\n",
       "946        54947.66                1985671.00        3014.05       561717.49   \n",
       "947        81166.47                2401089.00        2972.46       624963.78   \n",
       "948        47583.82                1572898.00        2986.19       365939.72   \n",
       "949        43628.40                1558661.00        3102.61       355825.84   \n",
       "950        24368.69                1113509.00        3117.23       196263.95   \n",
       "951        18526.75                 992921.00        3136.41       218760.27   \n",
       "952        34674.92                1392557.00        3062.60       355135.30   \n",
       "953        25598.79                1272898.00        3005.69       298796.68   \n",
       "954        26121.19                1415152.00        2974.21       266934.81   \n",
       "955        30660.81                1381957.00        3036.23       238561.75   \n",
       "\n",
       "     Number_of_trades_ETHUSDT  Close_BNBUSDT  Volume_BNBUSDT  \\\n",
       "946                1292873.00         578.40       766513.45   \n",
       "947                1365039.00         561.80       669027.32   \n",
       "948                 880167.00         560.50       359794.32   \n",
       "949                 859542.00         587.00       342906.43   \n",
       "950                 575026.00         585.70       197129.25   \n",
       "951                 600693.00         592.00       180458.24   \n",
       "952                 873200.00         588.20       278669.01   \n",
       "953                 815246.00         576.50       289488.71   \n",
       "954                 830635.00         588.60       297016.62   \n",
       "955                 686147.00         596.80       464857.60   \n",
       "\n",
       "     Number_of_trades_BNBUSDT  SMA_20  EMA_20  Upper_Band  Middle_Band  \\\n",
       "946                 486465.00    6.93    7.13        7.80         6.93   \n",
       "947                 427425.00    6.85    7.11        7.41         6.85   \n",
       "948                 250921.00    6.85    7.12        7.42         6.85   \n",
       "949                 257575.00    6.90    7.14        7.44         6.90   \n",
       "950                 210303.00    6.91    7.13        7.46         6.91   \n",
       "951                 180794.00    6.94    7.15        7.51         6.94   \n",
       "952                 248490.00    6.96    7.15        7.53         6.96   \n",
       "953                 266127.00    6.98    7.13        7.52         6.98   \n",
       "954                 249379.00    6.99    7.12        7.52         6.99   \n",
       "955                 332988.00    7.01    7.11        7.52         7.01   \n",
       "\n",
       "     Lower_Band   RSI  buy_1000x_high_coinbase  sell_1000x_high_coinbase  \\\n",
       "946        6.05 34.18                    51.00                     55.00   \n",
       "947        6.29 43.30                    42.00                     50.00   \n",
       "948        6.29 49.27                    87.00                     57.00   \n",
       "949        6.35 48.86                    52.00                     40.00   \n",
       "950        6.36 46.98                    68.00                     50.00   \n",
       "951        6.37 50.00                    37.00                     52.00   \n",
       "952        6.39 47.10                    49.00                     71.00   \n",
       "953        6.44 45.10                    21.00                     25.00   \n",
       "954        6.46 44.94                    17.00                     24.00   \n",
       "955        6.50 46.32                    18.00                     17.00   \n",
       "\n",
       "     total_trades_coinbase  Tweets_Utilizados  Tweets_Utilizados_coin  \\\n",
       "946               48709.00                142                     187   \n",
       "947               83718.00                130                     177   \n",
       "948               61208.00                461                     374   \n",
       "949               46255.00                573                     474   \n",
       "950               34251.00                407                     472   \n",
       "951               29197.00                417                     499   \n",
       "952               40027.00                482                     531   \n",
       "953               31028.00                495                     494   \n",
       "954               32040.00                426                     494   \n",
       "955               29314.00                475                     464   \n",
       "\n",
       "     Tweets_Utilizados_referentes  Tweets_Utilizados_whale_alert  \\\n",
       "946                          1.00                          23.00   \n",
       "947                          0.00                          36.00   \n",
       "948                          1.00                          25.00   \n",
       "949                          1.00                          22.00   \n",
       "950                          0.00                          14.00   \n",
       "951                          0.00                           6.00   \n",
       "952                          0.00                          25.00   \n",
       "953                          0.00                          28.00   \n",
       "954                          0.00                          24.00   \n",
       "955                          0.00                          16.00   \n",
       "\n",
       "     Buy_1000x_high  sell_1000x_high  total_trades_binance Tendencia  \n",
       "946          379.00           377.00              70000.00   Bajista  \n",
       "947          327.00           340.00             107000.00   Alcista  \n",
       "948          270.00           282.00              71000.00   Alcista  \n",
       "949          386.00           635.00              69000.00   Lateral  \n",
       "950          203.00           232.00              49000.00   Bajista  \n",
       "951          320.00           284.00              47000.00   Alcista  \n",
       "952          339.00           249.00              59000.00   Bajista  \n",
       "953          296.00           205.00              42000.00   Bajista  \n",
       "954          230.00           177.00              49000.00   Lateral  \n",
       "955          188.00           257.00              50000.00   Lateral  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(clasifier_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 694ms/step\n",
      "1/1 [==============================] - 1s 980ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 977ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 2, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['Alcista', 'Bajista', 'Lateral'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Lateral',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_clases = 3 \n",
    "\n",
    "clasifier_validation = clasifier_validation[columns]\n",
    "validation_predictions = ensemble.predict(clasifier_validation.drop(columns=[\"Open_time\"]))\n",
    "predicciones_one_hot = to_categorical(validation_predictions, num_classes=n_clases)\n",
    "etiquetas_numericas = np.argmax(predicciones_one_hot, axis=1)\n",
    "categorias_clases = onehot_encoder.categories_[0]\n",
    "nombres_clases = [categorias_clases[indice] for indice in etiquetas_numericas]\n",
    "\n",
    "display(validation_predictions)\n",
    "display(categorias_clases)\n",
    "display(nombres_clases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datos generados por auto ml con prophet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 0s 172ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 191ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['Alcista', 'Bajista', 'Lateral'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auto_ml_prophet_df = pd.read_csv('auto_timeseries_models_prophet/predicciones.csv')\n",
    "auto_ml_prophet_df = auto_ml_prophet_df[columns]\n",
    "auto_mp_prophet_predictions = ensemble.predict(auto_ml_prophet_df.drop(columns=[\"Open_time\"]))\n",
    "\n",
    "predicciones_one_hot = to_categorical(auto_mp_prophet_predictions, num_classes=n_clases)\n",
    "etiquetas_numericas = np.argmax(predicciones_one_hot, axis=1)\n",
    "categorias_clases = onehot_encoder.categories_[0]\n",
    "nombres_clases = [categorias_clases[indice] for indice in etiquetas_numericas]\n",
    "\n",
    "display(auto_mp_prophet_predictions)\n",
    "display(categorias_clases)\n",
    "display(nombres_clases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datos generados por auto ml con stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 106ms/step\n",
      "1/1 [==============================] - 0s 126ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 139ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['Alcista', 'Bajista', 'Lateral'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auto_ml_stats_df = pd.read_csv('auto_timeseries_models/predicciones.csv')\n",
    "auto_ml_stats_df = auto_ml_stats_df[columns]\n",
    "auto_mp_stats_predictions = ensemble.predict(auto_ml_stats_df.drop(columns=[\"Open_time\"]))\n",
    "\n",
    "predicciones_one_hot = to_categorical(auto_mp_stats_predictions, num_classes=n_clases)\n",
    "etiquetas_numericas = np.argmax(predicciones_one_hot, axis=1)\n",
    "categorias_clases = onehot_encoder.categories_[0]\n",
    "nombres_clases = [categorias_clases[indice] for indice in etiquetas_numericas]\n",
    "\n",
    "display(auto_mp_stats_predictions)\n",
    "display(categorias_clases)\n",
    "display(nombres_clases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datos generados por auto ml con modelos clasicos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 151ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['Alcista', 'Bajista', 'Lateral'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auto_ml_df = pd.read_csv('h2o_models/predicciones.csv')\n",
    "auto_ml_df = auto_ml_df[columns]\n",
    "auto_mp_predictions = ensemble.predict(auto_ml_df.drop(columns=[\"Open_time\"]))\n",
    "\n",
    "predicciones_one_hot = to_categorical(auto_mp_predictions, num_classes=n_clases)\n",
    "etiquetas_numericas = np.argmax(predicciones_one_hot, axis=1)\n",
    "categorias_clases = onehot_encoder.categories_[0]\n",
    "nombres_clases = [categorias_clases[indice] for indice in etiquetas_numericas]\n",
    "\n",
    "display(auto_mp_predictions)\n",
    "display(categorias_clases)\n",
    "display(nombres_clases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datos generados por auto ml con skforecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 165ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['Alcista', 'Bajista', 'Lateral'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista',\n",
       " 'Alcista']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skforecast_df = pd.read_csv('skforecast/predicciones.csv')\n",
    "skforecast_df = skforecast_df[columns[1:]]\n",
    "skforecast_predictions = ensemble.predict(skforecast_df)\n",
    "\n",
    "predicciones_one_hot = to_categorical(skforecast_predictions, num_classes=n_clases)\n",
    "etiquetas_numericas = np.argmax(predicciones_one_hot, axis=1)\n",
    "categorias_clases = onehot_encoder.categories_[0]\n",
    "nombres_clases = [categorias_clases[indice] for indice in etiquetas_numericas]\n",
    "\n",
    "display(skforecast_predictions)\n",
    "display(categorias_clases)\n",
    "display(nombres_clases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizo los features mas importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "# from sklearn.inspection import permutation_importance\n",
    "\n",
    "# feature_importances = pd.DataFrame()\n",
    "\n",
    "# model = models[0]\n",
    "# # Assuming X_test and y_test are your test data\n",
    "# X_test = X  # Replace with your actual test data\n",
    "# y_test = y_one_hot  # Replace with your actual test labels\n",
    "\n",
    "# perm_importance = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42)\n",
    "# feature_importances[f'model_{i}'] = perm_importance.importances_mean\n",
    "\n",
    "# # Calculate the mean importance across all models\n",
    "# feature_importances['mean_importance'] = feature_importances.mean(axis=1)\n",
    "\n",
    "# print(feature_importances)\n",
    "\n",
    "# # Optional: Use SHAP for additional interpretation (example for a Keras model)\n",
    "# explainer = shap.Explainer(models[0], X_test)  # This can be resource-intensive\n",
    "# shap_values = explainer(X_test)\n",
    "# shap.summary_plot(shap_values, X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
