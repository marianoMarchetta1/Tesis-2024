{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/Users/mmarchetta/Desktop/Tesis-2024/data-visualization/final_dataset.csv')\n",
    "dataset1 = pd.read_csv('/Users/mmarchetta/Desktop/Tesis-2024/data-cleaning/final_dataset_first_cleaning.csv')\n",
    "dataset2= pd.read_csv('/Users/mmarchetta/Desktop/Tesis-2024/data-cleaning/final_dataset_cleaned_kbest.csv')\n",
    "dataset3 = pd.read_csv('/Users/mmarchetta/Desktop/Tesis-2024/data-cleaning/final_dataset_cleaned_random_forest_feature_selector.csv')\n",
    "\n",
    "dataset4 = pd.read_csv('/Users/mmarchetta/Desktop/Tesis-2024/data-cleaning/final_dataset_first_cleaning_denormalized.csv')\n",
    "dataset5= pd.read_csv('/Users/mmarchetta/Desktop/Tesis-2024/data-cleaning/final_dataset_cleaned_kbest_denormalized.csv')\n",
    "dataset6 = pd.read_csv('/Users/mmarchetta/Desktop/Tesis-2024/data-cleaning/final_dataset_cleaned_random_forest_feature_selector_denormalized.csv')\n",
    "\n",
    "dataset.drop(['Open_time'], axis=1, inplace=True)\n",
    "dataset.drop(['Sentimiento'], axis=1, inplace=True)\n",
    "dataset.drop(['Sentimiento_coin'], axis=1, inplace=True)\n",
    "dataset.drop(['Sentimiento_referentes'], axis=1, inplace=True)\n",
    "\n",
    "dataset1.drop(['Open_time'], axis=1, inplace=True)\n",
    "dataset2.drop(['Open_time'], axis=1, inplace=True)\n",
    "dataset3.drop(['Open_time'], axis=1, inplace=True)\n",
    "dataset4.drop(['Open_time'], axis=1, inplace=True)\n",
    "dataset5.drop(['Open_time'], axis=1, inplace=True)\n",
    "dataset6.drop(['Open_time'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_logistic_regression(dataset):\n",
    "    # Dividir los datos en conjunto de entrenamiento y conjunto de prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset.drop(columns=[\"Tendencia\"]), \n",
    "                                                        dataset[\"Tendencia\"], \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=42)\n",
    "\n",
    "    # Entrenar un modelo final de Regresión Logística utilizando las características seleccionadas\n",
    "    final_model = LogisticRegression()\n",
    "    final_model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluar el modelo final\n",
    "    accuracy = final_model.score(X_test, y_test)\n",
    "    \n",
    "    y_pred = final_model.predict(X_test)\n",
    "    \n",
    "    # Calcular el F1-score\n",
    "    f1score = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, final_model.predict_proba(X_test), multi_class='ovr')\n",
    "\n",
    "    return accuracy, f1score, roc_auc, final_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_gradient_boosting(dataset):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset.drop(columns=[\"Tendencia\"]), \n",
    "                                                        dataset[\"Tendencia\"], \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=42)\n",
    "\n",
    "    # Crear el clasificador GradientBoostingClassifier\n",
    "    gb_model = GradientBoostingClassifier(\n",
    "        n_estimators=1000,  # Usar 1000 estimadores\n",
    "        learning_rate=0.1,  # Tasa de aprendizaje\n",
    "        max_depth=5,  # Profundidad máxima de cada árbol\n",
    "        min_samples_split=2,  # Número mínimo de muestras requeridas para dividir un nodo interno\n",
    "        min_samples_leaf=1,  # Número mínimo de muestras requeridas para estar en una hoja\n",
    "        subsample=0.8,  # Fracción de muestras a utilizar para ajustar los estimadores base\n",
    "        max_features='sqrt',  # Número máximo de características a considerar al dividir nodos: raíz cuadrada del número de características\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    gb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    accuracy = gb_model.score(X_test, y_test)\n",
    "    \n",
    "    y_pred = gb_model.predict(X_test)\n",
    "    \n",
    "    # Calcular el F1-score\n",
    "    f1score = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, gb_model.predict_proba(X_test), multi_class='ovr')\n",
    "\n",
    "    return accuracy, f1score, roc_auc, gb_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_svm(dataset):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset.drop(columns=[\"Tendencia\"]), \n",
    "                                                        dataset[\"Tendencia\"], \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=42)\n",
    "\n",
    "    # Codificar las etiquetas de destino numéricamente\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "    svc_model = SVC(\n",
    "        kernel='rbf',  # Kernel radial\n",
    "        C=10.0,  # Parámetro de regularización\n",
    "        gamma='scale',  # Coeficiente de kernel para 'rbf'\n",
    "        probability=True,  # Habilitar el cálculo de probabilidades\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    svc_model.fit(X_train, y_train_encoded)\n",
    "\n",
    "    # Predecir las probabilidades de clase\n",
    "    y_prob = svc_model.predict_proba(X_test)\n",
    "\n",
    "    # Calcular el F1-score\n",
    "    f1score = f1_score(y_test_encoded, y_prob.argmax(axis=1), average='weighted')\n",
    "\n",
    "    # Calcular el ROC AUC\n",
    "    roc_auc = roc_auc_score(y_test_encoded, y_prob, multi_class='ovr')\n",
    "\n",
    "    # Calcular la exactitud\n",
    "    accuracy = svc_model.score(X_test, y_test_encoded)\n",
    "\n",
    "    return accuracy, f1score, roc_auc, svc_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_MLP(dataset):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataset.drop(columns=[\"Tendencia\"]), \n",
    "                                                        dataset[\"Tendencia\"], \n",
    "                                                        test_size=0.2, \n",
    "                                                        random_state=42)\n",
    "\n",
    "    mlp_model = MLPClassifier(\n",
    "        hidden_layer_sizes=(100, 50),  # Dos capas ocultas con 100 y 50 neuronas respectivamente\n",
    "        activation='relu',  # Función de activación ReLU\n",
    "        solver='adam',  # Optimizador Adam\n",
    "        alpha=0.0001,  # Tasa de regularización L2\n",
    "        learning_rate='adaptive',  # Tasa de aprendizaje adaptativa\n",
    "        max_iter=1000,  # Número máximo de iteraciones\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    mlp_model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluar el modelo\n",
    "    accuracy = mlp_model.score(X_test, y_test)\n",
    "    \n",
    "    y_pred = mlp_model.predict(X_test)\n",
    "    \n",
    "    # Calcular el F1-score\n",
    "    f1score = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    roc_auc = roc_auc_score(y_test, mlp_model.predict_proba(X_test), multi_class='ovr')\n",
    "\n",
    "    return accuracy, f1score, roc_auc, mlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_constant_class(y_true, constant_class):\n",
    "    y_pred_constant = [constant_class] * len(y_true)\n",
    "    \n",
    "    # Calcular el accuracy entre las etiquetas verdaderas y las predicciones constantes\n",
    "    accuracy = accuracy_score(y_true, y_pred_constant)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmarchetta/Desktop/Tesis-2024/myenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mmarchetta/Desktop/Tesis-2024/myenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mmarchetta/Desktop/Tesis-2024/myenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mmarchetta/Desktop/Tesis-2024/myenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de los modelos:\n",
      "Regresión Logística 0: Accuracy=0.38285714285714284, F1-Score=0.3530942256511468, ROC AUC=0.7397754576260613\n",
      "Regresión Logística 1: Accuracy=0.36, F1-Score=0.3332597575313636, ROC AUC=0.6840298250441812\n",
      "Regresión Logística 2: Accuracy=0.36, F1-Score=0.3212197185530519, ROC AUC=0.6993069177700555\n",
      "Regresión Logística 3: Accuracy=0.3942857142857143, F1-Score=0.3724750108856069, ROC AUC=0.7190091394129754\n",
      "Regresión Logística 4: Accuracy=0.3485714285714286, F1-Score=0.2976393104372038, ROC AUC=0.7406022717118406\n",
      "Regresión Logística 5: Accuracy=0.34285714285714286, F1-Score=0.2773573393178281, ROC AUC=0.7373644647108922\n",
      "Regresión Logística 6: Accuracy=0.3657142857142857, F1-Score=0.2994342241401065, ROC AUC=0.7326529073789165\n",
      "-----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mmarchetta/Desktop/Tesis-2024/myenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mmarchetta/Desktop/Tesis-2024/myenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mmarchetta/Desktop/Tesis-2024/myenv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "performance_rl_0, f1_score_rl_0, roc_auc_rl_0, modelo_rl_0 = basic_logistic_regression(dataset)\n",
    "performance_rl_1, f1_score_rl_1, roc_auc_rl_1, modelo_rl_1 = basic_logistic_regression(dataset1)\n",
    "performance_rl_2, f1_score_rl_2, roc_auc_rl_2, modelo_rl_2 = basic_logistic_regression(dataset2)\n",
    "performance_rl_3, f1_score_rl_3, roc_auc_rl_3, modelo_rl_3 = basic_logistic_regression(dataset3)\n",
    "performance_rl_4, f1_score_rl_4, roc_auc_rl_4, modelo_rl_4 = basic_logistic_regression(dataset4)\n",
    "performance_rl_5, f1_score_rl_5, roc_auc_rl_5, modelo_rl_5 = basic_logistic_regression(dataset5)\n",
    "performance_rl_6, f1_score_rl_6, roc_auc_rl_6, modelo_rl_6 = basic_logistic_regression(dataset6)\n",
    "\n",
    "# Imprimir las métricas\n",
    "print(\"Métricas de los modelos:\")\n",
    "print(f\"Regresión Logística 0: Accuracy={performance_rl_0}, F1-Score={f1_score_rl_0}, ROC AUC={roc_auc_rl_0}\")\n",
    "print(f\"Regresión Logística 1: Accuracy={performance_rl_1}, F1-Score={f1_score_rl_1}, ROC AUC={roc_auc_rl_1}\")\n",
    "print(f\"Regresión Logística 2: Accuracy={performance_rl_2}, F1-Score={f1_score_rl_2}, ROC AUC={roc_auc_rl_2}\")\n",
    "print(f\"Regresión Logística 3: Accuracy={performance_rl_3}, F1-Score={f1_score_rl_3}, ROC AUC={roc_auc_rl_3}\")\n",
    "print(f\"Regresión Logística 4: Accuracy={performance_rl_4}, F1-Score={f1_score_rl_4}, ROC AUC={roc_auc_rl_4}\")\n",
    "print(f\"Regresión Logística 5: Accuracy={performance_rl_5}, F1-Score={f1_score_rl_5}, ROC AUC={roc_auc_rl_5}\")\n",
    "print(f\"Regresión Logística 6: Accuracy={performance_rl_6}, F1-Score={f1_score_rl_6}, ROC AUC={roc_auc_rl_6}\")\n",
    "print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting 0: Accuracy=0.5142857142857142, F1-Score=0.5065362726321937, ROC AUC=0.7512839611085134\n",
      "Gradient Boosting 1: Accuracy=0.49714285714285716, F1-Score=0.4904066605133962, ROC AUC=0.752054750920345\n",
      "Gradient Boosting 2: Accuracy=0.49142857142857144, F1-Score=0.4850891596808112, ROC AUC=0.7520520731623925\n",
      "Gradient Boosting 3: Accuracy=0.4685714285714286, F1-Score=0.4596080636139763, ROC AUC=0.7467436340979873\n",
      "Gradient Boosting 4: Accuracy=0.5085714285714286, F1-Score=0.5038132515442216, ROC AUC=0.7484625842303271\n",
      "Gradient Boosting 5: Accuracy=0.49714285714285716, F1-Score=0.49236116754463677, ROC AUC=0.7460065574786309\n",
      "Gradient Boosting 6: Accuracy=0.4742857142857143, F1-Score=0.46712770673486786, ROC AUC=0.7510182084940417\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "performance_gb_0, f1_score_gb_0, roc_auc_gb_0, modelo_gb_0 = basic_gradient_boosting(dataset)\n",
    "performance_gb_1, f1_score_gb_1, roc_auc_gb_1, modelo_gb_1 = basic_gradient_boosting(dataset1)\n",
    "performance_gb_2, f1_score_gb_2, roc_auc_gb_2, modelo_gb_2 = basic_gradient_boosting(dataset2)\n",
    "performance_gb_3, f1_score_gb_3, roc_auc_gb_3, modelo_gb_3 = basic_gradient_boosting(dataset3)\n",
    "performance_gb_4, f1_score_gb_4, roc_auc_gb_4, modelo_gb_4 = basic_gradient_boosting(dataset4)\n",
    "performance_gb_5, f1_score_gb_5, roc_auc_gb_5, modelo_gb_5 = basic_gradient_boosting(dataset5)\n",
    "performance_gb_6, f1_score_gb_6, roc_auc_gb_6, modelo_gb_6 = basic_gradient_boosting(dataset6)\n",
    "\n",
    "# Imprimir las métricas\n",
    "print(f\"Gradient Boosting 0: Accuracy={performance_gb_0}, F1-Score={f1_score_gb_0}, ROC AUC={roc_auc_gb_0}\")\n",
    "print(f\"Gradient Boosting 1: Accuracy={performance_gb_1}, F1-Score={f1_score_gb_1}, ROC AUC={roc_auc_gb_1}\")\n",
    "print(f\"Gradient Boosting 2: Accuracy={performance_gb_2}, F1-Score={f1_score_gb_2}, ROC AUC={roc_auc_gb_2}\")\n",
    "print(f\"Gradient Boosting 3: Accuracy={performance_gb_3}, F1-Score={f1_score_gb_3}, ROC AUC={roc_auc_gb_3}\")\n",
    "print(f\"Gradient Boosting 4: Accuracy={performance_gb_4}, F1-Score={f1_score_gb_4}, ROC AUC={roc_auc_gb_4}\")\n",
    "print(f\"Gradient Boosting 5: Accuracy={performance_gb_5}, F1-Score={f1_score_gb_5}, ROC AUC={roc_auc_gb_5}\")\n",
    "print(f\"Gradient Boosting 6: Accuracy={performance_gb_6}, F1-Score={f1_score_gb_6}, ROC AUC={roc_auc_gb_6}\")\n",
    "print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de los modelos de SVM:\n",
      "SVM 0: Accuracy=0.4514285714285714, F1-Score=0.3523694103656158, ROC AUC=0.7353259370889722\n",
      "SVM 1: Accuracy=0.42857142857142855, F1-Score=0.33783812453318424, ROC AUC=0.718533139449225\n",
      "SVM 2: Accuracy=0.38285714285714284, F1-Score=0.2936103896103896, ROC AUC=0.7107460835696278\n",
      "SVM 3: Accuracy=0.4114285714285714, F1-Score=0.37264017471395344, ROC AUC=0.6972126045830924\n",
      "SVM 4: Accuracy=0.4057142857142857, F1-Score=0.3804231008514581, ROC AUC=0.7431400325013336\n",
      "SVM 5: Accuracy=0.4057142857142857, F1-Score=0.3804231008514581, ROC AUC=0.7430399029170208\n",
      "SVM 6: Accuracy=0.44571428571428573, F1-Score=0.426626842892732, ROC AUC=0.7499140113458804\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "performance_svm_0, f1_score_svm_0, roc_auc_svm_0, modelo_svm_0 = basic_svm(dataset)\n",
    "performance_svm_1, f1_score_svm_1, roc_auc_svm_1, modelo_svm_1 = basic_svm(dataset1)\n",
    "performance_svm_2, f1_score_svm_2, roc_auc_svm_2, modelo_svm_2 = basic_svm(dataset2)\n",
    "performance_svm_3, f1_score_svm_3, roc_auc_svm_3, modelo_svm_3 = basic_svm(dataset3)\n",
    "performance_svm_4, f1_score_svm_4, roc_auc_svm_4, modelo_svm_4 = basic_svm(dataset4)\n",
    "performance_svm_5, f1_score_svm_5, roc_auc_svm_5, modelo_svm_5 = basic_svm(dataset5)\n",
    "performance_svm_6, f1_score_svm_6, roc_auc_svm_6, modelo_svm_6 = basic_svm(dataset6)\n",
    "\n",
    "\n",
    "# Imprimir las métricas\n",
    "print(\"Métricas de los modelos de SVM:\")\n",
    "print(f\"SVM 0: Accuracy={performance_svm_0}, F1-Score={f1_score_svm_0}, ROC AUC={roc_auc_svm_0}\")\n",
    "print(f\"SVM 1: Accuracy={performance_svm_1}, F1-Score={f1_score_svm_1}, ROC AUC={roc_auc_svm_1}\")\n",
    "print(f\"SVM 2: Accuracy={performance_svm_2}, F1-Score={f1_score_svm_2}, ROC AUC={roc_auc_svm_2}\")\n",
    "print(f\"SVM 3: Accuracy={performance_svm_3}, F1-Score={f1_score_svm_3}, ROC AUC={roc_auc_svm_3}\")\n",
    "print(f\"SVM 4: Accuracy={performance_svm_4}, F1-Score={f1_score_svm_4}, ROC AUC={roc_auc_svm_4}\")\n",
    "print(f\"SVM 5: Accuracy={performance_svm_5}, F1-Score={f1_score_svm_5}, ROC AUC={roc_auc_svm_5}\")\n",
    "print(f\"SVM 6: Accuracy={performance_svm_6}, F1-Score={f1_score_svm_6}, ROC AUC={roc_auc_svm_6}\")\n",
    "print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas de los modelos de MLP:\n",
      "MLP 0: Accuracy=0.3657142857142857, F1-Score=0.26423821879556186, ROC AUC=0.562858082947901\n",
      "MLP 1: Accuracy=0.37142857142857144, F1-Score=0.3278009827562566, ROC AUC=0.6000805756833493\n",
      "MLP 2: Accuracy=0.29714285714285715, F1-Score=0.23696456501514657, ROC AUC=0.5529468094622568\n",
      "MLP 3: Accuracy=0.32571428571428573, F1-Score=0.24032568633323353, ROC AUC=0.5484151886993803\n",
      "MLP 4: Accuracy=0.30857142857142855, F1-Score=0.30629948122392914, ROC AUC=0.54077235110191\n",
      "MLP 5: Accuracy=0.2571428571428571, F1-Score=0.13996464519873883, ROC AUC=0.5037746925329882\n",
      "MLP 6: Accuracy=0.42857142857142855, F1-Score=0.363694230138594, ROC AUC=0.6155791562931395\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "performance_mlp_0, f1_score_mlp_0, roc_auc_mlp_0, modelo_mlp_0 = basic_MLP(dataset)\n",
    "performance_mlp_1, f1_score_mlp_1, roc_auc_mlp_1, modelo_mlp_1 = basic_MLP(dataset1)\n",
    "performance_mlp_2, f1_score_mlp_2, roc_auc_mlp_2, modelo_mlp_2 = basic_MLP(dataset2)\n",
    "performance_mlp_3, f1_score_mlp_3, roc_auc_mlp_3, modelo_mlp_3 = basic_MLP(dataset3)\n",
    "performance_mlp_4, f1_score_mlp_4, roc_auc_mlp_4, modelo_mlp_4 = basic_MLP(dataset4)\n",
    "performance_mlp_5, f1_score_mlp_5, roc_auc_mlp_5, modelo_mlp_5 = basic_MLP(dataset5)\n",
    "performance_mlp_6, f1_score_mlp_6, roc_auc_mlp_6, modelo_mlp_6 = basic_MLP(dataset6)\n",
    "\n",
    "# Imprimir las métricas\n",
    "print(\"Métricas de los modelos de MLP:\")\n",
    "print(f\"MLP 0: Accuracy={performance_mlp_0}, F1-Score={f1_score_mlp_0}, ROC AUC={roc_auc_mlp_0}\")\n",
    "print(f\"MLP 1: Accuracy={performance_mlp_1}, F1-Score={f1_score_mlp_1}, ROC AUC={roc_auc_mlp_1}\")\n",
    "print(f\"MLP 2: Accuracy={performance_mlp_2}, F1-Score={f1_score_mlp_2}, ROC AUC={roc_auc_mlp_2}\")\n",
    "print(f\"MLP 3: Accuracy={performance_mlp_3}, F1-Score={f1_score_mlp_3}, ROC AUC={roc_auc_mlp_3}\")\n",
    "print(f\"MLP 4: Accuracy={performance_mlp_4}, F1-Score={f1_score_mlp_4}, ROC AUC={roc_auc_mlp_4}\")\n",
    "print(f\"MLP 5: Accuracy={performance_mlp_5}, F1-Score={f1_score_mlp_5}, ROC AUC={roc_auc_mlp_5}\")\n",
    "print(f\"MLP 6: Accuracy={performance_mlp_6}, F1-Score={f1_score_mlp_6}, ROC AUC={roc_auc_mlp_6}\")\n",
    "print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud clase constante - Alcista fuerte: 0.2629161882893226\n",
      "Exactitud clase constante - Alcista leve: 0.2468427095292767\n",
      "Exactitud clase constante - Bajista leve: 0.21814006888633755\n",
      "Exactitud clase constante - Bajista fuerte: 0.27210103329506313\n"
     ]
    }
   ],
   "source": [
    "print(\"Exactitud clase constante - Alcista fuerte:\", predict_constant_class(dataset['Tendencia'], \"Alcista fuerte\"))\n",
    "print(\"Exactitud clase constante - Alcista leve:\", predict_constant_class(dataset['Tendencia'], \"Alcista leve\"))\n",
    "# print(\"Exactitud clase constante - Lateral:\", predict_constant_class(dataset['Tendencia'], \"Lateral\"))\n",
    "print(\"Exactitud clase constante - Bajista leve:\", predict_constant_class(dataset['Tendencia'], \"Bajista leve\"))\n",
    "print(\"Exactitud clase constante - Bajista fuerte:\", predict_constant_class(dataset['Tendencia'], \"Bajista fuerte\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para seleccionar el mejor dataset basandome en las métricas F1 y ROC, es necesario identificar aquellos conjuntos de datos que proporcionen un rendimiento consistentemente alto en ambas métricas para todos los modelos. Observando los resultados, parece que el conjunto de datos que muestra un mejor desempeño es el que corresponde al índice 0 en cada modelo (dataset completo sin normalizar).\n",
    "\n",
    "Los resultados del conjunto de datos 0 para cada modelo son los siguientes:\n",
    "\n",
    "Para la regresión logística:\n",
    "\n",
    "F1-Score: 0.353\n",
    "ROC AUC: 0.740\n",
    "Para Gradient Boosting:\n",
    "\n",
    "F1-Score: 0.507\n",
    "ROC AUC: 0.751\n",
    "Para SVM:\n",
    "\n",
    "F1-Score: 0.352\n",
    "ROC AUC: 0.735\n",
    "Para MLP:\n",
    "\n",
    "F1-Score: 0.264\n",
    "ROC AUC: 0.563\n",
    "\n",
    "Aunque los resultados de MLP no son tan altos como los de los otros modelos, el conjunto de datos 0 sigue siendo el mejor en términos de F1-Score y ROC AUC en comparación con los otros conjuntos de datos.\n",
    "\n",
    "Por lo tanto, el dataset 0 sería el más recomendable para utilizar en futuros experimentos, ya que parece proporcionar un rendimiento general sólido en todos los modelos basado en las métricas F1-Score y ROC AUC. La siguiente opcion a este, seria el dataset 4, ambos podrian ser evaluados en los siguientes experimentos.\n",
    "\n",
    "Tomare estos valores como baseline a ser superado por futuros modelos. A continuacion evaluare cual seria la performance de estos modelos en conjuntos de validacion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tendencia\n",
      "Bajista fuerte    237\n",
      "Alcista fuerte    229\n",
      "Alcista leve      215\n",
      "Bajista leve      190\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_distribution = dataset['Tendencia'].value_counts()\n",
    "\n",
    "# Imprimir la distribución de clases\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
