{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from auto_ts import auto_timeseries\n",
    "import dill\n",
    "import talib\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Flatten, Conv1D, MaxPooling1D, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.losses import categorical_crossentropy\n",
    "from sklearn.metrics import log_loss\n",
    "from keras.utils import to_categorical\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evito que ciertas columnas se transformen a notacion cientifica en las predicciones\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'Open_time',\n",
    "    'Open',\n",
    "    'High',\n",
    "    'Low',\n",
    "    # 'Close',\n",
    "    'Number of trades',\n",
    "    'Close_BTCUSDT',\n",
    "    'Volume_BTCUSDT',\n",
    "    'Number_of_trades_BTCUSDT',\n",
    "    'Close_ETHUSDT',\n",
    "    'Volume_ETHUSDT',\n",
    "    'Number_of_trades_ETHUSDT',\n",
    "    'Close_BNBUSDT',\n",
    "    'Volume_BNBUSDT',\n",
    "    'Number_of_trades_BNBUSDT',\n",
    "    'SMA_20',\n",
    "    'EMA_20',\n",
    "    'Upper_Band',\n",
    "    'Middle_Band',\n",
    "    'Lower_Band',\n",
    "    'RSI',\n",
    "    'buy_1000x_high_coinbase',\n",
    "    'sell_1000x_high_coinbase',\n",
    "    'total_trades_coinbase',\t\n",
    "    'Tweets_Utilizados',\n",
    "    'Tweets_Utilizados_coin',\n",
    "    'Tweets_Utilizados_referentes',\n",
    "    'Tweets_Utilizados_whale_alert',\n",
    "    'Buy_1000x_high',\n",
    "    'sell_1000x_high',\n",
    "    'total_trades_binance'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armado y entrenamiento de un clasificador a partir de los datos originales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = pd.read_csv('/Users/mmarchetta/Desktop/Tesis-2024/data-visualization/final_dataset.csv') \n",
    "classifier_dataset = complete_dataset[columns]\n",
    "classifier_dataset['Open_time'] = pd.to_datetime(classifier_dataset['Open_time'])\n",
    "classifier_dataset['Tendencia'] = complete_dataset['Tendencia']\n",
    "\n",
    "clasifier_validation = classifier_dataset[-5:]\n",
    "classifier_dataset = classifier_dataset[:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open_time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Number of trades</th>\n",
       "      <th>Close_BTCUSDT</th>\n",
       "      <th>Volume_BTCUSDT</th>\n",
       "      <th>Number_of_trades_BTCUSDT</th>\n",
       "      <th>Close_ETHUSDT</th>\n",
       "      <th>Volume_ETHUSDT</th>\n",
       "      <th>Number_of_trades_ETHUSDT</th>\n",
       "      <th>Close_BNBUSDT</th>\n",
       "      <th>Volume_BNBUSDT</th>\n",
       "      <th>Number_of_trades_BNBUSDT</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>Upper_Band</th>\n",
       "      <th>Middle_Band</th>\n",
       "      <th>Lower_Band</th>\n",
       "      <th>RSI</th>\n",
       "      <th>buy_1000x_high_coinbase</th>\n",
       "      <th>sell_1000x_high_coinbase</th>\n",
       "      <th>total_trades_coinbase</th>\n",
       "      <th>Tweets_Utilizados</th>\n",
       "      <th>Tweets_Utilizados_coin</th>\n",
       "      <th>Tweets_Utilizados_referentes</th>\n",
       "      <th>Tweets_Utilizados_whale_alert</th>\n",
       "      <th>Buy_1000x_high</th>\n",
       "      <th>sell_1000x_high</th>\n",
       "      <th>total_trades_binance</th>\n",
       "      <th>Tendencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>2024-03-13</td>\n",
       "      <td>10.74</td>\n",
       "      <td>11.46</td>\n",
       "      <td>10.64</td>\n",
       "      <td>276468.00</td>\n",
       "      <td>73072.41</td>\n",
       "      <td>52659.71</td>\n",
       "      <td>2501197.00</td>\n",
       "      <td>4004.79</td>\n",
       "      <td>482305.78</td>\n",
       "      <td>1536498.00</td>\n",
       "      <td>630.50</td>\n",
       "      <td>2526002.56</td>\n",
       "      <td>1265237.00</td>\n",
       "      <td>9.45</td>\n",
       "      <td>9.70</td>\n",
       "      <td>11.82</td>\n",
       "      <td>9.45</td>\n",
       "      <td>7.07</td>\n",
       "      <td>73.43</td>\n",
       "      <td>64.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>92576.00</td>\n",
       "      <td>275</td>\n",
       "      <td>205</td>\n",
       "      <td>1.00</td>\n",
       "      <td>73.00</td>\n",
       "      <td>578.00</td>\n",
       "      <td>553.00</td>\n",
       "      <td>164000.00</td>\n",
       "      <td>Alcista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>2024-03-14</td>\n",
       "      <td>11.37</td>\n",
       "      <td>11.89</td>\n",
       "      <td>10.68</td>\n",
       "      <td>536988.00</td>\n",
       "      <td>71388.94</td>\n",
       "      <td>71757.63</td>\n",
       "      <td>2994869.00</td>\n",
       "      <td>3881.70</td>\n",
       "      <td>648237.52</td>\n",
       "      <td>1919963.00</td>\n",
       "      <td>603.20</td>\n",
       "      <td>2119540.30</td>\n",
       "      <td>1038297.00</td>\n",
       "      <td>9.65</td>\n",
       "      <td>9.88</td>\n",
       "      <td>12.03</td>\n",
       "      <td>9.65</td>\n",
       "      <td>7.27</td>\n",
       "      <td>74.51</td>\n",
       "      <td>102.00</td>\n",
       "      <td>133.00</td>\n",
       "      <td>145727.00</td>\n",
       "      <td>211</td>\n",
       "      <td>181</td>\n",
       "      <td>4.00</td>\n",
       "      <td>29.00</td>\n",
       "      <td>754.00</td>\n",
       "      <td>677.00</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>Alcista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>2024-03-15</td>\n",
       "      <td>11.56</td>\n",
       "      <td>11.71</td>\n",
       "      <td>9.97</td>\n",
       "      <td>557152.00</td>\n",
       "      <td>69499.85</td>\n",
       "      <td>103334.04</td>\n",
       "      <td>3904445.00</td>\n",
       "      <td>3742.19</td>\n",
       "      <td>947537.41</td>\n",
       "      <td>2487337.00</td>\n",
       "      <td>632.70</td>\n",
       "      <td>3066312.79</td>\n",
       "      <td>1365283.00</td>\n",
       "      <td>9.80</td>\n",
       "      <td>9.97</td>\n",
       "      <td>12.07</td>\n",
       "      <td>9.80</td>\n",
       "      <td>7.52</td>\n",
       "      <td>63.27</td>\n",
       "      <td>88.00</td>\n",
       "      <td>83.00</td>\n",
       "      <td>147460.00</td>\n",
       "      <td>238</td>\n",
       "      <td>106</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>493.00</td>\n",
       "      <td>430.00</td>\n",
       "      <td>360000.00</td>\n",
       "      <td>Bajista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>2024-03-16</td>\n",
       "      <td>10.81</td>\n",
       "      <td>10.90</td>\n",
       "      <td>9.50</td>\n",
       "      <td>330505.00</td>\n",
       "      <td>65300.63</td>\n",
       "      <td>55926.95</td>\n",
       "      <td>2729019.00</td>\n",
       "      <td>3523.09</td>\n",
       "      <td>548288.16</td>\n",
       "      <td>1798939.00</td>\n",
       "      <td>576.40</td>\n",
       "      <td>1811838.04</td>\n",
       "      <td>1025452.00</td>\n",
       "      <td>9.89</td>\n",
       "      <td>9.94</td>\n",
       "      <td>11.99</td>\n",
       "      <td>9.89</td>\n",
       "      <td>7.78</td>\n",
       "      <td>50.82</td>\n",
       "      <td>30.00</td>\n",
       "      <td>49.00</td>\n",
       "      <td>88095.00</td>\n",
       "      <td>670</td>\n",
       "      <td>471</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>513.00</td>\n",
       "      <td>403.00</td>\n",
       "      <td>209000.00</td>\n",
       "      <td>Bajista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>2024-03-17</td>\n",
       "      <td>9.68</td>\n",
       "      <td>10.25</td>\n",
       "      <td>9.19</td>\n",
       "      <td>229683.00</td>\n",
       "      <td>68393.48</td>\n",
       "      <td>49742.22</td>\n",
       "      <td>2449156.00</td>\n",
       "      <td>3644.71</td>\n",
       "      <td>517790.99</td>\n",
       "      <td>1721355.00</td>\n",
       "      <td>571.70</td>\n",
       "      <td>1712920.34</td>\n",
       "      <td>802297.00</td>\n",
       "      <td>9.98</td>\n",
       "      <td>9.95</td>\n",
       "      <td>11.93</td>\n",
       "      <td>9.98</td>\n",
       "      <td>8.04</td>\n",
       "      <td>54.27</td>\n",
       "      <td>36.00</td>\n",
       "      <td>48.00</td>\n",
       "      <td>71390.00</td>\n",
       "      <td>693</td>\n",
       "      <td>413</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>295.00</td>\n",
       "      <td>277.00</td>\n",
       "      <td>150000.00</td>\n",
       "      <td>Alcista</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Open_time  Open  High   Low  Number of trades  Close_BTCUSDT  \\\n",
       "898 2024-03-13 10.74 11.46 10.64         276468.00       73072.41   \n",
       "899 2024-03-14 11.37 11.89 10.68         536988.00       71388.94   \n",
       "900 2024-03-15 11.56 11.71  9.97         557152.00       69499.85   \n",
       "901 2024-03-16 10.81 10.90  9.50         330505.00       65300.63   \n",
       "902 2024-03-17  9.68 10.25  9.19         229683.00       68393.48   \n",
       "\n",
       "     Volume_BTCUSDT  Number_of_trades_BTCUSDT  Close_ETHUSDT  Volume_ETHUSDT  \\\n",
       "898        52659.71                2501197.00        4004.79       482305.78   \n",
       "899        71757.63                2994869.00        3881.70       648237.52   \n",
       "900       103334.04                3904445.00        3742.19       947537.41   \n",
       "901        55926.95                2729019.00        3523.09       548288.16   \n",
       "902        49742.22                2449156.00        3644.71       517790.99   \n",
       "\n",
       "     Number_of_trades_ETHUSDT  Close_BNBUSDT  Volume_BNBUSDT  \\\n",
       "898                1536498.00         630.50      2526002.56   \n",
       "899                1919963.00         603.20      2119540.30   \n",
       "900                2487337.00         632.70      3066312.79   \n",
       "901                1798939.00         576.40      1811838.04   \n",
       "902                1721355.00         571.70      1712920.34   \n",
       "\n",
       "     Number_of_trades_BNBUSDT  SMA_20  EMA_20  Upper_Band  Middle_Band  \\\n",
       "898                1265237.00    9.45    9.70       11.82         9.45   \n",
       "899                1038297.00    9.65    9.88       12.03         9.65   \n",
       "900                1365283.00    9.80    9.97       12.07         9.80   \n",
       "901                1025452.00    9.89    9.94       11.99         9.89   \n",
       "902                 802297.00    9.98    9.95       11.93         9.98   \n",
       "\n",
       "     Lower_Band   RSI  buy_1000x_high_coinbase  sell_1000x_high_coinbase  \\\n",
       "898        7.07 73.43                    64.00                     81.00   \n",
       "899        7.27 74.51                   102.00                    133.00   \n",
       "900        7.52 63.27                    88.00                     83.00   \n",
       "901        7.78 50.82                    30.00                     49.00   \n",
       "902        8.04 54.27                    36.00                     48.00   \n",
       "\n",
       "     total_trades_coinbase  Tweets_Utilizados  Tweets_Utilizados_coin  \\\n",
       "898               92576.00                275                     205   \n",
       "899              145727.00                211                     181   \n",
       "900              147460.00                238                     106   \n",
       "901               88095.00                670                     471   \n",
       "902               71390.00                693                     413   \n",
       "\n",
       "     Tweets_Utilizados_referentes  Tweets_Utilizados_whale_alert  \\\n",
       "898                          1.00                          73.00   \n",
       "899                          4.00                          29.00   \n",
       "900                          0.00                          25.00   \n",
       "901                          0.00                          20.00   \n",
       "902                          0.00                          21.00   \n",
       "\n",
       "     Buy_1000x_high  sell_1000x_high  total_trades_binance Tendencia  \n",
       "898          578.00           553.00             164000.00   Alcista  \n",
       "899          754.00           677.00             327000.00   Alcista  \n",
       "900          493.00           430.00             360000.00   Bajista  \n",
       "901          513.00           403.00             209000.00   Bajista  \n",
       "902          295.00           277.00             150000.00   Alcista  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(classifier_dataset.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(903, 31)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = classifier_dataset.drop(columns=[\"Tendencia\", \"Open_time\"])\n",
    "y = classifier_dataset[\"Tendencia\"]\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# y_encoded = label_encoder.fit_transform(classifier_dataset[\"Tendencia\"])\n",
    "\n",
    "y = y.to_numpy().reshape(-1, 1)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_one_hot = onehot_encoder.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LGBMClassifier(objective='multiclass', num_class=3, metric='multi_logloss', verbosity=-1)\n",
    "\n",
    "# Definir el espacio de búsqueda de hiperparámetros\n",
    "param_space = {\n",
    "    'num_leaves': (10, 300),\n",
    "    'learning_rate': (0.01, 0.5), \n",
    "    'n_estimators': (50, 300),\n",
    "    'min_child_samples': (5, 100),\n",
    "    'subsample': (0.5, 1.0),  \n",
    "    'colsample_bytree': (0.5, 1.0)\n",
    "}\n",
    "# Definir función de pérdida para la búsqueda bayesiana\n",
    "def multi_log_loss(estimator, X_test, y_test):\n",
    "    y_pred = estimator.predict_proba(X_test)\n",
    "    loss = log_loss(y_test, y_pred)\n",
    "    return loss\n",
    "\n",
    "# Definir validación cruzada temporal\n",
    "cv = TimeSeriesSplit(n_splits=10).split(X)\n",
    "\n",
    "# Realizar la búsqueda bayesiana de hiperparámetros\n",
    "bayes_search = BayesSearchCV(\n",
    "    classifier, \n",
    "    param_space, \n",
    "    scoring=multi_log_loss, \n",
    "    cv=cv,\n",
    "    n_iter=50,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Realizar la búsqueda bayesiana\n",
    "bayes_result = bayes_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 3.3233412813590393\n",
      "Best parameters: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.5), ('min_child_samples', 24), ('n_estimators', 300), ('num_leaves', 10), ('subsample', 0.5)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.5, metric=&#x27;multi_logloss&#x27;, min_child_samples=24,\n",
       "               n_estimators=300, num_class=3, num_leaves=10,\n",
       "               objective=&#x27;multiclass&#x27;, subsample=0.5, verbosity=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.5, metric=&#x27;multi_logloss&#x27;, min_child_samples=24,\n",
       "               n_estimators=300, num_class=3, num_leaves=10,\n",
       "               objective=&#x27;multiclass&#x27;, subsample=0.5, verbosity=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.5, metric='multi_logloss', min_child_samples=24,\n",
       "               n_estimators=300, num_class=3, num_leaves=10,\n",
       "               objective='multiclass', subsample=0.5, verbosity=-1)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show best results\n",
    "print(\"Best score:\", bayes_result.best_score_)\n",
    "print(\"Best parameters:\", bayes_result.best_params_)\n",
    "\n",
    "# Entrenar el modelo con los mejores hiperparámetros\n",
    "best_model = bayes_result.best_estimator_\n",
    "best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 mejores modelos:\n",
      "Modelo 1\n",
      "Hiperparámetros: OrderedDict([('colsample_bytree', 0.5885752220313429), ('learning_rate', 0.17082884484681185), ('min_child_samples', 6), ('n_estimators', 192), ('num_leaves', 231), ('subsample', 0.5085623038169307)])\n",
      "Puntaje: 2.093090507673048\n",
      "Modelo 2\n",
      "Hiperparámetros: OrderedDict([('colsample_bytree', 0.7313732549225939), ('learning_rate', 0.47007092381868965), ('min_child_samples', 19), ('n_estimators', 291), ('num_leaves', 209), ('subsample', 0.9196262867394146)])\n",
      "Puntaje: 2.847121139240301\n",
      "Modelo 3\n",
      "Hiperparámetros: OrderedDict([('colsample_bytree', 0.9392242353895535), ('learning_rate', 0.26428839588200526), ('min_child_samples', 13), ('n_estimators', 187), ('num_leaves', 32), ('subsample', 0.70993998152444)])\n",
      "Puntaje: 2.541656866917237\n",
      "Modelo 4\n",
      "Hiperparámetros: OrderedDict([('colsample_bytree', 0.7804555919276301), ('learning_rate', 0.34732279373697456), ('min_child_samples', 54), ('n_estimators', 228), ('num_leaves', 145), ('subsample', 0.6855874898863495)])\n",
      "Puntaje: 1.981545416686292\n",
      "Modelo 5\n",
      "Hiperparámetros: OrderedDict([('colsample_bytree', 0.7117112096391811), ('learning_rate', 0.25324736023487676), ('min_child_samples', 63), ('n_estimators', 163), ('num_leaves', 159), ('subsample', 0.6187453051399433)])\n",
      "Puntaje: 1.3493390881001401\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Obtener los hiperparámetros y puntajes de los 5 mejores modelos\n",
    "top_n_models = 5\n",
    "best_params_list = []\n",
    "best_scores_list = []\n",
    "\n",
    "for i in range(min(top_n_models, len(bayes_search.cv_results_['params']))):\n",
    "    best_params_list.append(bayes_search.cv_results_['params'][i])\n",
    "    best_scores_list.append(bayes_search.cv_results_['mean_test_score'][i])\n",
    "\n",
    "# Guardar los hiperparámetros de los 5 mejores modelos en un archivo JSON\n",
    "with open('gbm_classifier/top_5_hyperparameters.json', 'w') as f:\n",
    "    json.dump({'best_params': best_params_list, 'best_scores': best_scores_list}, f)\n",
    "\n",
    "# O imprimir los hiperparámetros\n",
    "print(\"Top 5 mejores modelos:\")\n",
    "for i in range(len(best_params_list)):\n",
    "    print(\"Modelo\", i+1)\n",
    "    print(\"Hiperparámetros:\", best_params_list[i])\n",
    "    print(\"Puntaje:\", best_scores_list[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Armado del ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una lista para almacenar los modelos individuales\n",
    "individual_models = []\n",
    "\n",
    "# Entrenar los modelos individuales\n",
    "for params_str in best_params_list:\n",
    "    model = LGBMClassifier(verbosity=-1, **params_str)\n",
    "    model.fit(X, y)\n",
    "    individual_models.append(model)\n",
    "\n",
    "voting_model = VotingClassifier(estimators=[('model_'+str(i), model) for i, model in enumerate(individual_models)], voting='soft', verbose=0)\n",
    "voting_model.fit(X, y)\n",
    "\n",
    "with open('gbm_classifier/gbm_boosting_classifier.pkl', 'wb') as f:\n",
    "    dill.dump(voting_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clasificacion con el ensamble sobre las redicciones de los modelos generativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gbm_classifier/gbm_boosting_classifier.pkl', 'rb') as f:\n",
    "    voting_model = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;model_0&#x27;,\n",
       "                              LGBMClassifier(colsample_bytree=0.5885752220313429,\n",
       "                                             learning_rate=0.17082884484681185,\n",
       "                                             min_child_samples=6,\n",
       "                                             n_estimators=192, num_leaves=231,\n",
       "                                             subsample=0.5085623038169307,\n",
       "                                             verbosity=-1)),\n",
       "                             (&#x27;model_1&#x27;,\n",
       "                              LGBMClassifier(colsample_bytree=0.7313732549225939,\n",
       "                                             learning_rate=0.47007092381868965,\n",
       "                                             min_child_samples=19,\n",
       "                                             n_estimators...\n",
       "                              LGBMClassifier(colsample_bytree=0.7804555919276301,\n",
       "                                             learning_rate=0.34732279373697456,\n",
       "                                             min_child_samples=54,\n",
       "                                             n_estimators=228, num_leaves=145,\n",
       "                                             subsample=0.6855874898863495,\n",
       "                                             verbosity=-1)),\n",
       "                             (&#x27;model_4&#x27;,\n",
       "                              LGBMClassifier(colsample_bytree=0.7117112096391811,\n",
       "                                             learning_rate=0.25324736023487676,\n",
       "                                             min_child_samples=63,\n",
       "                                             n_estimators=163, num_leaves=159,\n",
       "                                             subsample=0.6187453051399433,\n",
       "                                             verbosity=-1))],\n",
       "                 verbose=0, voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;model_0&#x27;,\n",
       "                              LGBMClassifier(colsample_bytree=0.5885752220313429,\n",
       "                                             learning_rate=0.17082884484681185,\n",
       "                                             min_child_samples=6,\n",
       "                                             n_estimators=192, num_leaves=231,\n",
       "                                             subsample=0.5085623038169307,\n",
       "                                             verbosity=-1)),\n",
       "                             (&#x27;model_1&#x27;,\n",
       "                              LGBMClassifier(colsample_bytree=0.7313732549225939,\n",
       "                                             learning_rate=0.47007092381868965,\n",
       "                                             min_child_samples=19,\n",
       "                                             n_estimators...\n",
       "                              LGBMClassifier(colsample_bytree=0.7804555919276301,\n",
       "                                             learning_rate=0.34732279373697456,\n",
       "                                             min_child_samples=54,\n",
       "                                             n_estimators=228, num_leaves=145,\n",
       "                                             subsample=0.6855874898863495,\n",
       "                                             verbosity=-1)),\n",
       "                             (&#x27;model_4&#x27;,\n",
       "                              LGBMClassifier(colsample_bytree=0.7117112096391811,\n",
       "                                             learning_rate=0.25324736023487676,\n",
       "                                             min_child_samples=63,\n",
       "                                             n_estimators=163, num_leaves=159,\n",
       "                                             subsample=0.6187453051399433,\n",
       "                                             verbosity=-1))],\n",
       "                 verbose=0, voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>model_0</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(colsample_bytree=0.5885752220313429,\n",
       "               learning_rate=0.17082884484681185, min_child_samples=6,\n",
       "               n_estimators=192, num_leaves=231, subsample=0.5085623038169307,\n",
       "               verbosity=-1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>model_1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(colsample_bytree=0.7313732549225939,\n",
       "               learning_rate=0.47007092381868965, min_child_samples=19,\n",
       "               n_estimators=291, num_leaves=209, subsample=0.9196262867394146,\n",
       "               verbosity=-1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>model_2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(colsample_bytree=0.9392242353895535,\n",
       "               learning_rate=0.26428839588200526, min_child_samples=13,\n",
       "               n_estimators=187, num_leaves=32, subsample=0.70993998152444,\n",
       "               verbosity=-1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>model_3</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(colsample_bytree=0.7804555919276301,\n",
       "               learning_rate=0.34732279373697456, min_child_samples=54,\n",
       "               n_estimators=228, num_leaves=145, subsample=0.6855874898863495,\n",
       "               verbosity=-1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>model_4</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(colsample_bytree=0.7117112096391811,\n",
       "               learning_rate=0.25324736023487676, min_child_samples=63,\n",
       "               n_estimators=163, num_leaves=159, subsample=0.6187453051399433,\n",
       "               verbosity=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('model_0',\n",
       "                              LGBMClassifier(colsample_bytree=0.5885752220313429,\n",
       "                                             learning_rate=0.17082884484681185,\n",
       "                                             min_child_samples=6,\n",
       "                                             n_estimators=192, num_leaves=231,\n",
       "                                             subsample=0.5085623038169307,\n",
       "                                             verbosity=-1)),\n",
       "                             ('model_1',\n",
       "                              LGBMClassifier(colsample_bytree=0.7313732549225939,\n",
       "                                             learning_rate=0.47007092381868965,\n",
       "                                             min_child_samples=19,\n",
       "                                             n_estimators...\n",
       "                              LGBMClassifier(colsample_bytree=0.7804555919276301,\n",
       "                                             learning_rate=0.34732279373697456,\n",
       "                                             min_child_samples=54,\n",
       "                                             n_estimators=228, num_leaves=145,\n",
       "                                             subsample=0.6855874898863495,\n",
       "                                             verbosity=-1)),\n",
       "                             ('model_4',\n",
       "                              LGBMClassifier(colsample_bytree=0.7117112096391811,\n",
       "                                             learning_rate=0.25324736023487676,\n",
       "                                             min_child_samples=63,\n",
       "                                             n_estimators=163, num_leaves=159,\n",
       "                                             subsample=0.6187453051399433,\n",
       "                                             verbosity=-1))],\n",
       "                 verbose=0, voting='soft')"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datos originales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open_time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Number of trades</th>\n",
       "      <th>Close_BTCUSDT</th>\n",
       "      <th>Volume_BTCUSDT</th>\n",
       "      <th>Number_of_trades_BTCUSDT</th>\n",
       "      <th>Close_ETHUSDT</th>\n",
       "      <th>Volume_ETHUSDT</th>\n",
       "      <th>Number_of_trades_ETHUSDT</th>\n",
       "      <th>Close_BNBUSDT</th>\n",
       "      <th>Volume_BNBUSDT</th>\n",
       "      <th>Number_of_trades_BNBUSDT</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>Upper_Band</th>\n",
       "      <th>Middle_Band</th>\n",
       "      <th>Lower_Band</th>\n",
       "      <th>RSI</th>\n",
       "      <th>buy_1000x_high_coinbase</th>\n",
       "      <th>sell_1000x_high_coinbase</th>\n",
       "      <th>total_trades_coinbase</th>\n",
       "      <th>Tweets_Utilizados</th>\n",
       "      <th>Tweets_Utilizados_coin</th>\n",
       "      <th>Tweets_Utilizados_referentes</th>\n",
       "      <th>Tweets_Utilizados_whale_alert</th>\n",
       "      <th>Buy_1000x_high</th>\n",
       "      <th>sell_1000x_high</th>\n",
       "      <th>total_trades_binance</th>\n",
       "      <th>Tendencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>2024-03-18</td>\n",
       "      <td>10.08</td>\n",
       "      <td>10.46</td>\n",
       "      <td>9.60</td>\n",
       "      <td>245319.00</td>\n",
       "      <td>67609.99</td>\n",
       "      <td>55691.08</td>\n",
       "      <td>2464515.00</td>\n",
       "      <td>3520.46</td>\n",
       "      <td>570901.29</td>\n",
       "      <td>1906387.00</td>\n",
       "      <td>555.40</td>\n",
       "      <td>2284301.81</td>\n",
       "      <td>994512.00</td>\n",
       "      <td>10.06</td>\n",
       "      <td>9.95</td>\n",
       "      <td>11.86</td>\n",
       "      <td>10.06</td>\n",
       "      <td>8.26</td>\n",
       "      <td>52.48</td>\n",
       "      <td>34.00</td>\n",
       "      <td>43.00</td>\n",
       "      <td>84706.00</td>\n",
       "      <td>696</td>\n",
       "      <td>471</td>\n",
       "      <td>0.00</td>\n",
       "      <td>43.00</td>\n",
       "      <td>343.00</td>\n",
       "      <td>228.00</td>\n",
       "      <td>154000.00</td>\n",
       "      <td>Bajista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>2024-03-19</td>\n",
       "      <td>9.90</td>\n",
       "      <td>9.99</td>\n",
       "      <td>8.60</td>\n",
       "      <td>341363.00</td>\n",
       "      <td>61937.40</td>\n",
       "      <td>101005.32</td>\n",
       "      <td>3593832.00</td>\n",
       "      <td>3158.64</td>\n",
       "      <td>1049629.69</td>\n",
       "      <td>2647385.00</td>\n",
       "      <td>507.70</td>\n",
       "      <td>2551361.51</td>\n",
       "      <td>1213572.00</td>\n",
       "      <td>10.08</td>\n",
       "      <td>9.84</td>\n",
       "      <td>11.81</td>\n",
       "      <td>10.08</td>\n",
       "      <td>8.35</td>\n",
       "      <td>42.93</td>\n",
       "      <td>120.00</td>\n",
       "      <td>126.00</td>\n",
       "      <td>135180.00</td>\n",
       "      <td>961</td>\n",
       "      <td>509</td>\n",
       "      <td>1.00</td>\n",
       "      <td>56.00</td>\n",
       "      <td>534.00</td>\n",
       "      <td>433.00</td>\n",
       "      <td>221000.00</td>\n",
       "      <td>Bajista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>2024-03-20</td>\n",
       "      <td>8.77</td>\n",
       "      <td>9.57</td>\n",
       "      <td>8.49</td>\n",
       "      <td>267797.00</td>\n",
       "      <td>67840.51</td>\n",
       "      <td>90420.59</td>\n",
       "      <td>3549793.00</td>\n",
       "      <td>3516.53</td>\n",
       "      <td>1207322.82</td>\n",
       "      <td>2987953.00</td>\n",
       "      <td>556.80</td>\n",
       "      <td>1425296.58</td>\n",
       "      <td>809335.00</td>\n",
       "      <td>10.14</td>\n",
       "      <td>9.80</td>\n",
       "      <td>11.68</td>\n",
       "      <td>10.14</td>\n",
       "      <td>8.60</td>\n",
       "      <td>49.21</td>\n",
       "      <td>185.00</td>\n",
       "      <td>117.00</td>\n",
       "      <td>112997.00</td>\n",
       "      <td>866</td>\n",
       "      <td>555</td>\n",
       "      <td>1.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>473.00</td>\n",
       "      <td>386.00</td>\n",
       "      <td>171000.00</td>\n",
       "      <td>Alcista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>2024-03-21</td>\n",
       "      <td>9.48</td>\n",
       "      <td>9.58</td>\n",
       "      <td>9.07</td>\n",
       "      <td>156774.00</td>\n",
       "      <td>65501.27</td>\n",
       "      <td>53357.48</td>\n",
       "      <td>2388390.00</td>\n",
       "      <td>3492.85</td>\n",
       "      <td>602755.21</td>\n",
       "      <td>1791989.00</td>\n",
       "      <td>553.80</td>\n",
       "      <td>953921.37</td>\n",
       "      <td>563996.00</td>\n",
       "      <td>10.17</td>\n",
       "      <td>9.74</td>\n",
       "      <td>11.63</td>\n",
       "      <td>10.17</td>\n",
       "      <td>8.71</td>\n",
       "      <td>46.85</td>\n",
       "      <td>64.00</td>\n",
       "      <td>81.00</td>\n",
       "      <td>66543.00</td>\n",
       "      <td>692</td>\n",
       "      <td>533</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>350.00</td>\n",
       "      <td>290.00</td>\n",
       "      <td>101000.00</td>\n",
       "      <td>Bajista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>2024-03-22</td>\n",
       "      <td>9.18</td>\n",
       "      <td>9.37</td>\n",
       "      <td>8.69</td>\n",
       "      <td>147578.00</td>\n",
       "      <td>63796.64</td>\n",
       "      <td>51482.38</td>\n",
       "      <td>2492881.00</td>\n",
       "      <td>3336.35</td>\n",
       "      <td>558848.89</td>\n",
       "      <td>1747756.00</td>\n",
       "      <td>553.80</td>\n",
       "      <td>1181298.51</td>\n",
       "      <td>712381.00</td>\n",
       "      <td>10.14</td>\n",
       "      <td>9.67</td>\n",
       "      <td>11.67</td>\n",
       "      <td>10.14</td>\n",
       "      <td>8.62</td>\n",
       "      <td>45.00</td>\n",
       "      <td>57.00</td>\n",
       "      <td>66.00</td>\n",
       "      <td>68616.00</td>\n",
       "      <td>681</td>\n",
       "      <td>546</td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.00</td>\n",
       "      <td>252.00</td>\n",
       "      <td>206.00</td>\n",
       "      <td>92000.00</td>\n",
       "      <td>Bajista</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Open_time  Open  High  Low  Number of trades  Close_BTCUSDT  \\\n",
       "903 2024-03-18 10.08 10.46 9.60         245319.00       67609.99   \n",
       "904 2024-03-19  9.90  9.99 8.60         341363.00       61937.40   \n",
       "905 2024-03-20  8.77  9.57 8.49         267797.00       67840.51   \n",
       "906 2024-03-21  9.48  9.58 9.07         156774.00       65501.27   \n",
       "907 2024-03-22  9.18  9.37 8.69         147578.00       63796.64   \n",
       "\n",
       "     Volume_BTCUSDT  Number_of_trades_BTCUSDT  Close_ETHUSDT  Volume_ETHUSDT  \\\n",
       "903        55691.08                2464515.00        3520.46       570901.29   \n",
       "904       101005.32                3593832.00        3158.64      1049629.69   \n",
       "905        90420.59                3549793.00        3516.53      1207322.82   \n",
       "906        53357.48                2388390.00        3492.85       602755.21   \n",
       "907        51482.38                2492881.00        3336.35       558848.89   \n",
       "\n",
       "     Number_of_trades_ETHUSDT  Close_BNBUSDT  Volume_BNBUSDT  \\\n",
       "903                1906387.00         555.40      2284301.81   \n",
       "904                2647385.00         507.70      2551361.51   \n",
       "905                2987953.00         556.80      1425296.58   \n",
       "906                1791989.00         553.80       953921.37   \n",
       "907                1747756.00         553.80      1181298.51   \n",
       "\n",
       "     Number_of_trades_BNBUSDT  SMA_20  EMA_20  Upper_Band  Middle_Band  \\\n",
       "903                 994512.00   10.06    9.95       11.86        10.06   \n",
       "904                1213572.00   10.08    9.84       11.81        10.08   \n",
       "905                 809335.00   10.14    9.80       11.68        10.14   \n",
       "906                 563996.00   10.17    9.74       11.63        10.17   \n",
       "907                 712381.00   10.14    9.67       11.67        10.14   \n",
       "\n",
       "     Lower_Band   RSI  buy_1000x_high_coinbase  sell_1000x_high_coinbase  \\\n",
       "903        8.26 52.48                    34.00                     43.00   \n",
       "904        8.35 42.93                   120.00                    126.00   \n",
       "905        8.60 49.21                   185.00                    117.00   \n",
       "906        8.71 46.85                    64.00                     81.00   \n",
       "907        8.62 45.00                    57.00                     66.00   \n",
       "\n",
       "     total_trades_coinbase  Tweets_Utilizados  Tweets_Utilizados_coin  \\\n",
       "903               84706.00                696                     471   \n",
       "904              135180.00                961                     509   \n",
       "905              112997.00                866                     555   \n",
       "906               66543.00                692                     533   \n",
       "907               68616.00                681                     546   \n",
       "\n",
       "     Tweets_Utilizados_referentes  Tweets_Utilizados_whale_alert  \\\n",
       "903                          0.00                          43.00   \n",
       "904                          1.00                          56.00   \n",
       "905                          1.00                          40.00   \n",
       "906                          0.00                          24.00   \n",
       "907                          0.00                          41.00   \n",
       "\n",
       "     Buy_1000x_high  sell_1000x_high  total_trades_binance Tendencia  \n",
       "903          343.00           228.00             154000.00   Bajista  \n",
       "904          534.00           433.00             221000.00   Bajista  \n",
       "905          473.00           386.00             171000.00   Alcista  \n",
       "906          350.00           290.00             101000.00   Bajista  \n",
       "907          252.00           206.00              92000.00   Bajista  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(clasifier_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bajista', 'Bajista', 'Bajista', 'Alcista', 'Alcista'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_clases = 3 \n",
    "\n",
    "validation_predictions = voting_model.predict(clasifier_validation.drop(columns=[\"Open_time\", \"Tendencia\"]))\n",
    "display(validation_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datos generados por auto ml con prophet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bajista', 'Bajista', 'Bajista', 'Bajista', 'Bajista'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auto_ml_prophet_df = pd.read_csv('auto_timeseries_models_prophet/predicciones.csv')\n",
    "auto_mp_prophet_predictions = voting_model.predict(auto_ml_prophet_df.drop(columns=[\"Open_time\", \"Close\"]))\n",
    "display(auto_mp_prophet_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datos generados por auto ml con stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bajista', 'Bajista', 'Bajista', 'Bajista', 'Bajista'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auto_ml_stats_df = pd.read_csv('auto_timeseries_models/predicciones.csv')\n",
    "auto_mp_stats_predictions = voting_model.predict(auto_ml_stats_df.drop(columns=[\"Open_time\", \"Close\"]))\n",
    "\n",
    "display(auto_mp_stats_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datos generados por auto ml con modelos clasicos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alcista', 'Alcista', 'Alcista', 'Alcista', 'Alcista'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auto_ml_df = pd.read_csv('h2o_models/predicciones.csv')\n",
    "auto_mp_predictions = voting_model.predict(auto_ml_df.drop(columns=[\"Open_time\", \"Next_Day_Target\", \"Close\"]))\n",
    "display(auto_mp_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
