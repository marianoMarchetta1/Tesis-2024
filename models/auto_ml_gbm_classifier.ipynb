{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 11:05:45.065345: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from auto_ts import auto_timeseries\n",
    "import dill\n",
    "import talib\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Flatten, Conv1D, MaxPooling1D, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.losses import categorical_crossentropy\n",
    "from sklearn.metrics import log_loss\n",
    "from keras.utils import to_categorical\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evito que ciertas columnas se transformen a notacion cientifica en las predicciones\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'Open_time',\n",
    "    'Open',\n",
    "    'High',\n",
    "    'Low',\n",
    "    # 'Close',\n",
    "    'Number of trades',\n",
    "    'Close_BTCUSDT',\n",
    "    'Volume_BTCUSDT',\n",
    "    'Number_of_trades_BTCUSDT',\n",
    "    'Close_ETHUSDT',\n",
    "    'Volume_ETHUSDT',\n",
    "    'Number_of_trades_ETHUSDT',\n",
    "    'Close_BNBUSDT',\n",
    "    'Volume_BNBUSDT',\n",
    "    'Number_of_trades_BNBUSDT',\n",
    "    'SMA_20',\n",
    "    'EMA_20',\n",
    "    'Upper_Band',\n",
    "    'Middle_Band',\n",
    "    'Lower_Band',\n",
    "    'RSI',\n",
    "    'buy_1000x_high_coinbase',\n",
    "    'sell_1000x_high_coinbase',\n",
    "    'total_trades_coinbase',\t\n",
    "    'Tweets_Utilizados',\n",
    "    'Tweets_Utilizados_coin',\n",
    "    'Tweets_Utilizados_referentes',\n",
    "    'Tweets_Utilizados_whale_alert',\n",
    "    'Buy_1000x_high',\n",
    "    'sell_1000x_high',\n",
    "    'total_trades_binance'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Armado y entrenamiento de un clasificador a partir de los datos originales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_dataset = pd.read_csv('/Users/mmarchetta/Desktop/Tesis-2024/data-visualization/final_dataset.csv') \n",
    "classifier_dataset = complete_dataset[columns]\n",
    "classifier_dataset['Open_time'] = pd.to_datetime(classifier_dataset['Open_time'])\n",
    "classifier_dataset['Tendencia'] = complete_dataset['Tendencia']\n",
    "\n",
    "clasifier_validation = classifier_dataset[-10:]\n",
    "classifier_dataset = classifier_dataset[:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open_time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Number of trades</th>\n",
       "      <th>Close_BTCUSDT</th>\n",
       "      <th>Volume_BTCUSDT</th>\n",
       "      <th>Number_of_trades_BTCUSDT</th>\n",
       "      <th>Close_ETHUSDT</th>\n",
       "      <th>Volume_ETHUSDT</th>\n",
       "      <th>Number_of_trades_ETHUSDT</th>\n",
       "      <th>Close_BNBUSDT</th>\n",
       "      <th>Volume_BNBUSDT</th>\n",
       "      <th>Number_of_trades_BNBUSDT</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>Upper_Band</th>\n",
       "      <th>Middle_Band</th>\n",
       "      <th>Lower_Band</th>\n",
       "      <th>RSI</th>\n",
       "      <th>buy_1000x_high_coinbase</th>\n",
       "      <th>sell_1000x_high_coinbase</th>\n",
       "      <th>total_trades_coinbase</th>\n",
       "      <th>Tweets_Utilizados</th>\n",
       "      <th>Tweets_Utilizados_coin</th>\n",
       "      <th>Tweets_Utilizados_referentes</th>\n",
       "      <th>Tweets_Utilizados_whale_alert</th>\n",
       "      <th>Buy_1000x_high</th>\n",
       "      <th>sell_1000x_high</th>\n",
       "      <th>total_trades_binance</th>\n",
       "      <th>Tendencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>2024-04-25</td>\n",
       "      <td>6.93</td>\n",
       "      <td>7.00</td>\n",
       "      <td>6.70</td>\n",
       "      <td>71088.00</td>\n",
       "      <td>64498.34</td>\n",
       "      <td>31341.46</td>\n",
       "      <td>1375324.00</td>\n",
       "      <td>3155.80</td>\n",
       "      <td>352288.55</td>\n",
       "      <td>861077.00</td>\n",
       "      <td>613.20</td>\n",
       "      <td>453745.52</td>\n",
       "      <td>353114.00</td>\n",
       "      <td>7.43</td>\n",
       "      <td>7.45</td>\n",
       "      <td>9.08</td>\n",
       "      <td>7.43</td>\n",
       "      <td>5.77</td>\n",
       "      <td>38.83</td>\n",
       "      <td>21.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>33468.00</td>\n",
       "      <td>151</td>\n",
       "      <td>114</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>242.00</td>\n",
       "      <td>219.00</td>\n",
       "      <td>48000.00</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>2024-04-26</td>\n",
       "      <td>6.86</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.71</td>\n",
       "      <td>67383.00</td>\n",
       "      <td>63770.01</td>\n",
       "      <td>27085.19</td>\n",
       "      <td>1025561.00</td>\n",
       "      <td>3131.30</td>\n",
       "      <td>252522.65</td>\n",
       "      <td>628635.00</td>\n",
       "      <td>598.00</td>\n",
       "      <td>302119.88</td>\n",
       "      <td>269508.00</td>\n",
       "      <td>7.34</td>\n",
       "      <td>7.38</td>\n",
       "      <td>8.94</td>\n",
       "      <td>7.34</td>\n",
       "      <td>5.74</td>\n",
       "      <td>37.81</td>\n",
       "      <td>29.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>26619.00</td>\n",
       "      <td>117</td>\n",
       "      <td>106</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>292.00</td>\n",
       "      <td>324.00</td>\n",
       "      <td>42000.00</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>2024-04-27</td>\n",
       "      <td>6.76</td>\n",
       "      <td>6.87</td>\n",
       "      <td>6.51</td>\n",
       "      <td>64779.00</td>\n",
       "      <td>63461.98</td>\n",
       "      <td>20933.06</td>\n",
       "      <td>912422.00</td>\n",
       "      <td>3255.56</td>\n",
       "      <td>323811.19</td>\n",
       "      <td>734026.00</td>\n",
       "      <td>596.20</td>\n",
       "      <td>268783.91</td>\n",
       "      <td>233820.00</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.33</td>\n",
       "      <td>8.73</td>\n",
       "      <td>7.24</td>\n",
       "      <td>5.76</td>\n",
       "      <td>38.57</td>\n",
       "      <td>17.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>25565.00</td>\n",
       "      <td>101</td>\n",
       "      <td>138</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>248.00</td>\n",
       "      <td>179.00</td>\n",
       "      <td>41000.00</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>2024-04-28</td>\n",
       "      <td>6.81</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.69</td>\n",
       "      <td>43208.00</td>\n",
       "      <td>63118.62</td>\n",
       "      <td>16949.20</td>\n",
       "      <td>790652.00</td>\n",
       "      <td>3263.45</td>\n",
       "      <td>304766.01</td>\n",
       "      <td>753239.00</td>\n",
       "      <td>600.20</td>\n",
       "      <td>258059.43</td>\n",
       "      <td>206703.00</td>\n",
       "      <td>7.13</td>\n",
       "      <td>7.27</td>\n",
       "      <td>8.38</td>\n",
       "      <td>7.13</td>\n",
       "      <td>5.88</td>\n",
       "      <td>37.66</td>\n",
       "      <td>16.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20954.00</td>\n",
       "      <td>82</td>\n",
       "      <td>106</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>173.00</td>\n",
       "      <td>165.00</td>\n",
       "      <td>26000.00</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>2024-04-29</td>\n",
       "      <td>6.73</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.47</td>\n",
       "      <td>63006.00</td>\n",
       "      <td>63866.00</td>\n",
       "      <td>28150.23</td>\n",
       "      <td>1152296.00</td>\n",
       "      <td>3216.73</td>\n",
       "      <td>421831.29</td>\n",
       "      <td>943719.00</td>\n",
       "      <td>592.80</td>\n",
       "      <td>330474.01</td>\n",
       "      <td>271926.00</td>\n",
       "      <td>7.03</td>\n",
       "      <td>7.20</td>\n",
       "      <td>8.08</td>\n",
       "      <td>7.03</td>\n",
       "      <td>5.97</td>\n",
       "      <td>36.02</td>\n",
       "      <td>69.00</td>\n",
       "      <td>37.00</td>\n",
       "      <td>33959.00</td>\n",
       "      <td>115</td>\n",
       "      <td>125</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>260.00</td>\n",
       "      <td>188.00</td>\n",
       "      <td>41000.00</td>\n",
       "      <td>Bajista</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Open_time  Open  High  Low  Number of trades  Close_BTCUSDT  \\\n",
       "941 2024-04-25  6.93  7.00 6.70          71088.00       64498.34   \n",
       "942 2024-04-26  6.86  6.95 6.71          67383.00       63770.01   \n",
       "943 2024-04-27  6.76  6.87 6.51          64779.00       63461.98   \n",
       "944 2024-04-28  6.81  6.95 6.69          43208.00       63118.62   \n",
       "945 2024-04-29  6.73  6.83 6.47          63006.00       63866.00   \n",
       "\n",
       "     Volume_BTCUSDT  Number_of_trades_BTCUSDT  Close_ETHUSDT  Volume_ETHUSDT  \\\n",
       "941        31341.46                1375324.00        3155.80       352288.55   \n",
       "942        27085.19                1025561.00        3131.30       252522.65   \n",
       "943        20933.06                 912422.00        3255.56       323811.19   \n",
       "944        16949.20                 790652.00        3263.45       304766.01   \n",
       "945        28150.23                1152296.00        3216.73       421831.29   \n",
       "\n",
       "     Number_of_trades_ETHUSDT  Close_BNBUSDT  Volume_BNBUSDT  \\\n",
       "941                 861077.00         613.20       453745.52   \n",
       "942                 628635.00         598.00       302119.88   \n",
       "943                 734026.00         596.20       268783.91   \n",
       "944                 753239.00         600.20       258059.43   \n",
       "945                 943719.00         592.80       330474.01   \n",
       "\n",
       "     Number_of_trades_BNBUSDT  SMA_20  EMA_20  Upper_Band  Middle_Band  \\\n",
       "941                 353114.00    7.43    7.45        9.08         7.43   \n",
       "942                 269508.00    7.34    7.38        8.94         7.34   \n",
       "943                 233820.00    7.24    7.33        8.73         7.24   \n",
       "944                 206703.00    7.13    7.27        8.38         7.13   \n",
       "945                 271926.00    7.03    7.20        8.08         7.03   \n",
       "\n",
       "     Lower_Band   RSI  buy_1000x_high_coinbase  sell_1000x_high_coinbase  \\\n",
       "941        5.77 38.83                    21.00                     26.00   \n",
       "942        5.74 37.81                    29.00                     24.00   \n",
       "943        5.76 38.57                    17.00                     17.00   \n",
       "944        5.88 37.66                    16.00                     20.00   \n",
       "945        5.97 36.02                    69.00                     37.00   \n",
       "\n",
       "     total_trades_coinbase  Tweets_Utilizados  Tweets_Utilizados_coin  \\\n",
       "941               33468.00                151                     114   \n",
       "942               26619.00                117                     106   \n",
       "943               25565.00                101                     138   \n",
       "944               20954.00                 82                     106   \n",
       "945               33959.00                115                     125   \n",
       "\n",
       "     Tweets_Utilizados_referentes  Tweets_Utilizados_whale_alert  \\\n",
       "941                          0.00                          22.00   \n",
       "942                          0.00                          14.00   \n",
       "943                          0.00                           7.00   \n",
       "944                          0.00                          13.00   \n",
       "945                          0.00                          24.00   \n",
       "\n",
       "     Buy_1000x_high  sell_1000x_high  total_trades_binance Tendencia  \n",
       "941          242.00           219.00              48000.00   Lateral  \n",
       "942          292.00           324.00              42000.00   Lateral  \n",
       "943          248.00           179.00              41000.00   Lateral  \n",
       "944          173.00           165.00              26000.00   Lateral  \n",
       "945          260.00           188.00              41000.00   Bajista  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(classifier_dataset.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(946, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = classifier_dataset.drop(columns=[\"Tendencia\", \"Open_time\"])\n",
    "y = classifier_dataset[\"Tendencia\"]\n",
    "\n",
    "y = y.to_numpy().reshape(-1, 1)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "y_one_hot = onehot_encoder.fit_transform(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LGBMClassifier(objective='multiclass', num_class=3, metric='multi_logloss', verbosity=-1)\n",
    "\n",
    "# Definir el espacio de búsqueda de hiperparámetros\n",
    "param_space = {\n",
    "    'num_leaves': (10, 500),\n",
    "    'learning_rate': (0.001, 0.5), \n",
    "    'n_estimators': (50, 500),\n",
    "    'min_child_samples': (5, 200),\n",
    "    'subsample': (0.5, 1.0),  \n",
    "    'colsample_bytree': (0.5, 1.0),\n",
    "    'n_iter': (50, 500),\n",
    "    'reg_alpha': (0.0, 1.0),\n",
    "    'reg_lambda': (0.0, 1.0),\n",
    "    'objective': ['multiclass'],\n",
    "    'metric': ['multi_logloss', 'multi_error'],\n",
    "    'importance_type': ['gain', 'split'],\n",
    "    'boosting_type': ['gbdt', 'dart', 'rf'],\n",
    "}\n",
    "# Definir función de pérdida para la búsqueda bayesiana\n",
    "def multi_log_loss(estimator, X_test, y_test):\n",
    "    y_pred = estimator.predict_proba(X_test)\n",
    "    loss = log_loss(y_test, y_pred)\n",
    "    return loss\n",
    "\n",
    "# Definir validación cruzada temporal\n",
    "cv = TimeSeriesSplit(n_splits=10).split(X)\n",
    "# stratified_cv = StratifiedKFold(n_splits=10, shuffle=False)\n",
    "\n",
    "# Realizar la búsqueda bayesiana de hiperparámetros\n",
    "bayes_search = BayesSearchCV(\n",
    "    classifier, \n",
    "    param_space, \n",
    "    scoring=multi_log_loss, \n",
    "    # cv=cv\n",
    "    # cv=TimeSeriesSplit(n_splits=10),\n",
    "    # cv=stratified_cv,\n",
    "    # n_iter=100,\n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Realizar la búsqueda bayesiana\n",
    "bayes_result = bayes_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 6.885260735808174\n",
      "Best parameters: OrderedDict([('boosting_type', 'gbdt'), ('colsample_bytree', 0.5), ('importance_type', 'gain'), ('learning_rate', 0.21563682141704843), ('metric', 'multi_logloss'), ('min_child_samples', 36), ('n_estimators', 329), ('n_iter', 500), ('num_leaves', 464), ('objective', 'multiclass'), ('reg_alpha', 0.0), ('reg_lambda', 0.0), ('subsample', 0.7400565273683408)])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(colsample_bytree=0.5, importance_type=&#x27;gain&#x27;,\n",
       "               learning_rate=0.21563682141704843, metric=&#x27;multi_logloss&#x27;,\n",
       "               min_child_samples=36, n_estimators=329, n_iter=500, num_class=3,\n",
       "               num_leaves=464, objective=&#x27;multiclass&#x27;,\n",
       "               subsample=0.7400565273683408, verbosity=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-42\" type=\"checkbox\" checked><label for=\"sk-estimator-id-42\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(colsample_bytree=0.5, importance_type=&#x27;gain&#x27;,\n",
       "               learning_rate=0.21563682141704843, metric=&#x27;multi_logloss&#x27;,\n",
       "               min_child_samples=36, n_estimators=329, n_iter=500, num_class=3,\n",
       "               num_leaves=464, objective=&#x27;multiclass&#x27;,\n",
       "               subsample=0.7400565273683408, verbosity=-1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.5, importance_type='gain',\n",
       "               learning_rate=0.21563682141704843, metric='multi_logloss',\n",
       "               min_child_samples=36, n_estimators=329, n_iter=500, num_class=3,\n",
       "               num_leaves=464, objective='multiclass',\n",
       "               subsample=0.7400565273683408, verbosity=-1)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show best results\n",
    "print(\"Best score:\", bayes_result.best_score_)\n",
    "print(\"Best parameters:\", bayes_result.best_params_)\n",
    "\n",
    "# Entrenar el modelo con los mejores hiperparámetros\n",
    "best_model = bayes_result.best_estimator_\n",
    "best_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 mejores modelos:\n",
      "Modelo 1\n",
      "Hiperparámetros: OrderedDict([('boosting_type', 'rf'), ('colsample_bytree', 0.6640058726815146), ('importance_type', 'gain'), ('learning_rate', 0.4323494224455862), ('metric', 'multi_logloss'), ('min_child_samples', 23), ('n_estimators', 316), ('n_iter', 104), ('num_leaves', 365), ('objective', 'multiclass'), ('reg_alpha', 0.58120052568765), ('reg_lambda', 0.26916188313538064), ('subsample', 0.6368865124311849)])\n",
      "Puntaje: 1.2861887738563345\n",
      "Modelo 2\n",
      "Hiperparámetros: OrderedDict([('boosting_type', 'gbdt'), ('colsample_bytree', 0.6698998613002191), ('importance_type', 'gain'), ('learning_rate', 0.3285155778390284), ('metric', 'multi_error'), ('min_child_samples', 122), ('n_estimators', 408), ('n_iter', 173), ('num_leaves', 285), ('objective', 'multiclass'), ('reg_alpha', 0.22689605408891694), ('reg_lambda', 0.7042148383733584), ('subsample', 0.5357531123324053)])\n",
      "Puntaje: 2.163352437711942\n",
      "Modelo 3\n",
      "Hiperparámetros: OrderedDict([('boosting_type', 'rf'), ('colsample_bytree', 0.6969682351040698), ('importance_type', 'split'), ('learning_rate', 0.187244260950049), ('metric', 'multi_logloss'), ('min_child_samples', 48), ('n_estimators', 195), ('n_iter', 53), ('num_leaves', 61), ('objective', 'multiclass'), ('reg_alpha', 0.33697607820722847), ('reg_lambda', 0.1761118165841086), ('subsample', 0.7584950361291855)])\n",
      "Puntaje: 1.205696885390676\n",
      "Modelo 4\n",
      "Hiperparámetros: OrderedDict([('boosting_type', 'dart'), ('colsample_bytree', 0.519230231656305), ('importance_type', 'split'), ('learning_rate', 0.3517744832478285), ('metric', 'multi_logloss'), ('min_child_samples', 95), ('n_estimators', 394), ('n_iter', 240), ('num_leaves', 346), ('objective', 'multiclass'), ('reg_alpha', 0.8694905166943462), ('reg_lambda', 0.5672021168911027), ('subsample', 0.831698857987385)])\n",
      "Puntaje: 1.844470866165676\n",
      "Modelo 5\n",
      "Hiperparámetros: OrderedDict([('boosting_type', 'gbdt'), ('colsample_bytree', 0.5144223041600338), ('importance_type', 'gain'), ('learning_rate', 0.48854856571948185), ('metric', 'multi_error'), ('min_child_samples', 61), ('n_estimators', 478), ('n_iter', 216), ('num_leaves', 429), ('objective', 'multiclass'), ('reg_alpha', 0.9096874262800255), ('reg_lambda', 0.4705999608821384), ('subsample', 0.7705885393418578)])\n",
      "Puntaje: 2.553559113952261\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Obtener los hiperparámetros y puntajes de los 5 mejores modelos\n",
    "top_n_models = 5\n",
    "best_params_list = []\n",
    "best_scores_list = []\n",
    "\n",
    "for i in range(min(top_n_models, len(bayes_search.cv_results_['params']))):\n",
    "    best_params_list.append(bayes_search.cv_results_['params'][i])\n",
    "    best_scores_list.append(bayes_search.cv_results_['mean_test_score'][i])\n",
    "\n",
    "# Guardar los hiperparámetros de los 5 mejores modelos en un archivo JSON\n",
    "with open('gbm_classifier/top_5_hyperparameters.json', 'w') as f:\n",
    "    json.dump({'best_params': best_params_list, 'best_scores': best_scores_list}, f)\n",
    "\n",
    "# O imprimir los hiperparámetros\n",
    "print(\"Top 5 mejores modelos:\")\n",
    "for i in range(len(best_params_list)):\n",
    "    print(\"Modelo\", i+1)\n",
    "    print(\"Hiperparámetros:\", best_params_list[i])\n",
    "    print(\"Puntaje:\", best_scores_list[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Armado del ensamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una lista para almacenar los modelos individuales\n",
    "individual_models = []\n",
    "\n",
    "# Entrenar los modelos individuales\n",
    "for params_str in best_params_list:\n",
    "    model = LGBMClassifier(verbosity=-1, **params_str)\n",
    "    model.fit(X, y)\n",
    "    individual_models.append(model)\n",
    "\n",
    "voting_model = VotingClassifier(estimators=[('model_'+str(i), model) for i, model in enumerate(individual_models)], voting='hard', verbose=0)#voting='soft', verbose=0)\n",
    "voting_model.fit(X, y)\n",
    "\n",
    "with open('gbm_classifier/gbm_boosting_classifier.pkl', 'wb') as f:\n",
    "    dill.dump(voting_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clasificacion con el ensamble sobre las redicciones de los modelos generativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gbm_classifier/gbm_boosting_classifier.pkl', 'rb') as f:\n",
    "    voting_model = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;model_0&#x27;,\n",
       "                              LGBMClassifier(boosting_type=&#x27;rf&#x27;,\n",
       "                                             colsample_bytree=0.6640058726815146,\n",
       "                                             importance_type=&#x27;gain&#x27;,\n",
       "                                             learning_rate=0.4323494224455862,\n",
       "                                             metric=&#x27;multi_logloss&#x27;,\n",
       "                                             min_child_samples=23,\n",
       "                                             n_estimators=316, n_iter=104,\n",
       "                                             num_leaves=365,\n",
       "                                             objective=&#x27;multiclass&#x27;,\n",
       "                                             reg_alpha=0.58120052568765,\n",
       "                                             reg_lambda=0.26916188313538064,\n",
       "                                             subsample=0.6368...\n",
       "                                             verbosity=-1)),\n",
       "                             (&#x27;model_4&#x27;,\n",
       "                              LGBMClassifier(colsample_bytree=0.5144223041600338,\n",
       "                                             importance_type=&#x27;gain&#x27;,\n",
       "                                             learning_rate=0.48854856571948185,\n",
       "                                             metric=&#x27;multi_error&#x27;,\n",
       "                                             min_child_samples=61,\n",
       "                                             n_estimators=478, n_iter=216,\n",
       "                                             num_leaves=429,\n",
       "                                             objective=&#x27;multiclass&#x27;,\n",
       "                                             reg_alpha=0.9096874262800255,\n",
       "                                             reg_lambda=0.4705999608821384,\n",
       "                                             subsample=0.7705885393418578,\n",
       "                                             verbosity=-1))],\n",
       "                 verbose=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;model_0&#x27;,\n",
       "                              LGBMClassifier(boosting_type=&#x27;rf&#x27;,\n",
       "                                             colsample_bytree=0.6640058726815146,\n",
       "                                             importance_type=&#x27;gain&#x27;,\n",
       "                                             learning_rate=0.4323494224455862,\n",
       "                                             metric=&#x27;multi_logloss&#x27;,\n",
       "                                             min_child_samples=23,\n",
       "                                             n_estimators=316, n_iter=104,\n",
       "                                             num_leaves=365,\n",
       "                                             objective=&#x27;multiclass&#x27;,\n",
       "                                             reg_alpha=0.58120052568765,\n",
       "                                             reg_lambda=0.26916188313538064,\n",
       "                                             subsample=0.6368...\n",
       "                                             verbosity=-1)),\n",
       "                             (&#x27;model_4&#x27;,\n",
       "                              LGBMClassifier(colsample_bytree=0.5144223041600338,\n",
       "                                             importance_type=&#x27;gain&#x27;,\n",
       "                                             learning_rate=0.48854856571948185,\n",
       "                                             metric=&#x27;multi_error&#x27;,\n",
       "                                             min_child_samples=61,\n",
       "                                             n_estimators=478, n_iter=216,\n",
       "                                             num_leaves=429,\n",
       "                                             objective=&#x27;multiclass&#x27;,\n",
       "                                             reg_alpha=0.9096874262800255,\n",
       "                                             reg_lambda=0.4705999608821384,\n",
       "                                             subsample=0.7705885393418578,\n",
       "                                             verbosity=-1))],\n",
       "                 verbose=0)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>model_0</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(boosting_type=&#x27;rf&#x27;, colsample_bytree=0.6640058726815146,\n",
       "               importance_type=&#x27;gain&#x27;, learning_rate=0.4323494224455862,\n",
       "               metric=&#x27;multi_logloss&#x27;, min_child_samples=23, n_estimators=316,\n",
       "               n_iter=104, num_leaves=365, objective=&#x27;multiclass&#x27;,\n",
       "               reg_alpha=0.58120052568765, reg_lambda=0.26916188313538064,\n",
       "               subsample=0.6368865124311849, verbosity=-1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>model_1</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(colsample_bytree=0.6698998613002191, importance_type=&#x27;gain&#x27;,\n",
       "               learning_rate=0.3285155778390284, metric=&#x27;multi_error&#x27;,\n",
       "               min_child_samples=122, n_estimators=408, n_iter=173,\n",
       "               num_leaves=285, objective=&#x27;multiclass&#x27;,\n",
       "               reg_alpha=0.22689605408891694, reg_lambda=0.7042148383733584,\n",
       "               subsample=0.5357531123324053, verbosity=-1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>model_2</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(boosting_type=&#x27;rf&#x27;, colsample_bytree=0.6969682351040698,\n",
       "               learning_rate=0.187244260950049, metric=&#x27;multi_logloss&#x27;,\n",
       "               min_child_samples=48, n_estimators=195, n_iter=53, num_leaves=61,\n",
       "               objective=&#x27;multiclass&#x27;, reg_alpha=0.33697607820722847,\n",
       "               reg_lambda=0.1761118165841086, subsample=0.7584950361291855,\n",
       "               verbosity=-1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>model_3</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(boosting_type=&#x27;dart&#x27;, colsample_bytree=0.519230231656305,\n",
       "               learning_rate=0.3517744832478285, metric=&#x27;multi_logloss&#x27;,\n",
       "               min_child_samples=95, n_estimators=394, n_iter=240,\n",
       "               num_leaves=346, objective=&#x27;multiclass&#x27;,\n",
       "               reg_alpha=0.8694905166943462, reg_lambda=0.5672021168911027,\n",
       "               subsample=0.831698857987385, verbosity=-1)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>model_4</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(colsample_bytree=0.5144223041600338, importance_type=&#x27;gain&#x27;,\n",
       "               learning_rate=0.48854856571948185, metric=&#x27;multi_error&#x27;,\n",
       "               min_child_samples=61, n_estimators=478, n_iter=216,\n",
       "               num_leaves=429, objective=&#x27;multiclass&#x27;,\n",
       "               reg_alpha=0.9096874262800255, reg_lambda=0.4705999608821384,\n",
       "               subsample=0.7705885393418578, verbosity=-1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingClassifier(estimators=[('model_0',\n",
       "                              LGBMClassifier(boosting_type='rf',\n",
       "                                             colsample_bytree=0.6640058726815146,\n",
       "                                             importance_type='gain',\n",
       "                                             learning_rate=0.4323494224455862,\n",
       "                                             metric='multi_logloss',\n",
       "                                             min_child_samples=23,\n",
       "                                             n_estimators=316, n_iter=104,\n",
       "                                             num_leaves=365,\n",
       "                                             objective='multiclass',\n",
       "                                             reg_alpha=0.58120052568765,\n",
       "                                             reg_lambda=0.26916188313538064,\n",
       "                                             subsample=0.6368...\n",
       "                                             verbosity=-1)),\n",
       "                             ('model_4',\n",
       "                              LGBMClassifier(colsample_bytree=0.5144223041600338,\n",
       "                                             importance_type='gain',\n",
       "                                             learning_rate=0.48854856571948185,\n",
       "                                             metric='multi_error',\n",
       "                                             min_child_samples=61,\n",
       "                                             n_estimators=478, n_iter=216,\n",
       "                                             num_leaves=429,\n",
       "                                             objective='multiclass',\n",
       "                                             reg_alpha=0.9096874262800255,\n",
       "                                             reg_lambda=0.4705999608821384,\n",
       "                                             subsample=0.7705885393418578,\n",
       "                                             verbosity=-1))],\n",
       "                 verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datos originales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open_time</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Number of trades</th>\n",
       "      <th>Close_BTCUSDT</th>\n",
       "      <th>Volume_BTCUSDT</th>\n",
       "      <th>Number_of_trades_BTCUSDT</th>\n",
       "      <th>Close_ETHUSDT</th>\n",
       "      <th>Volume_ETHUSDT</th>\n",
       "      <th>Number_of_trades_ETHUSDT</th>\n",
       "      <th>Close_BNBUSDT</th>\n",
       "      <th>Volume_BNBUSDT</th>\n",
       "      <th>Number_of_trades_BNBUSDT</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>EMA_20</th>\n",
       "      <th>Upper_Band</th>\n",
       "      <th>Middle_Band</th>\n",
       "      <th>Lower_Band</th>\n",
       "      <th>RSI</th>\n",
       "      <th>buy_1000x_high_coinbase</th>\n",
       "      <th>sell_1000x_high_coinbase</th>\n",
       "      <th>total_trades_coinbase</th>\n",
       "      <th>Tweets_Utilizados</th>\n",
       "      <th>Tweets_Utilizados_coin</th>\n",
       "      <th>Tweets_Utilizados_referentes</th>\n",
       "      <th>Tweets_Utilizados_whale_alert</th>\n",
       "      <th>Buy_1000x_high</th>\n",
       "      <th>sell_1000x_high</th>\n",
       "      <th>total_trades_binance</th>\n",
       "      <th>Tendencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>2024-04-30</td>\n",
       "      <td>6.59</td>\n",
       "      <td>6.67</td>\n",
       "      <td>6.04</td>\n",
       "      <td>115512.00</td>\n",
       "      <td>60672.00</td>\n",
       "      <td>54947.66</td>\n",
       "      <td>1985671.00</td>\n",
       "      <td>3014.05</td>\n",
       "      <td>561717.49</td>\n",
       "      <td>1292873.00</td>\n",
       "      <td>578.40</td>\n",
       "      <td>766513.45</td>\n",
       "      <td>486465.00</td>\n",
       "      <td>6.93</td>\n",
       "      <td>7.13</td>\n",
       "      <td>7.80</td>\n",
       "      <td>6.93</td>\n",
       "      <td>6.05</td>\n",
       "      <td>34.18</td>\n",
       "      <td>51.00</td>\n",
       "      <td>55.00</td>\n",
       "      <td>48709.00</td>\n",
       "      <td>142</td>\n",
       "      <td>187</td>\n",
       "      <td>1.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>379.00</td>\n",
       "      <td>377.00</td>\n",
       "      <td>70000.00</td>\n",
       "      <td>Bajista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>6.42</td>\n",
       "      <td>6.93</td>\n",
       "      <td>6.13</td>\n",
       "      <td>175570.00</td>\n",
       "      <td>58364.97</td>\n",
       "      <td>81166.47</td>\n",
       "      <td>2401089.00</td>\n",
       "      <td>2972.46</td>\n",
       "      <td>624963.78</td>\n",
       "      <td>1365039.00</td>\n",
       "      <td>561.80</td>\n",
       "      <td>669027.32</td>\n",
       "      <td>427425.00</td>\n",
       "      <td>6.85</td>\n",
       "      <td>7.11</td>\n",
       "      <td>7.41</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.29</td>\n",
       "      <td>43.30</td>\n",
       "      <td>42.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>83718.00</td>\n",
       "      <td>130</td>\n",
       "      <td>177</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36.00</td>\n",
       "      <td>327.00</td>\n",
       "      <td>340.00</td>\n",
       "      <td>107000.00</td>\n",
       "      <td>Alcista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>2024-05-02</td>\n",
       "      <td>6.90</td>\n",
       "      <td>7.41</td>\n",
       "      <td>6.69</td>\n",
       "      <td>109002.00</td>\n",
       "      <td>59060.61</td>\n",
       "      <td>47583.82</td>\n",
       "      <td>1572898.00</td>\n",
       "      <td>2986.19</td>\n",
       "      <td>365939.72</td>\n",
       "      <td>880167.00</td>\n",
       "      <td>560.50</td>\n",
       "      <td>359794.32</td>\n",
       "      <td>250921.00</td>\n",
       "      <td>6.85</td>\n",
       "      <td>7.12</td>\n",
       "      <td>7.42</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.29</td>\n",
       "      <td>49.27</td>\n",
       "      <td>87.00</td>\n",
       "      <td>57.00</td>\n",
       "      <td>61208.00</td>\n",
       "      <td>461</td>\n",
       "      <td>374</td>\n",
       "      <td>1.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>270.00</td>\n",
       "      <td>282.00</td>\n",
       "      <td>71000.00</td>\n",
       "      <td>Alcista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>2024-05-03</td>\n",
       "      <td>7.27</td>\n",
       "      <td>7.39</td>\n",
       "      <td>7.00</td>\n",
       "      <td>109634.00</td>\n",
       "      <td>62882.01</td>\n",
       "      <td>43628.40</td>\n",
       "      <td>1558661.00</td>\n",
       "      <td>3102.61</td>\n",
       "      <td>355825.84</td>\n",
       "      <td>859542.00</td>\n",
       "      <td>587.00</td>\n",
       "      <td>342906.43</td>\n",
       "      <td>257575.00</td>\n",
       "      <td>6.90</td>\n",
       "      <td>7.14</td>\n",
       "      <td>7.44</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.35</td>\n",
       "      <td>48.86</td>\n",
       "      <td>52.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>46255.00</td>\n",
       "      <td>573</td>\n",
       "      <td>474</td>\n",
       "      <td>1.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>386.00</td>\n",
       "      <td>635.00</td>\n",
       "      <td>69000.00</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>2024-05-04</td>\n",
       "      <td>7.24</td>\n",
       "      <td>7.28</td>\n",
       "      <td>7.11</td>\n",
       "      <td>71120.00</td>\n",
       "      <td>63892.04</td>\n",
       "      <td>24368.69</td>\n",
       "      <td>1113509.00</td>\n",
       "      <td>3117.23</td>\n",
       "      <td>196263.95</td>\n",
       "      <td>575026.00</td>\n",
       "      <td>585.70</td>\n",
       "      <td>197129.25</td>\n",
       "      <td>210303.00</td>\n",
       "      <td>6.91</td>\n",
       "      <td>7.13</td>\n",
       "      <td>7.46</td>\n",
       "      <td>6.91</td>\n",
       "      <td>6.36</td>\n",
       "      <td>46.98</td>\n",
       "      <td>68.00</td>\n",
       "      <td>50.00</td>\n",
       "      <td>34251.00</td>\n",
       "      <td>407</td>\n",
       "      <td>472</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.00</td>\n",
       "      <td>203.00</td>\n",
       "      <td>232.00</td>\n",
       "      <td>49000.00</td>\n",
       "      <td>Bajista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>2024-05-05</td>\n",
       "      <td>7.12</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.01</td>\n",
       "      <td>72928.00</td>\n",
       "      <td>64012.00</td>\n",
       "      <td>18526.75</td>\n",
       "      <td>992921.00</td>\n",
       "      <td>3136.41</td>\n",
       "      <td>218760.27</td>\n",
       "      <td>600693.00</td>\n",
       "      <td>592.00</td>\n",
       "      <td>180458.24</td>\n",
       "      <td>180794.00</td>\n",
       "      <td>6.94</td>\n",
       "      <td>7.15</td>\n",
       "      <td>7.51</td>\n",
       "      <td>6.94</td>\n",
       "      <td>6.37</td>\n",
       "      <td>50.00</td>\n",
       "      <td>37.00</td>\n",
       "      <td>52.00</td>\n",
       "      <td>29197.00</td>\n",
       "      <td>417</td>\n",
       "      <td>499</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>320.00</td>\n",
       "      <td>284.00</td>\n",
       "      <td>47000.00</td>\n",
       "      <td>Alcista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>2024-05-06</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.47</td>\n",
       "      <td>7.06</td>\n",
       "      <td>94264.00</td>\n",
       "      <td>63165.19</td>\n",
       "      <td>34674.92</td>\n",
       "      <td>1392557.00</td>\n",
       "      <td>3062.60</td>\n",
       "      <td>355135.30</td>\n",
       "      <td>873200.00</td>\n",
       "      <td>588.20</td>\n",
       "      <td>278669.01</td>\n",
       "      <td>248490.00</td>\n",
       "      <td>6.96</td>\n",
       "      <td>7.15</td>\n",
       "      <td>7.53</td>\n",
       "      <td>6.96</td>\n",
       "      <td>6.39</td>\n",
       "      <td>47.10</td>\n",
       "      <td>49.00</td>\n",
       "      <td>71.00</td>\n",
       "      <td>40027.00</td>\n",
       "      <td>482</td>\n",
       "      <td>531</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>339.00</td>\n",
       "      <td>249.00</td>\n",
       "      <td>59000.00</td>\n",
       "      <td>Bajista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>2024-05-07</td>\n",
       "      <td>7.12</td>\n",
       "      <td>7.29</td>\n",
       "      <td>6.98</td>\n",
       "      <td>64947.00</td>\n",
       "      <td>62312.08</td>\n",
       "      <td>25598.79</td>\n",
       "      <td>1272898.00</td>\n",
       "      <td>3005.69</td>\n",
       "      <td>298796.68</td>\n",
       "      <td>815246.00</td>\n",
       "      <td>576.50</td>\n",
       "      <td>289488.71</td>\n",
       "      <td>266127.00</td>\n",
       "      <td>6.98</td>\n",
       "      <td>7.13</td>\n",
       "      <td>7.52</td>\n",
       "      <td>6.98</td>\n",
       "      <td>6.44</td>\n",
       "      <td>45.10</td>\n",
       "      <td>21.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>31028.00</td>\n",
       "      <td>495</td>\n",
       "      <td>494</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>296.00</td>\n",
       "      <td>205.00</td>\n",
       "      <td>42000.00</td>\n",
       "      <td>Bajista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>2024-05-08</td>\n",
       "      <td>6.99</td>\n",
       "      <td>7.19</td>\n",
       "      <td>6.89</td>\n",
       "      <td>75550.00</td>\n",
       "      <td>61193.03</td>\n",
       "      <td>26121.19</td>\n",
       "      <td>1415152.00</td>\n",
       "      <td>2974.21</td>\n",
       "      <td>266934.81</td>\n",
       "      <td>830635.00</td>\n",
       "      <td>588.60</td>\n",
       "      <td>297016.62</td>\n",
       "      <td>249379.00</td>\n",
       "      <td>6.99</td>\n",
       "      <td>7.12</td>\n",
       "      <td>7.52</td>\n",
       "      <td>6.99</td>\n",
       "      <td>6.46</td>\n",
       "      <td>44.94</td>\n",
       "      <td>17.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>32040.00</td>\n",
       "      <td>426</td>\n",
       "      <td>494</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>230.00</td>\n",
       "      <td>177.00</td>\n",
       "      <td>49000.00</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>2024-05-09</td>\n",
       "      <td>6.98</td>\n",
       "      <td>7.09</td>\n",
       "      <td>6.78</td>\n",
       "      <td>75016.00</td>\n",
       "      <td>63074.01</td>\n",
       "      <td>30660.81</td>\n",
       "      <td>1381957.00</td>\n",
       "      <td>3036.23</td>\n",
       "      <td>238561.75</td>\n",
       "      <td>686147.00</td>\n",
       "      <td>596.80</td>\n",
       "      <td>464857.60</td>\n",
       "      <td>332988.00</td>\n",
       "      <td>7.01</td>\n",
       "      <td>7.11</td>\n",
       "      <td>7.52</td>\n",
       "      <td>7.01</td>\n",
       "      <td>6.50</td>\n",
       "      <td>46.32</td>\n",
       "      <td>18.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>29314.00</td>\n",
       "      <td>475</td>\n",
       "      <td>464</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.00</td>\n",
       "      <td>188.00</td>\n",
       "      <td>257.00</td>\n",
       "      <td>50000.00</td>\n",
       "      <td>Lateral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Open_time  Open  High  Low  Number of trades  Close_BTCUSDT  \\\n",
       "946 2024-04-30  6.59  6.67 6.04         115512.00       60672.00   \n",
       "947 2024-05-01  6.42  6.93 6.13         175570.00       58364.97   \n",
       "948 2024-05-02  6.90  7.41 6.69         109002.00       59060.61   \n",
       "949 2024-05-03  7.27  7.39 7.00         109634.00       62882.01   \n",
       "950 2024-05-04  7.24  7.28 7.11          71120.00       63892.04   \n",
       "951 2024-05-05  7.12  7.40 7.01          72928.00       64012.00   \n",
       "952 2024-05-06  7.30  7.47 7.06          94264.00       63165.19   \n",
       "953 2024-05-07  7.12  7.29 6.98          64947.00       62312.08   \n",
       "954 2024-05-08  6.99  7.19 6.89          75550.00       61193.03   \n",
       "955 2024-05-09  6.98  7.09 6.78          75016.00       63074.01   \n",
       "\n",
       "     Volume_BTCUSDT  Number_of_trades_BTCUSDT  Close_ETHUSDT  Volume_ETHUSDT  \\\n",
       "946        54947.66                1985671.00        3014.05       561717.49   \n",
       "947        81166.47                2401089.00        2972.46       624963.78   \n",
       "948        47583.82                1572898.00        2986.19       365939.72   \n",
       "949        43628.40                1558661.00        3102.61       355825.84   \n",
       "950        24368.69                1113509.00        3117.23       196263.95   \n",
       "951        18526.75                 992921.00        3136.41       218760.27   \n",
       "952        34674.92                1392557.00        3062.60       355135.30   \n",
       "953        25598.79                1272898.00        3005.69       298796.68   \n",
       "954        26121.19                1415152.00        2974.21       266934.81   \n",
       "955        30660.81                1381957.00        3036.23       238561.75   \n",
       "\n",
       "     Number_of_trades_ETHUSDT  Close_BNBUSDT  Volume_BNBUSDT  \\\n",
       "946                1292873.00         578.40       766513.45   \n",
       "947                1365039.00         561.80       669027.32   \n",
       "948                 880167.00         560.50       359794.32   \n",
       "949                 859542.00         587.00       342906.43   \n",
       "950                 575026.00         585.70       197129.25   \n",
       "951                 600693.00         592.00       180458.24   \n",
       "952                 873200.00         588.20       278669.01   \n",
       "953                 815246.00         576.50       289488.71   \n",
       "954                 830635.00         588.60       297016.62   \n",
       "955                 686147.00         596.80       464857.60   \n",
       "\n",
       "     Number_of_trades_BNBUSDT  SMA_20  EMA_20  Upper_Band  Middle_Band  \\\n",
       "946                 486465.00    6.93    7.13        7.80         6.93   \n",
       "947                 427425.00    6.85    7.11        7.41         6.85   \n",
       "948                 250921.00    6.85    7.12        7.42         6.85   \n",
       "949                 257575.00    6.90    7.14        7.44         6.90   \n",
       "950                 210303.00    6.91    7.13        7.46         6.91   \n",
       "951                 180794.00    6.94    7.15        7.51         6.94   \n",
       "952                 248490.00    6.96    7.15        7.53         6.96   \n",
       "953                 266127.00    6.98    7.13        7.52         6.98   \n",
       "954                 249379.00    6.99    7.12        7.52         6.99   \n",
       "955                 332988.00    7.01    7.11        7.52         7.01   \n",
       "\n",
       "     Lower_Band   RSI  buy_1000x_high_coinbase  sell_1000x_high_coinbase  \\\n",
       "946        6.05 34.18                    51.00                     55.00   \n",
       "947        6.29 43.30                    42.00                     50.00   \n",
       "948        6.29 49.27                    87.00                     57.00   \n",
       "949        6.35 48.86                    52.00                     40.00   \n",
       "950        6.36 46.98                    68.00                     50.00   \n",
       "951        6.37 50.00                    37.00                     52.00   \n",
       "952        6.39 47.10                    49.00                     71.00   \n",
       "953        6.44 45.10                    21.00                     25.00   \n",
       "954        6.46 44.94                    17.00                     24.00   \n",
       "955        6.50 46.32                    18.00                     17.00   \n",
       "\n",
       "     total_trades_coinbase  Tweets_Utilizados  Tweets_Utilizados_coin  \\\n",
       "946               48709.00                142                     187   \n",
       "947               83718.00                130                     177   \n",
       "948               61208.00                461                     374   \n",
       "949               46255.00                573                     474   \n",
       "950               34251.00                407                     472   \n",
       "951               29197.00                417                     499   \n",
       "952               40027.00                482                     531   \n",
       "953               31028.00                495                     494   \n",
       "954               32040.00                426                     494   \n",
       "955               29314.00                475                     464   \n",
       "\n",
       "     Tweets_Utilizados_referentes  Tweets_Utilizados_whale_alert  \\\n",
       "946                          1.00                          23.00   \n",
       "947                          0.00                          36.00   \n",
       "948                          1.00                          25.00   \n",
       "949                          1.00                          22.00   \n",
       "950                          0.00                          14.00   \n",
       "951                          0.00                           6.00   \n",
       "952                          0.00                          25.00   \n",
       "953                          0.00                          28.00   \n",
       "954                          0.00                          24.00   \n",
       "955                          0.00                          16.00   \n",
       "\n",
       "     Buy_1000x_high  sell_1000x_high  total_trades_binance Tendencia  \n",
       "946          379.00           377.00              70000.00   Bajista  \n",
       "947          327.00           340.00             107000.00   Alcista  \n",
       "948          270.00           282.00              71000.00   Alcista  \n",
       "949          386.00           635.00              69000.00   Lateral  \n",
       "950          203.00           232.00              49000.00   Bajista  \n",
       "951          320.00           284.00              47000.00   Alcista  \n",
       "952          339.00           249.00              59000.00   Bajista  \n",
       "953          296.00           205.00              42000.00   Bajista  \n",
       "954          230.00           177.00              49000.00   Lateral  \n",
       "955          188.00           257.00              50000.00   Lateral  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(clasifier_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bajista', 'Alcista', 'Alcista', 'Alcista', 'Alcista', 'Alcista',\n",
       "       'Bajista', 'Alcista', 'Alcista', 'Alcista'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_clases = 3 \n",
    "\n",
    "validation_predictions = voting_model.predict(clasifier_validation[columns].drop(columns=[\"Open_time\"]))\n",
    "display(validation_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datos generados por auto ml con prophet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Lateral', 'Lateral', 'Alcista', 'Alcista', 'Lateral', 'Alcista',\n",
       "       'Alcista', 'Alcista', 'Alcista', 'Alcista'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auto_ml_prophet_df = pd.read_csv('auto_timeseries_models_prophet/predicciones.csv')\n",
    "auto_mp_prophet_predictions = voting_model.predict(auto_ml_prophet_df[columns].drop(columns=[\"Open_time\"]))\n",
    "display(auto_mp_prophet_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datos generados por auto ml con stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bajista', 'Bajista', 'Bajista', 'Bajista', 'Bajista', 'Bajista',\n",
       "       'Bajista', 'Bajista', 'Bajista', 'Bajista'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auto_ml_stats_df = pd.read_csv('auto_timeseries_models/predicciones.csv')\n",
    "auto_mp_stats_predictions = voting_model.predict(auto_ml_stats_df[columns].drop(columns=[\"Open_time\"]))\n",
    "\n",
    "display(auto_mp_stats_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datos generados por auto ml con modelos clasicos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bajista', 'Bajista', 'Bajista', 'Bajista', 'Bajista', 'Bajista',\n",
       "       'Bajista', 'Bajista', 'Bajista', 'Bajista'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "auto_ml_df = pd.read_csv('h2o_models/predicciones.csv')\n",
    "auto_mp_predictions = voting_model.predict(auto_ml_df[columns].drop(columns=[\"Open_time\"]))\n",
    "display(auto_mp_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Datos generados por auto ml con skforecast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bajista', 'Lateral', 'Alcista', 'Alcista', 'Alcista', 'Alcista',\n",
       "       'Alcista', 'Alcista', 'Alcista', 'Alcista'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "skforecast_df = pd.read_csv('skforecast/predicciones.csv')\n",
    "skforecast_predictions = voting_model.predict(skforecast_df[columns[1:]])\n",
    "display(skforecast_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
